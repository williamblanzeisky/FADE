{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import math\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "import random as python_random\n",
    "import collections\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import balanced_accuracy_score,accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Conv2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Why BNN?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# some helper functions for Deep Ensembles\n",
    "def nll1(y_true, y_pred):\n",
    "    \"\"\" Negative log likelihood. \"\"\"\n",
    "    y_true = tf.cast(y_true, dtype=tf.float32)\n",
    "    # keras.losses.binary_crossentropy give the mean\n",
    "    # over the last axis. we require the sum\n",
    "    return K.sum(K.binary_crossentropy(y_true, y_pred), axis=-1)\n",
    "\n",
    "def train(xtrain, ytrain, batch, epochs, validation_data=None):\n",
    "        h = []\n",
    "        models = []\n",
    "        # Train 10 models\n",
    "        for i in tqdm(range(10)):\n",
    "            # Get model\n",
    "            models.append(base_model())\n",
    "            # Train model\n",
    "            h1=models[i].fit(xtrain, ytrain, batch_size=batch,  epochs=epochs,verbose=0)\n",
    "            h.append(h1)\n",
    "        return h, models\n",
    "\n",
    "def base_model():\n",
    "    model = Sequential([\n",
    "            Dense(50,activation='sigmoid'),\n",
    "            Dense(1,activation='sigmoid')])\n",
    "    model.compile(tf.keras.optimizers.Adam(learning_rate=0.01), loss=nll1,metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "def model_eval(X,Y,classifiers):\n",
    "    loss = []\n",
    "    acc = []\n",
    "    for each_model in classifiers:\n",
    "        test_results = each_model.evaluate(X,Y)\n",
    "        print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]}%')\n",
    "        loss.append(test_results[0])\n",
    "        acc.append(test_results[1])\n",
    "    print(\"######################################################\")\n",
    "    print(f' Loss    : {np.mean(loss)} - {np.std(loss)}')\n",
    "    print(f' Accuracy: {np.mean(acc)} - {np.std(acc)}%')\n",
    "    return loss,acc\n",
    "\n",
    "def underestimation_score_1(y_true,y_pred,SA):\n",
    "\n",
    "    mydict = {}\n",
    "    mydict['actual'] = y_true\n",
    "    mydict['predicted'] = y_pred\n",
    "    mydict['sex'] = SA\n",
    "    us = pd.DataFrame(mydict)\n",
    "\n",
    "    P_dash_FX0 = df_count_feat_val_match(us, 'predicted', 1, 'sex',1)\n",
    "    P_FX0 = df_count_feat_val_match(us, 'actual', 1, 'sex',1)\n",
    "\n",
    "\n",
    "    if P_FX0 == 0:\n",
    "        print(\"Divsion by zero detected: denom is \",P_FX0)\n",
    "        return 0.000001\n",
    "    print(P_dash_FX0,P_FX0)\n",
    "    return P_dash_FX0/P_FX0\n",
    "\n",
    "def underestimation_score(y_true,y_pred,SA):\n",
    "\n",
    "    mydict = {}\n",
    "    mydict['actual'] = y_true\n",
    "    mydict['predicted'] = y_pred\n",
    "    mydict['sex'] = SA\n",
    "    us = pd.DataFrame(mydict)\n",
    "\n",
    "    P_dash_FX0 = df_count_feat_val_match(us, 'predicted', 1, 'sex',0)\n",
    "    P_FX0 = df_count_feat_val_match(us, 'actual', 1, 'sex',0)\n",
    "    if P_FX0 == 0:\n",
    "        print(\"Divsion by zero detected: denom is \",P_FX0)\n",
    "        return 0.000001\n",
    "    print(P_dash_FX0,P_FX0)\n",
    "    return P_dash_FX0/P_FX0\n",
    "\n",
    "def UEI(sa, Y_train, Y_pred):\n",
    "    us_df = {}\n",
    "    us_df['sa'] = sa\n",
    "    us_df['ytrain_actual'] = Y_train\n",
    "    us_df['ytest_pred'] = Y_pred\n",
    "    us_df = pd.DataFrame(us_df)\n",
    "\n",
    "    prob_array = []\n",
    "    for y in (0,1):\n",
    "        for s in (0,1):\n",
    "#             print((y,s))\n",
    "            p_tilda = df_count_feat_val_match(us_df, 'ytrain_actual', y, 'sa',s)/len(us_df)\n",
    "            p_hat = df_count_feat_val_match(us_df, 'ytest_pred', y, 'sa',s)/len(us_df)\n",
    "#             print(p_hat,p_tilda)\n",
    "            prob_array.append(   np.square(np.sqrt(p_hat)-np.sqrt(p_tilda))    )\n",
    "    return np.sqrt(0.5*np.sum(prob_array))\n",
    "\n",
    "def df_count_feat_val_match(df1, f1, v1, f2, v2):\n",
    "    return len (df1[(df1[f1]==int(v1)) & (df1[f2]==int(v2))])\n",
    "\n",
    "import os\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from sklearn.utils import check_consistent_length, column_or_1d\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "\n",
    "__all__ = [\n",
    "    'compute_calibration_error',\n",
    "    'create_binned_data',\n",
    "    'get_bin_boundaries',\n",
    "    'compute_binary_score',\n",
    "    'compute_calibration_summary',\n",
    "]\n",
    "\n",
    "\n",
    "def compute_calibration_error(\n",
    "    y_true: np.ndarray,\n",
    "    y_prob: np.ndarray,\n",
    "    n_bins: int=15,\n",
    "    round_digits: int=4) -> float:\n",
    "    \"\"\"\n",
    "    Computes the calibration error for binary classification via binning\n",
    "    data points into the specified number of bins. Samples with similar\n",
    "    ``y_prob`` will be grouped into the same bin. The bin boundary is\n",
    "    determined by having similar number of samples within each bin.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : 1d ndarray\n",
    "        Binary true targets.\n",
    "\n",
    "    y_prob : 1d ndarray\n",
    "        Raw probability/score of the positive class.\n",
    "\n",
    "    n_bins : int, default 15\n",
    "        A bigger bin number requires more data. In general,\n",
    "        the larger the bin size, the closer the calibration error\n",
    "        will be to the true calibration error.\n",
    "\n",
    "    round_digits : int, default 4\n",
    "        Round the calibration error metric.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    calibration_error : float\n",
    "        RMSE between the average positive label and predicted probability\n",
    "        within each bin.\n",
    "    \"\"\"\n",
    "    y_true = column_or_1d(y_true)\n",
    "    y_prob = column_or_1d(y_prob)\n",
    "    check_consistent_length(y_true, y_prob)\n",
    "\n",
    "    binned_y_true, binned_y_prob = create_binned_data(y_true, y_prob, n_bins)\n",
    "\n",
    "    # looping shouldn't be a source of bottleneck as n_bins should be a small number.\n",
    "    bin_errors = 0.0\n",
    "    for bin_y_true, bin_y_prob in zip(binned_y_true, binned_y_prob):\n",
    "        avg_y_true = np.mean(bin_y_true)\n",
    "        avg_y_score = np.mean(bin_y_prob)\n",
    "        bin_error = (avg_y_score - avg_y_true) ** 2\n",
    "        bin_errors += bin_error * len(bin_y_true)\n",
    "\n",
    "    calibration_error = math.sqrt(bin_errors / len(y_true))\n",
    "    return round(calibration_error, round_digits)\n",
    "\n",
    "\n",
    "def create_binned_data(\n",
    "    y_true: np.ndarray,\n",
    "    y_prob: np.ndarray,\n",
    "    n_bins: int) -> Tuple[List[np.ndarray], List[np.ndarray]]:\n",
    "    \"\"\"\n",
    "    Bin ``y_true`` and ``y_prob`` by distribution of the data.\n",
    "    i.e. each bin will contain approximately an equal number of\n",
    "    data points. Bins are sorted based on ascending order of ``y_prob``.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : 1d ndarray\n",
    "        Binary true targets.\n",
    "\n",
    "    y_prob : 1d ndarray\n",
    "        Raw probability/score of the positive class.\n",
    "\n",
    "    n_bins : int, default 15\n",
    "        A bigger bin number requires more data.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    binned_y_true/binned_y_prob : 1d ndarray\n",
    "        Each element in the list stores the data for that bin.\n",
    "    \"\"\"\n",
    "    sorted_indices = np.argsort(y_prob)\n",
    "    sorted_y_true = y_true[sorted_indices]\n",
    "    sorted_y_prob = y_prob[sorted_indices]\n",
    "    binned_y_true = np.array_split(sorted_y_true, n_bins)\n",
    "    binned_y_prob = np.array_split(sorted_y_prob, n_bins)\n",
    "    return binned_y_true, binned_y_prob\n",
    "\n",
    "\n",
    "def get_bin_boundaries(binned_y_prob: List[np.ndarray]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Given ``binned_y_prob`` from ``create_binned_data`` get the\n",
    "    boundaries for each bin.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    binned_y_prob : list\n",
    "        Each element in the list stores the data for that bin.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bins : 1d ndarray\n",
    "        Boundaries for each bin.\n",
    "    \"\"\"\n",
    "    bins = []\n",
    "    for i in range(len(binned_y_prob) - 1):\n",
    "        last_prob = binned_y_prob[i][-1]\n",
    "        next_first_prob = binned_y_prob[i + 1][0]\n",
    "        bins.append((last_prob + next_first_prob) / 2.0)\n",
    "\n",
    "    bins.append(1.0)\n",
    "    return np.array(bins)\n",
    "\n",
    "\n",
    "def compute_binary_score(\n",
    "    y_true: np.ndarray,\n",
    "    y_prob: np.ndarray,\n",
    "    round_digits: int=4) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Compute various evaluation metrics for binary classification.\n",
    "    Including auc, precision, recall, f1, log loss, brier score. The\n",
    "    threshold for precision and recall numbers are based on the one\n",
    "    that gives the best f1 score.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : 1d ndarray\n",
    "        Binary true targets.\n",
    "\n",
    "    y_prob : 1d ndarray\n",
    "        Raw probability/score of the positive class.\n",
    "\n",
    "    round_digits : int, default 4\n",
    "        Round the evaluation metric.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    metrics_dict : dict\n",
    "        Metrics are stored in key value pair. ::\n",
    "\n",
    "        {\n",
    "            'auc': 0.82,\n",
    "            'precision': 0.56,\n",
    "            'recall': 0.61,\n",
    "            'f1': 0.59,\n",
    "            'log_loss': 0.42,\n",
    "            'brier': 0.12\n",
    "        }\n",
    "    \"\"\"\n",
    "    auc = round(metrics.roc_auc_score(y_true, y_prob), round_digits)\n",
    "    log_loss = round(metrics.log_loss(y_true, y_prob), round_digits)\n",
    "    brier_score = round(metrics.brier_score_loss(y_true, y_prob), round_digits)\n",
    "\n",
    "    precision, recall, threshold = metrics.precision_recall_curve(y_true, y_prob)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    mask = ~np.isnan(f1)\n",
    "    f1 = f1[mask]\n",
    "    precision = precision[mask]\n",
    "    recall = recall[mask]\n",
    "\n",
    "    best_index = np.argmax(f1)\n",
    "    precision = round(precision[best_index], round_digits)\n",
    "    recall = round(recall[best_index], round_digits)\n",
    "    f1 = round(f1[best_index], round_digits)\n",
    "    return {\n",
    "        'auc': auc,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'log_loss': log_loss,\n",
    "        'brier': brier_score\n",
    "    }\n",
    "\n",
    "\n",
    "def compute_calibration_summary(\n",
    "    eval_dict: Dict[str, pd.DataFrame],\n",
    "    label_col: str='label',\n",
    "    score_col: str='score',\n",
    "    n_bins: int=15,\n",
    "    strategy: str='quantile',\n",
    "    round_digits: int=4,\n",
    "    show: bool=True,\n",
    "    save_plot_path: Optional[str]=None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Plots the calibration curve and computes the summary statistics for the model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    eval_dict : dict\n",
    "        We can evaluate multiple calibration model's performance in one go. The key\n",
    "        is the model name used to distinguish different calibration model, the value\n",
    "        is the dataframe that stores the binary true targets and the predicted score\n",
    "        for the positive class.\n",
    "\n",
    "    label_col : str\n",
    "        Column name for the dataframe in ``eval_dict`` that stores the binary true targets.\n",
    "\n",
    "    score_col : str\n",
    "        Column name for the dataframe in ``eval_dict`` that stores the predicted score.\n",
    "\n",
    "    n_bins : int, default 15\n",
    "        Number of bins to discretize the calibration curve plot and calibration error statistics.\n",
    "        A bigger number requires more data, but will be closer to the true calibration error.\n",
    "\n",
    "    strategy : {'uniform', 'quantile'}, default 'quantile'\n",
    "        Strategy used to define the boundary of the bins.\n",
    "\n",
    "        - uniform: The bins have identical widths.\n",
    "        - quantile: The bins have the same number of samples and depend on the predicted score.\n",
    "\n",
    "    round_digits : default 4\n",
    "        Round the evaluation metric.\n",
    "\n",
    "    show : bool, default True\n",
    "        Whether to show the plots on the console or jupyter notebook.\n",
    "\n",
    "    save_plot_path : str, default None\n",
    "        Path where we'll store the calibration plot. None means it will not save the plot.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df_metrics : pd.DataFrame\n",
    "        Corresponding metrics for all the input dataframe.\n",
    "    \"\"\"\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(2)\n",
    "\n",
    "    # estimator_metrics stores list of dict, e.g.\n",
    "    # [{'auc': 0.776, 'name': 'xgb'}]\n",
    "    estimator_metrics = []\n",
    "    for name, df_eval in eval_dict.items():\n",
    "        prob_true, prob_pred = calibration_curve(\n",
    "            df_eval[label_col],\n",
    "            df_eval[score_col],\n",
    "            n_bins=n_bins,\n",
    "            strategy=strategy)\n",
    "\n",
    "        calibration_error = compute_calibration_error(\n",
    "            df_eval[label_col], df_eval[score_col], n_bins, round_digits)\n",
    "        metrics_dict = compute_binary_score(df_eval[label_col], df_eval[score_col], round_digits)\n",
    "        metrics_dict['calibration_error'] = calibration_error\n",
    "        metrics_dict['name'] = name\n",
    "        estimator_metrics.append(metrics_dict)\n",
    "\n",
    "        ax1.plot(prob_pred, prob_true, 's-', label=name)\n",
    "        ax2.hist(df_eval[score_col], range=(0, 1), bins=n_bins, label=name, histtype='step', lw=2)\n",
    "\n",
    "    ax1.plot([0, 1], [0, 1], 'k:', label='perfect')\n",
    "\n",
    "    ax1.set_xlabel('Fraction of positives (Predicted)')\n",
    "    ax1.set_ylabel('Fraction of positives (Actual)')\n",
    "    ax1.set_ylim([-0.05, 1.05])\n",
    "    ax1.legend(loc='upper left', ncol=2)\n",
    "    ax1.set_title('Calibration Plots (Reliability Curve)')\n",
    "\n",
    "    ax2.set_xlabel('Predicted scores')\n",
    "    ax2.set_ylabel('Count')\n",
    "    ax2.set_title('Histogram of Predicted Scores')\n",
    "    ax2.legend(loc='upper right', ncol=2)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if show:\n",
    "        plt.show()\n",
    "\n",
    "    if save_plot_path is not None:\n",
    "        save_dir = os.path.dirname(save_plot_path)\n",
    "        if save_dir:\n",
    "            os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "        fig.savefig(save_plot_path, dpi=300, bbox_inches='tight')\n",
    "\n",
    "    plt.close(fig)\n",
    "\n",
    "    df_metrics = pd.DataFrame(estimator_metrics)\n",
    "    return df_metrics\n",
    "\n",
    "\n",
    "def underestimation_score_1(y_true,y_pred,SA):\n",
    "\n",
    "    mydict = {}\n",
    "    mydict['actual'] = y_true\n",
    "    mydict['predicted'] = y_pred\n",
    "    mydict['sex'] = SA\n",
    "    us = pd.DataFrame(mydict)\n",
    "\n",
    "    P_dash_FX0 = df_count_feat_val_match(us, 'predicted', 1, 'sex',1)\n",
    "    P_FX0 = df_count_feat_val_match(us, 'actual', 1, 'sex',1)\n",
    "\n",
    "\n",
    "    if P_FX0 == 0:\n",
    "        print(\"Divsion by zero detected: denom is \",P_FX0)\n",
    "        return 0.000001\n",
    "    print(P_dash_FX0,P_FX0)\n",
    "    return P_dash_FX0/P_FX0\n",
    "\n",
    "def underestimation_score(y_true,y_pred,SA):\n",
    "\n",
    "    mydict = {}\n",
    "    mydict['actual'] = y_true\n",
    "    mydict['predicted'] = y_pred\n",
    "    mydict['sex'] = SA\n",
    "    us = pd.DataFrame(mydict)\n",
    "\n",
    "    P_dash_FX0 = df_count_feat_val_match(us, 'predicted', 1, 'sex',0)\n",
    "    P_FX0 = df_count_feat_val_match(us, 'actual', 1, 'sex',0)\n",
    "    if P_FX0 == 0:\n",
    "        print(\"Divsion by zero detected: denom is \",P_FX0)\n",
    "        return 0.000001\n",
    "    print(P_dash_FX0,P_FX0)\n",
    "    return P_dash_FX0/P_FX0\n",
    "\n",
    "def UEI(sa, Y_train, Y_pred):\n",
    "    us_df = {}\n",
    "    us_df['sa'] = sa\n",
    "    us_df['ytrain_actual'] = Y_train\n",
    "    us_df['ytest_pred'] = Y_pred\n",
    "    us_df = pd.DataFrame(us_df)\n",
    "\n",
    "    prob_array = []\n",
    "    for y in (0,1):\n",
    "        for s in (0,1):\n",
    "#             print((y,s))\n",
    "            p_tilda = df_count_feat_val_match(us_df, 'ytrain_actual', y, 'sa',s)/len(us_df)\n",
    "            p_hat = df_count_feat_val_match(us_df, 'ytest_pred', y, 'sa',s)/len(us_df)\n",
    "#             print(p_hat,p_tilda)\n",
    "            prob_array.append(   np.square(np.sqrt(p_hat)-np.sqrt(p_tilda))    )\n",
    "    return np.sqrt(0.5*np.sum(prob_array))\n",
    "\n",
    "def df_count_feat_val_match(df1, f1, v1, f2, v2):\n",
    "    return len (df1[(df1[f1]==int(v1)) & (df1[f2]==int(v2))])\n",
    "\n",
    "\n",
    "import os\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from sklearn.utils import check_consistent_length, column_or_1d\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "\n",
    "__all__ = [\n",
    "    'compute_calibration_error',\n",
    "    'create_binned_data',\n",
    "    'get_bin_boundaries',\n",
    "    'compute_binary_score',\n",
    "    'compute_calibration_summary',\n",
    "]\n",
    "\n",
    "\n",
    "def compute_calibration_error(\n",
    "    y_true: np.ndarray,\n",
    "    y_prob: np.ndarray,\n",
    "    n_bins: int=15,\n",
    "    round_digits: int=4) -> float:\n",
    "    \"\"\"\n",
    "    Computes the calibration error for binary classification via binning\n",
    "    data points into the specified number of bins. Samples with similar\n",
    "    ``y_prob`` will be grouped into the same bin. The bin boundary is\n",
    "    determined by having similar number of samples within each bin.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : 1d ndarray\n",
    "        Binary true targets.\n",
    "\n",
    "    y_prob : 1d ndarray\n",
    "        Raw probability/score of the positive class.\n",
    "\n",
    "    n_bins : int, default 15\n",
    "        A bigger bin number requires more data. In general,\n",
    "        the larger the bin size, the closer the calibration error\n",
    "        will be to the true calibration error.\n",
    "\n",
    "    round_digits : int, default 4\n",
    "        Round the calibration error metric.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    calibration_error : float\n",
    "        RMSE between the average positive label and predicted probability\n",
    "        within each bin.\n",
    "    \"\"\"\n",
    "    y_true = column_or_1d(y_true)\n",
    "    y_prob = column_or_1d(y_prob)\n",
    "    check_consistent_length(y_true, y_prob)\n",
    "\n",
    "    binned_y_true, binned_y_prob = create_binned_data(y_true, y_prob, n_bins)\n",
    "\n",
    "    # looping shouldn't be a source of bottleneck as n_bins should be a small number.\n",
    "    bin_errors = 0.0\n",
    "    for bin_y_true, bin_y_prob in zip(binned_y_true, binned_y_prob):\n",
    "        avg_y_true = np.mean(bin_y_true)\n",
    "        avg_y_score = np.mean(bin_y_prob)\n",
    "        bin_error = (avg_y_score - avg_y_true) ** 2\n",
    "        bin_errors += bin_error * len(bin_y_true)\n",
    "\n",
    "    calibration_error = math.sqrt(bin_errors / len(y_true))\n",
    "    return round(calibration_error, round_digits)\n",
    "\n",
    "\n",
    "def create_binned_data(\n",
    "    y_true: np.ndarray,\n",
    "    y_prob: np.ndarray,\n",
    "    n_bins: int) -> Tuple[List[np.ndarray], List[np.ndarray]]:\n",
    "    \"\"\"\n",
    "    Bin ``y_true`` and ``y_prob`` by distribution of the data.\n",
    "    i.e. each bin will contain approximately an equal number of\n",
    "    data points. Bins are sorted based on ascending order of ``y_prob``.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : 1d ndarray\n",
    "        Binary true targets.\n",
    "\n",
    "    y_prob : 1d ndarray\n",
    "        Raw probability/score of the positive class.\n",
    "\n",
    "    n_bins : int, default 15\n",
    "        A bigger bin number requires more data.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    binned_y_true/binned_y_prob : 1d ndarray\n",
    "        Each element in the list stores the data for that bin.\n",
    "    \"\"\"\n",
    "    sorted_indices = np.argsort(y_prob)\n",
    "    sorted_y_true = y_true[sorted_indices]\n",
    "    sorted_y_prob = y_prob[sorted_indices]\n",
    "    binned_y_true = np.array_split(sorted_y_true, n_bins)\n",
    "    binned_y_prob = np.array_split(sorted_y_prob, n_bins)\n",
    "    return binned_y_true, binned_y_prob\n",
    "\n",
    "\n",
    "def get_bin_boundaries(binned_y_prob: List[np.ndarray]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Given ``binned_y_prob`` from ``create_binned_data`` get the\n",
    "    boundaries for each bin.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    binned_y_prob : list\n",
    "        Each element in the list stores the data for that bin.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bins : 1d ndarray\n",
    "        Boundaries for each bin.\n",
    "    \"\"\"\n",
    "    bins = []\n",
    "    for i in range(len(binned_y_prob) - 1):\n",
    "        last_prob = binned_y_prob[i][-1]\n",
    "        next_first_prob = binned_y_prob[i + 1][0]\n",
    "        bins.append((last_prob + next_first_prob) / 2.0)\n",
    "\n",
    "    bins.append(1.0)\n",
    "    return np.array(bins)\n",
    "\n",
    "\n",
    "def compute_binary_score(\n",
    "    y_true: np.ndarray,\n",
    "    y_prob: np.ndarray,\n",
    "    round_digits: int=4) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Compute various evaluation metrics for binary classification.\n",
    "    Including auc, precision, recall, f1, log loss, brier score. The\n",
    "    threshold for precision and recall numbers are based on the one\n",
    "    that gives the best f1 score.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : 1d ndarray\n",
    "        Binary true targets.\n",
    "\n",
    "    y_prob : 1d ndarray\n",
    "        Raw probability/score of the positive class.\n",
    "\n",
    "    round_digits : int, default 4\n",
    "        Round the evaluation metric.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    metrics_dict : dict\n",
    "        Metrics are stored in key value pair. ::\n",
    "\n",
    "        {\n",
    "            'auc': 0.82,\n",
    "            'precision': 0.56,\n",
    "            'recall': 0.61,\n",
    "            'f1': 0.59,\n",
    "            'log_loss': 0.42,\n",
    "            'brier': 0.12\n",
    "        }\n",
    "    \"\"\"\n",
    "    auc = round(metrics.roc_auc_score(y_true, y_prob), round_digits)\n",
    "    log_loss = round(metrics.log_loss(y_true, y_prob), round_digits)\n",
    "    brier_score = round(metrics.brier_score_loss(y_true, y_prob), round_digits)\n",
    "\n",
    "    precision, recall, threshold = metrics.precision_recall_curve(y_true, y_prob)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    mask = ~np.isnan(f1)\n",
    "    f1 = f1[mask]\n",
    "    precision = precision[mask]\n",
    "    recall = recall[mask]\n",
    "\n",
    "    best_index = np.argmax(f1)\n",
    "    precision = round(precision[best_index], round_digits)\n",
    "    recall = round(recall[best_index], round_digits)\n",
    "    f1 = round(f1[best_index], round_digits)\n",
    "    return {\n",
    "        'auc': auc,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'log_loss': log_loss,\n",
    "        'brier': brier_score\n",
    "    }\n",
    "\n",
    "\n",
    "def compute_calibration_summary(\n",
    "    eval_dict: Dict[str, pd.DataFrame],\n",
    "    label_col: str='label',\n",
    "    score_col: str='score',\n",
    "    n_bins: int=15,\n",
    "    strategy: str='quantile',\n",
    "    round_digits: int=4,\n",
    "    show: bool=True,\n",
    "    save_plot_path: Optional[str]=None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Plots the calibration curve and computes the summary statistics for the model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    eval_dict : dict\n",
    "        We can evaluate multiple calibration model's performance in one go. The key\n",
    "        is the model name used to distinguish different calibration model, the value\n",
    "        is the dataframe that stores the binary true targets and the predicted score\n",
    "        for the positive class.\n",
    "\n",
    "    label_col : str\n",
    "        Column name for the dataframe in ``eval_dict`` that stores the binary true targets.\n",
    "\n",
    "    score_col : str\n",
    "        Column name for the dataframe in ``eval_dict`` that stores the predicted score.\n",
    "\n",
    "    n_bins : int, default 15\n",
    "        Number of bins to discretize the calibration curve plot and calibration error statistics.\n",
    "        A bigger number requires more data, but will be closer to the true calibration error.\n",
    "\n",
    "    strategy : {'uniform', 'quantile'}, default 'quantile'\n",
    "        Strategy used to define the boundary of the bins.\n",
    "\n",
    "        - uniform: The bins have identical widths.\n",
    "        - quantile: The bins have the same number of samples and depend on the predicted score.\n",
    "\n",
    "    round_digits : default 4\n",
    "        Round the evaluation metric.\n",
    "\n",
    "    show : bool, default True\n",
    "        Whether to show the plots on the console or jupyter notebook.\n",
    "\n",
    "    save_plot_path : str, default None\n",
    "        Path where we'll store the calibration plot. None means it will not save the plot.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df_metrics : pd.DataFrame\n",
    "        Corresponding metrics for all the input dataframe.\n",
    "    \"\"\"\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(2)\n",
    "\n",
    "    # estimator_metrics stores list of dict, e.g.\n",
    "    # [{'auc': 0.776, 'name': 'xgb'}]\n",
    "    estimator_metrics = []\n",
    "    for name, df_eval in eval_dict.items():\n",
    "        prob_true, prob_pred = calibration_curve(\n",
    "            df_eval[label_col],\n",
    "            df_eval[score_col],\n",
    "            n_bins=n_bins,\n",
    "            strategy=strategy)\n",
    "\n",
    "        calibration_error = compute_calibration_error(\n",
    "            df_eval[label_col], df_eval[score_col], n_bins, round_digits)\n",
    "        metrics_dict = compute_binary_score(df_eval[label_col], df_eval[score_col], round_digits)\n",
    "        metrics_dict['calibration_error'] = calibration_error\n",
    "        metrics_dict['name'] = name\n",
    "        estimator_metrics.append(metrics_dict)\n",
    "\n",
    "        ax1.plot(prob_pred, prob_true, 's-', label=name)\n",
    "        ax2.hist(df_eval[score_col], range=(0, 1), bins=n_bins, label=name, histtype='step', lw=2)\n",
    "\n",
    "    ax1.plot([0, 1], [0, 1], 'k:', label='perfect')\n",
    "\n",
    "    ax1.set_xlabel('Fraction of positives (Predicted)')\n",
    "    ax1.set_ylabel('Fraction of positives (Actual)')\n",
    "    ax1.set_ylim([-0.05, 1.05])\n",
    "    ax1.legend(loc='upper left', ncol=2)\n",
    "    ax1.set_title('Calibration Plots (Reliability Curve)')\n",
    "\n",
    "    ax2.set_xlabel('Predicted scores')\n",
    "    ax2.set_ylabel('Count')\n",
    "    ax2.set_title('Histogram of Predicted Scores')\n",
    "    ax2.legend(loc='upper right', ncol=2)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if show:\n",
    "        plt.show()\n",
    "\n",
    "    if save_plot_path is not None:\n",
    "        save_dir = os.path.dirname(save_plot_path)\n",
    "        if save_dir:\n",
    "            os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "        fig.savefig(save_plot_path, dpi=300, bbox_inches='tight')\n",
    "\n",
    "    plt.close(fig)\n",
    "\n",
    "    df_metrics = pd.DataFrame(estimator_metrics)\n",
    "    return df_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Recidivism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Deep Ensembles Model~~~~~~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:32<00:00,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/68 [..............................] - ETA: 10s - loss: 0.6139 - accuracy: 0.7188"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 0s 1ms/step - loss: 0.6082 - accuracy: 0.6855\n",
      "Test results - Loss: 0.6081584692001343 - Accuracy: 0.6854503750801086%\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.6055 - accuracy: 0.6905\n",
      "Test results - Loss: 0.6055217981338501 - Accuracy: 0.6905311942100525%\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.6060 - accuracy: 0.6896\n",
      "Test results - Loss: 0.6060453057289124 - Accuracy: 0.6896073818206787%\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.6064 - accuracy: 0.6887\n",
      "Test results - Loss: 0.6064422130584717 - Accuracy: 0.6886836290359497%\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.6070 - accuracy: 0.6905\n",
      "Test results - Loss: 0.6069598197937012 - Accuracy: 0.6905311942100525%\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.6095 - accuracy: 0.6864\n",
      "Test results - Loss: 0.6094592809677124 - Accuracy: 0.6863741278648376%\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.6050 - accuracy: 0.6878\n",
      "Test results - Loss: 0.6050091981887817 - Accuracy: 0.6877598166465759%\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.6062 - accuracy: 0.6887\n",
      "Test results - Loss: 0.6062184572219849 - Accuracy: 0.6886836290359497%\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.6071 - accuracy: 0.6873\n",
      "Test results - Loss: 0.6070865988731384 - Accuracy: 0.6872979402542114%\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.6054 - accuracy: 0.6878\n",
      "Test results - Loss: 0.6053617000579834 - Accuracy: 0.6877598166465759%\n",
      "######################################################\n",
      " Loss    : 0.606626284122467 - 0.0012910603337691947\n",
      " Accuracy: 0.6882679104804993 - 0.001592696237285618%\n",
      "Deep Ensembles trained!!!~~~~~~~\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training standard NN Model~~~~~~~\n",
      "Epoch 1/60\n",
      "51/51 [==============================] - 1s 1ms/step - loss: 0.6341 - accuracy: 0.6445\n",
      "Epoch 2/60\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.6153 - accuracy: 0.6673\n",
      "Epoch 3/60\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.6147 - accuracy: 0.6710\n",
      "Epoch 4/60\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.6152 - accuracy: 0.6688\n",
      "Epoch 5/60\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.6120 - accuracy: 0.6692\n",
      "Epoch 6/60\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.6150 - accuracy: 0.6649\n",
      "Epoch 7/60\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.6118 - accuracy: 0.6716\n",
      "Epoch 8/60\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.6127 - accuracy: 0.6671\n",
      "Epoch 9/60\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.6113 - accuracy: 0.6677\n",
      "Epoch 10/60\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.6103 - accuracy: 0.6736\n",
      "Epoch 11/60\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.6091 - accuracy: 0.6673\n",
      "Epoch 12/60\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.6080 - accuracy: 0.6710\n",
      "Epoch 13/60\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.6074 - accuracy: 0.6748\n",
      "Epoch 14/60\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.6080 - accuracy: 0.6776\n",
      "Epoch 15/60\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.6070 - accuracy: 0.6756\n",
      "Epoch 16/60\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.6074 - accuracy: 0.6730\n",
      "Epoch 17/60\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.6076 - accuracy: 0.6730\n",
      "Epoch 18/60\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.6079 - accuracy: 0.6726\n",
      "Epoch 19/60\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.6096 - accuracy: 0.6704\n",
      "Epoch 20/60\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.6061 - accuracy: 0.6766\n",
      "Epoch 21/60\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.6043 - accuracy: 0.6782\n",
      "Epoch 22/60\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.6038 - accuracy: 0.6782\n",
      "Epoch 23/60\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.6036 - accuracy: 0.6807\n",
      "Epoch 24/60\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.6038 - accuracy: 0.6803\n",
      "Epoch 25/60\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.6023 - accuracy: 0.6766\n",
      "Epoch 26/60\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.6027 - accuracy: 0.6762\n",
      "Epoch 27/60\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.6030 - accuracy: 0.6766\n",
      "Epoch 28/60\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.6026 - accuracy: 0.6780\n",
      "Epoch 29/60\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.6022 - accuracy: 0.6823\n",
      "Epoch 30/60\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.6017 - accuracy: 0.6768\n",
      "Epoch 31/60\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.6036 - accuracy: 0.6803\n",
      "Epoch 32/60\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.6032 - accuracy: 0.6756\n",
      "Epoch 33/60\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.6023 - accuracy: 0.6797\n",
      "Epoch 34/60\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.6036 - accuracy: 0.6786\n",
      "Epoch 35/60\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.6056 - accuracy: 0.6758\n",
      "Epoch 36/60\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.6029 - accuracy: 0.6780\n",
      "Epoch 37/60\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.6007 - accuracy: 0.6805\n",
      "Epoch 38/60\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.6016 - accuracy: 0.6748\n",
      "Epoch 39/60\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.6013 - accuracy: 0.6791\n",
      "Epoch 40/60\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.6007 - accuracy: 0.6795\n",
      "Epoch 41/60\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.6019 - accuracy: 0.6740\n",
      "Epoch 42/60\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.6005 - accuracy: 0.6770\n",
      "Epoch 43/60\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.6026 - accuracy: 0.6744\n",
      "Epoch 44/60\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.6014 - accuracy: 0.6736\n",
      "Epoch 45/60\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.5992 - accuracy: 0.6787\n",
      "Epoch 46/60\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.5989 - accuracy: 0.6819\n",
      "Epoch 47/60\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.6017 - accuracy: 0.6754\n",
      "Epoch 48/60\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.6002 - accuracy: 0.6744\n",
      "Epoch 49/60\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.6013 - accuracy: 0.6797\n",
      "Epoch 50/60\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.5997 - accuracy: 0.6774\n",
      "Epoch 51/60\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.5997 - accuracy: 0.6766\n",
      "Epoch 52/60\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.6022 - accuracy: 0.6825\n",
      "Epoch 53/60\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.6013 - accuracy: 0.6795\n",
      "Epoch 54/60\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.6009 - accuracy: 0.6797\n",
      "Epoch 55/60\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.6020 - accuracy: 0.6803\n",
      "Epoch 56/60\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.6005 - accuracy: 0.6789\n",
      "Epoch 57/60\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.5983 - accuracy: 0.6807\n",
      "Epoch 58/60\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.5980 - accuracy: 0.6813\n",
      "Epoch 59/60\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.6007 - accuracy: 0.6791\n",
      "Epoch 60/60\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.5978 - accuracy: 0.6770\n",
      "Standard NN trained!!!~~~~~~~\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Recidivism Dataset\n",
    "df = pd.read_csv(\"recidivism.csv\")\n",
    "df.pop('Unnamed: 0')\n",
    "df.head()\n",
    "\n",
    "y = df['Recid2Y'].values\n",
    "df.pop('Recid2Y')\n",
    "X = df\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,\n",
    "                                                    shuffle = True, random_state=40, stratify = y)\n",
    "Xtrain_num = X_train[['age','juv_fel_count','juv_misd_count','priors_count']]\n",
    "x_train_cat = X_train[['Gender','Felony','Caucasian']]\n",
    "Xtest_num = X_test[['age','juv_fel_count','juv_misd_count','priors_count']]\n",
    "x_test_cat = X_test[['Gender','Felony','Caucasian']]\n",
    "\n",
    "stdscl = StandardScaler()\n",
    "Xtrain_num = stdscl.fit_transform(Xtrain_num)\n",
    "Xtest_num = stdscl.transform(Xtest_num)\n",
    "\n",
    "Xtrain = np.hstack((Xtrain_num,x_train_cat))\n",
    "Xtest = np.hstack((Xtest_num,x_test_cat))\n",
    "\n",
    "## Train Deep Ensembles Model\n",
    "print(\"Training Deep Ensembles Model~~~~~~~\")\n",
    "histories,trained_models = train(Xtrain, np.array(y_train).reshape(-1,1), epochs=60, batch=100)\n",
    "losses,accuracies = model_eval(Xtest,np.array(y_test).reshape(-1,1),trained_models)\n",
    "print(\"Deep Ensembles trained!!!~~~~~~~\")\n",
    "print(\"\\n\\n\\n\\n\\n\")\n",
    "## Train standard NN\n",
    "print(\"Training standard NN Model~~~~~~~\")\n",
    "DNN_model = Sequential([\n",
    "            Dense(50,activation='sigmoid'),\n",
    "            Dense(1,activation='sigmoid')])\n",
    "DNN_model.compile(tf.keras.optimizers.Adam(learning_rate=0.01), loss=nll1,metrics=[\"accuracy\"])\n",
    "DNN_model.fit(Xtrain, np.array(y_train).reshape(-1,1), epochs=60, batch_size=100)\n",
    "print(\"Standard NN trained!!!~~~~~~~\")\n",
    "print(\"\\n\\n\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 0s 1ms/step - loss: 0.6083 - accuracy: 0.6831\n",
      "Test results - Loss: 0.6083477735519409 - Accuracy: 0.6831408739089966%\n",
      "ECE with n_bins = 5:\n",
      "ECE_DeepEnsembles:  0.0277\n",
      "ECE_StandardNN   :  0.0513\n",
      "UEI: \n",
      "UEI_DeepEnsembles:  0.06750998641992328\n",
      "UEI_StandardNN   :  0.10452858128745272\n",
      "US_0: \n",
      "172 270\n",
      "US0_DeepEnsembles:  0.6370370370370371\n",
      "139 270\n",
      "US0_StandardNN   :  0.5148148148148148\n",
      "US_1: \n",
      "631 706\n",
      "US1_DeepEnsembles:  0.8937677053824362\n",
      "549 706\n",
      "US1_StandardNN   :  0.7776203966005666\n"
     ]
    }
   ],
   "source": [
    "y_probs_combined = np.stack([model(Xtest) for model in trained_models])\n",
    "y_preds_combined = np.mean(y_probs_combined, axis=0)\n",
    "\n",
    "\n",
    "# Test the model after training\n",
    "test_results = DNN_model.evaluate(Xtest, np.array(y_test).reshape(-1,1), verbose=1)\n",
    "print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]}%')\n",
    "y_pred_1NN = DNN_model(Xtest)\n",
    "\n",
    "df = {}\n",
    "df['sa'] = Xtest[:,-1]\n",
    "df['actual'] = y_test\n",
    "df['Ensembles'] = y_preds_combined.ravel()\n",
    "df['DNN'] = np.array(y_pred_1NN).ravel()\n",
    "df = pd.DataFrame(df)\n",
    "\n",
    "print(\"ECE with n_bins = 5:\")\n",
    "print(\"ECE_DeepEnsembles: \",compute_calibration_error(np.array(y_test),y_preds_combined,n_bins=5))\n",
    "print(\"ECE_StandardNN   : \",compute_calibration_error(np.array(y_test),y_pred_1NN,n_bins=5))\n",
    "\n",
    "\n",
    "\n",
    "print(\"UEI: \")\n",
    "print(\"UEI_DeepEnsembles: \",UEI(df.sa.values, df.actual.values, np.round(df['Ensembles'].values)))\n",
    "print(\"UEI_StandardNN   : \",UEI(df.sa.values, df.actual.values, np.round(df['DNN'].values)))\n",
    "\n",
    "print(\"US_0: \")\n",
    "print(\"US0_DeepEnsembles: \",underestimation_score_1(df.actual.values, np.round(df['Ensembles'].values),df.sa.values))\n",
    "print(\"US0_StandardNN   : \",underestimation_score_1(df.actual.values, np.round(df['DNN'].values),df.sa.values))\n",
    "\n",
    "print(\"US_1: \")\n",
    "print(\"US1_DeepEnsembles: \",underestimation_score(df.actual.values, np.round(df['Ensembles'].values),df.sa.values))\n",
    "print(\"US1_StandardNN   : \",underestimation_score(df.actual.values, np.round(df['DNN'].values),df.sa.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECE with n_bins = 5:\n",
      "ECE_DeepEnsembles_Maj:  0.0287\n",
      "ECE_DeepEnsembles_Min   :  0.0215\n",
      "ECE with n_bins = 5:\n",
      "ECE_DeepEnsembles_Maj:  0.0584\n",
      "ECE_DeepEnsembles_Min   :  0.0264\n"
     ]
    }
   ],
   "source": [
    "from sklearn.calibration import calibration_curve\n",
    "prob_true, prob_pred = calibration_curve(y_test, y_preds_combined, n_bins=5)\n",
    "prob_true_dnn, prob_pred_dnn = calibration_curve(y_test, y_pred_1NN, n_bins=5)\n",
    "minority = df[df['sa'] == 1]\n",
    "majority = df[df['sa'] == 0]\n",
    "prob_true_maj, prob_pred_maj = calibration_curve(np.array(majority.actual), majority['Ensembles'].values.reshape(-1,1), n_bins=5)\n",
    "prob_true_min, prob_pred_min = calibration_curve(np.array(minority.actual), minority['Ensembles'].values.reshape(-1,1), n_bins=5)\n",
    "prob_true_dnn_maj, prob_pre_dnnd_maj = calibration_curve(np.array(majority.actual), majority['DNN'].values.reshape(-1,1), n_bins=5)\n",
    "prob_true_dnn_min, prob_pred_dnn_min = calibration_curve(np.array(minority.actual), minority['DNN'].values.reshape(-1,1), n_bins=5)\n",
    "\n",
    "print(\"ECE with n_bins = 5:\")\n",
    "print(\"ECE_DeepEnsembles_Maj: \",compute_calibration_error(np.array(majority.actual), majority['Ensembles'].values.reshape(-1,1), n_bins=5))\n",
    "print(\"ECE_DeepEnsembles_Min   : \",compute_calibration_error(np.array(minority.actual), minority['Ensembles'].values.reshape(-1,1), n_bins=5))\n",
    "\n",
    "print(\"ECE with n_bins = 5:\")\n",
    "print(\"ECE_DeepEnsembles_Maj: \",compute_calibration_error(np.array(majority.actual), majority['DNN'].values.reshape(-1,1), n_bins=5))\n",
    "print(\"ECE_DeepEnsembles_Min   : \",compute_calibration_error(np.array(minority.actual), minority['DNN'].values.reshape(-1,1), n_bins=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Calibration plot for Deep Ensembles V.S Standard NN: we see that deep ensembles method gives more calibrated probability estimates\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.transforms as mtransforms\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "# only these two lines are calibration curves\n",
    "plt.plot(prob_true, prob_pred, marker='o', linewidth=1, label='Deep Ensemble')\n",
    "plt.plot(prob_true_dnn, prob_pred_dnn, marker='x', linewidth=1, label='Standard NN')\n",
    "# reference line, legends, and axis labels\n",
    "line = mlines.Line2D([0, 1], [0, 1], color='black')\n",
    "transform = ax.transAxes\n",
    "line.set_transform(transform)\n",
    "ax.add_line(line)\n",
    "fig.suptitle('Calibration plot: Recidivism')\n",
    "ax.set_xlabel('Predicted probability')\n",
    "ax.set_ylabel('True probability in each bin')\n",
    "plt.legend()\n",
    "plt.savefig(\"calib_plot_recid.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Calibration plot for Deep Ensembles in terms of majority and minority group\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "# only these two lines are calibration curves\n",
    "plt.plot(prob_true, prob_pred, marker='o', linewidth=1, label='Deep Ensemble')\n",
    "plt.plot(prob_true_maj, prob_pred_maj, marker='o', linewidth=1, label='Deep Ensemble_Majority')\n",
    "plt.plot(prob_true_min, prob_pred_min, marker='o', linewidth=1, label='Deep Ensemble_Minority')\n",
    "plt.plot(prob_true_dnn, prob_pred_dnn, marker='x', linewidth=0.5, linestyle = \"--\", color='red',label='StandardNN')\n",
    "\n",
    "# reference line, legends, and axis labels\n",
    "line = mlines.Line2D([0, 1], [0, 1], color='black')\n",
    "transform = ax.transAxes\n",
    "line.set_transform(transform)\n",
    "ax.add_line(line)\n",
    "fig.suptitle('Calibration plot: Deep Ensembles')\n",
    "ax.set_xlabel('Predicted probability')\n",
    "ax.set_ylabel('True probability in each bin')\n",
    "ax.set_xlim(0,1)\n",
    "ax.set_ylim(0,1)\n",
    "plt.legend()\n",
    "plt.savefig(\"calib_plot_recid.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Calibration plot for Standard NN in terms of majority and minority group\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.plot(prob_true_dnn, prob_pred_dnn, marker='x', linewidth=1, label='StandardNN')\n",
    "plt.plot(prob_true_dnn_maj, prob_pre_dnnd_maj, marker='x', linewidth=1, label='StandardNN_Minority')\n",
    "plt.plot(prob_true_dnn_min, prob_pred_dnn_min, marker='x', linewidth=1, label='StandardNN_Majority')\n",
    "\n",
    "\n",
    "# reference line, legends, and axis labels\n",
    "line = mlines.Line2D([0, 1], [0, 1], color='black')\n",
    "transform = ax.transAxes\n",
    "line.set_transform(transform)\n",
    "ax.add_line(line)\n",
    "fig.suptitle('Calibration plot: Recid (Point Estimates)')\n",
    "ax.set_xlabel('Predicted probability')\n",
    "ax.set_ylabel('True probability in each bin')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "c = {}\n",
    "c['Predicted Probability'] = df['Ensembles']\n",
    "c['sex'] = Xtest[:,-1]\n",
    "c = pd.DataFrame(c)\n",
    "sns.kdeplot(data=c,x='Predicted Probability',hue='sex',multiple='layer',legend=False,palette=[\"green\", \"orange\"],shade=True)\n",
    "sns.kdeplot(data=c,x='Predicted Probability',shade=True)\n",
    "plt.legend(title='Sensitive Attribute', loc='upper right', labels=['Minority', 'Majority','Overall'],fontsize=14)\n",
    "plt.xlabel('Predicted Probability', fontsize=14);\n",
    "plt.ylabel('Density', fontsize=14);\n",
    "# plt.title(\"PDF: Recidivism\")\n",
    "plt.savefig('kde.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best threshold for s=0 that minimizes P(Y|S) - P(Yhat|S) is:  0.48484848484848486\n",
      "best threshold for s=1 that minimizes P(Y|S) - P(Yhat|S) is:  0.4141414141414142\n",
      "Train:\n",
      "0.6777579718756189 0.5963468651744157 0.0052915163942326435\n",
      "Test:\n",
      "0.6803695150115473 0.6054995353998268 0.019269002068436177\n",
      "US_S_0\n",
      "659 706\n",
      "0.93342776203966\n",
      "US_S_1\n",
      "263 270\n",
      "0.9740740740740741\n"
     ]
    }
   ],
   "source": [
    "## Post-processing\n",
    "\n",
    "def find_thres(group,clf_prob,truth):\n",
    "    ls_0 = {}\n",
    "    ls_1 = {}\n",
    "    thresholds = np.linspace(0, 1, num=100)\n",
    "    for thres in thresholds:\n",
    "        df = {}\n",
    "        df['sa'] = group\n",
    "        df['prob'] = clf_prob\n",
    "        df['ground_truth'] = truth\n",
    "        df['prob_pred'] =[0]*truth\n",
    "        df = pd.DataFrame(df)\n",
    "        df.loc[ (df['sa'] == 0) & (df['prob'] > thres),'prob_pred'] = 1\n",
    "        df.loc[ (df['sa'] == 1) & (df['prob'] > thres),'prob_pred'] = 1\n",
    "        US_pred_0 = df_count_feat_val_match(df, 'prob_pred', 1, 'sa',0)\n",
    "        US_true_0 = df_count_feat_val_match(df, 'ground_truth', 1, 'sa',0)\n",
    "        US_pred_1 = df_count_feat_val_match(df, 'prob_pred', 1, 'sa',1)\n",
    "        US_true_1 = df_count_feat_val_match(df, 'ground_truth', 1, 'sa',1)\n",
    "        ls_0[thres] = np.abs(US_pred_0-US_true_0)\n",
    "        ls_1[thres] = np.abs(US_pred_1-US_true_1)\n",
    "    best_0 = thresholds[np.argmin(list(ls_0.values()))]\n",
    "    best_1 = thresholds[np.argmin(list(ls_1.values()))]\n",
    "    print(\"best threshold for s=0 that minimizes P(Y|S) - P(Yhat|S) is: \",best_0)\n",
    "    print(\"best threshold for s=1 that minimizes P(Y|S) - P(Yhat|S) is: \",best_1)\n",
    "    return best_0,best_1\n",
    "\n",
    "def make_pred(group,clf_prob,thres_0,thres_1):\n",
    "    y_post = []\n",
    "    for sa,predictproba in zip(group,clf_prob):\n",
    "        if sa == 0 and predictproba > thres_0:\n",
    "            y_post.append(1)\n",
    "        elif sa == 0 and predictproba <= thres_0:\n",
    "            y_post.append(0)\n",
    "        elif sa == 1 and predictproba > thres_1:\n",
    "            y_post.append(1)\n",
    "        else:\n",
    "            y_post.append(0)\n",
    "    return y_post\n",
    "\n",
    "def evaluate(y_true,y_pred,sa):\n",
    "    ## convert the probability estimates to class labels (MC Dropout)\n",
    "\n",
    "    ba = accuracy_score(y_true,y_pred)\n",
    "    us_s = UEI(sa, y_true, np.round(y_pred))\n",
    "    return ba,us_s\n",
    "\n",
    "y_probs_combined = np.stack([model(Xtrain) for model in trained_models])\n",
    "y_preds_combined = np.mean(y_probs_combined, axis=0)\n",
    "best_thres_0,best_thres_1 = find_thres(Xtrain[:,-1],np.array(y_preds_combined.ravel()),y_train)\n",
    "y_pred_post = make_pred(Xtrain[:,-1],np.array(y_preds_combined.ravel()),best_thres_0,best_thres_1)\n",
    "best_ba,best_us = evaluate(y_train,np.array(y_pred_post),Xtrain[:,-1])\n",
    "print(\"Train:\")\n",
    "print(best_ba,nll1(y_train,np.array(y_preds_combined.ravel())).numpy()/Xtrain.shape[0],best_us)\n",
    "## test\n",
    "y_probs_combined = np.stack([model(Xtest) for model in trained_models])\n",
    "y_preds_combined = np.mean(y_probs_combined, axis=0)\n",
    "y_pred_post = make_pred(Xtest[:,-1],np.array(y_preds_combined.ravel()),best_thres_0,best_thres_1)\n",
    "best_ba,best_us = evaluate(y_test,np.array(y_pred_post),Xtest[:,-1])\n",
    "print(\"Test:\")\n",
    "print(best_ba,nll1(y_test,np.array(y_preds_combined.ravel())).numpy()/Xtest.shape[0],best_us)\n",
    "\n",
    "print(\"US_S_0\")\n",
    "print(underestimation_score(y_test,y_pred_post,Xtest[:,-1]))\n",
    "print(\"US_S_1\")\n",
    "print(underestimation_score_1(y_test,y_pred_post,Xtest[:,-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:\n",
      "0.6863741339491917 0.6030774686958719 0.061856008953863555\n",
      "US_S_0\n",
      "651 706\n",
      "0.9220963172804533\n",
      "US_S_1\n",
      "176 270\n",
      "0.6518518518518519\n",
      "ECE with n_bins = 5:\n",
      "ECE_Platt_All:  0.0261\n",
      "ECE_Platt_Maj:  0.0219\n",
      "ECE_Platt_Min   :  0.0265\n"
     ]
    }
   ],
   "source": [
    "##Platt\n",
    "\n",
    "y_probs_combined = np.stack([model(Xtrain) for model in trained_models])\n",
    "y_preds_combined = np.mean(y_probs_combined, axis=0)\n",
    "platt = LogisticRegression(random_state=0)\n",
    "platt.fit(y_preds_combined, y_train)\n",
    "y_probs_combined = np.stack([model(Xtest) for model in trained_models])\n",
    "y_preds_combined = np.mean(y_probs_combined, axis=0)\n",
    "platt_probs = platt.predict_proba(y_preds_combined)[:,1]\n",
    "print(\"Test:\")\n",
    "best_ba,best_us = evaluate(y_test,np.array(np.round(platt_probs)),Xtest[:,-1])\n",
    "print(best_ba,nll1(y_test,np.array(tf.cast(platt_probs, dtype=tf.float32))).numpy()/Xtest.shape[0],best_us)\n",
    "\n",
    "print(\"US_S_0\")\n",
    "print(underestimation_score(y_test,np.round(platt_probs),Xtest[:,-1]))\n",
    "print(\"US_S_1\")\n",
    "print(underestimation_score_1(y_test,np.round(platt_probs),Xtest[:,-1]))\n",
    "\n",
    "from sklearn.calibration import calibration_curve\n",
    "prob_true, prob_pred = calibration_curve(y_test, platt_probs, n_bins=5)\n",
    "df['Platt'] = platt_probs\n",
    "minority = df[df['sa'] == 1]\n",
    "majority = df[df['sa'] == 0]\n",
    "prob_true_maj, prob_pred_maj = calibration_curve(np.array(majority.actual), majority['Platt'].values.reshape(-1,1), n_bins=5)\n",
    "prob_true_min, prob_pred_min = calibration_curve(np.array(minority.actual), minority['Platt'].values.reshape(-1,1), n_bins=5)\n",
    "\n",
    "print(\"ECE with n_bins = 5:\")\n",
    "print(\"ECE_Platt_All: \",compute_calibration_error(np.array(df.actual), df['Platt'].values.reshape(-1,1), n_bins=5))\n",
    "print(\"ECE_Platt_Maj: \",compute_calibration_error(np.array(majority.actual), majority['Platt'].values.reshape(-1,1), n_bins=5))\n",
    "print(\"ECE_Platt_Min   : \",compute_calibration_error(np.array(minority.actual), minority['Platt'].values.reshape(-1,1), n_bins=5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_data =    pd.read_csv(\"http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\",\n",
    "           names = ['age','workclass','fnlwgt','education','education-num','marital-status','occupation',\n",
    "                    'relationship','race','sex','capital-gain','capital-loss','hours-per-week','native-country',\n",
    "                    'salary'])\n",
    "\n",
    "test_data =    pd.read_csv(\"http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test\",\n",
    "          names = ['age','workclass','fnlwgt','education','education-num','marital-status','occupation',\n",
    "                    'relationship','race','sex','capital-gain','capital-loss','hours-per-week','native-country',\n",
    "                    'salary'],\n",
    "          skiprows = 1)\n",
    "\n",
    "y_train = [1 if salary.strip() == \">50K\" else 0 for salary in train_data['salary']]\n",
    "y_test = [1 if salary.strip() == \">50K.\" else 0 for salary in test_data['salary']]\n",
    "Xtest_num = test_data[['age', 'fnlwgt', 'education-num','capital-gain','capital-loss','hours-per-week']]\n",
    "\n",
    "Xtrain_num = train_data[['age', 'fnlwgt', 'education-num','capital-gain','capital-loss','hours-per-week']]\n",
    "\n",
    "stdscl = StandardScaler()\n",
    "Xtrain_num = stdscl.fit_transform(Xtrain_num)\n",
    "Xtest_num = stdscl.transform(Xtest_num)\n",
    "\n",
    "x_test_cat = np.array([1 if gender.strip() == 'Male' else 0 for gender in test_data['sex']]).reshape(-1,1)\n",
    "x_train_cat = np.array([1 if gender.strip() == 'Male' else 0 for gender in train_data['sex']]).reshape(-1,1)\n",
    "\n",
    "Xtrain = np.hstack((Xtrain_num,x_train_cat))\n",
    "Xtest = np.hstack((Xtest_num,x_test_cat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Deep Ensembles Model~~~~~~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [03:57<00:00, 23.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  1/509 [..............................] - ETA: 1:11 - loss: 0.2294 - accuracy: 0.9062"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "509/509 [==============================] - 1s 1ms/step - loss: 0.3621 - accuracy: 0.8358\n",
      "Test results - Loss: 0.36214232444763184 - Accuracy: 0.8358209133148193%\n",
      "509/509 [==============================] - 1s 1ms/step - loss: 0.3626 - accuracy: 0.8317\n",
      "Test results - Loss: 0.36262184381484985 - Accuracy: 0.8317056894302368%\n",
      "509/509 [==============================] - 1s 1ms/step - loss: 0.3638 - accuracy: 0.8342\n",
      "Test results - Loss: 0.3637620806694031 - Accuracy: 0.8342239260673523%\n",
      "509/509 [==============================] - 1s 1ms/step - loss: 0.3625 - accuracy: 0.8326\n",
      "Test results - Loss: 0.36247265338897705 - Accuracy: 0.8325655460357666%\n",
      "509/509 [==============================] - 1s 1ms/step - loss: 0.3620 - accuracy: 0.8340\n",
      "Test results - Loss: 0.3620207607746124 - Accuracy: 0.8339782357215881%\n",
      "509/509 [==============================] - 1s 1ms/step - loss: 0.3624 - accuracy: 0.8349\n",
      "Test results - Loss: 0.36242160201072693 - Accuracy: 0.8348996043205261%\n",
      "509/509 [==============================] - 1s 1ms/step - loss: 0.3633 - accuracy: 0.8331\n",
      "Test results - Loss: 0.3633076548576355 - Accuracy: 0.8330569267272949%\n",
      "509/509 [==============================] - 1s 1ms/step - loss: 0.3618 - accuracy: 0.8337\n",
      "Test results - Loss: 0.36179959774017334 - Accuracy: 0.833732545375824%\n",
      "509/509 [==============================] - 1s 1ms/step - loss: 0.3621 - accuracy: 0.8361\n",
      "Test results - Loss: 0.36213919520378113 - Accuracy: 0.8361279964447021%\n",
      "509/509 [==============================] - 1s 1ms/step - loss: 0.3629 - accuracy: 0.8331\n",
      "Test results - Loss: 0.36286625266075134 - Accuracy: 0.8330569267272949%\n",
      "######################################################\n",
      " Loss    : 0.36255539655685426 - 0.0005786788981004894\n",
      " Accuracy: 0.8339168310165406 - 0.0013344157301615144%\n",
      "Deep Ensembles trained!!!~~~~~~~\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training standard NN Model~~~~~~~\n",
      "Epoch 1/60\n",
      "326/326 [==============================] - 1s 1ms/step - loss: 0.4101 - accuracy: 0.8082\n",
      "Epoch 2/60\n",
      "326/326 [==============================] - 0s 1ms/step - loss: 0.3827 - accuracy: 0.8279\n",
      "Epoch 3/60\n",
      "326/326 [==============================] - 0s 1ms/step - loss: 0.3754 - accuracy: 0.8303\n",
      "Epoch 4/60\n",
      "326/326 [==============================] - 0s 1ms/step - loss: 0.3735 - accuracy: 0.8306\n",
      "Epoch 5/60\n",
      "326/326 [==============================] - 0s 1ms/step - loss: 0.3717 - accuracy: 0.8301\n",
      "Epoch 6/60\n",
      "326/326 [==============================] - 0s 1ms/step - loss: 0.3712 - accuracy: 0.8300\n",
      "Epoch 7/60\n",
      "326/326 [==============================] - 0s 1ms/step - loss: 0.3694 - accuracy: 0.8301\n",
      "Epoch 8/60\n",
      "326/326 [==============================] - 0s 1ms/step - loss: 0.3685 - accuracy: 0.8318\n",
      "Epoch 9/60\n",
      "326/326 [==============================] - 0s 1ms/step - loss: 0.3665 - accuracy: 0.8329\n",
      "Epoch 10/60\n",
      "326/326 [==============================] - 0s 1ms/step - loss: 0.3660 - accuracy: 0.8324\n",
      "Epoch 11/60\n",
      "326/326 [==============================] - 0s 1ms/step - loss: 0.3648 - accuracy: 0.8337\n",
      "Epoch 12/60\n",
      "326/326 [==============================] - 0s 2ms/step - loss: 0.3638 - accuracy: 0.8340\n",
      "Epoch 13/60\n",
      "326/326 [==============================] - 0s 1ms/step - loss: 0.3628 - accuracy: 0.8338\n",
      "Epoch 14/60\n",
      "326/326 [==============================] - 0s 1ms/step - loss: 0.3624 - accuracy: 0.8344\n",
      "Epoch 15/60\n",
      "326/326 [==============================] - 0s 1ms/step - loss: 0.3619 - accuracy: 0.8352\n",
      "Epoch 16/60\n",
      "326/326 [==============================] - 0s 1ms/step - loss: 0.3618 - accuracy: 0.8350\n",
      "Epoch 17/60\n",
      "326/326 [==============================] - 0s 1ms/step - loss: 0.3607 - accuracy: 0.8348\n",
      "Epoch 18/60\n",
      "326/326 [==============================] - 0s 1ms/step - loss: 0.3605 - accuracy: 0.8356\n",
      "Epoch 19/60\n",
      "326/326 [==============================] - 0s 1ms/step - loss: 0.3603 - accuracy: 0.8350\n",
      "Epoch 20/60\n",
      "326/326 [==============================] - 0s 1ms/step - loss: 0.3597 - accuracy: 0.8359\n",
      "Epoch 21/60\n",
      "326/326 [==============================] - 0s 1ms/step - loss: 0.3591 - accuracy: 0.8361\n",
      "Epoch 22/60\n",
      "326/326 [==============================] - 0s 1ms/step - loss: 0.3588 - accuracy: 0.8355\n",
      "Epoch 23/60\n",
      "326/326 [==============================] - 1s 2ms/step - loss: 0.3589 - accuracy: 0.8360\n",
      "Epoch 24/60\n",
      "326/326 [==============================] - 0s 1ms/step - loss: 0.3588 - accuracy: 0.8357\n",
      "Epoch 25/60\n",
      "326/326 [==============================] - 0s 1ms/step - loss: 0.3587 - accuracy: 0.8358\n",
      "Epoch 26/60\n",
      "326/326 [==============================] - 0s 1ms/step - loss: 0.3586 - accuracy: 0.8352\n",
      "Epoch 27/60\n",
      "326/326 [==============================] - 0s 1ms/step - loss: 0.3583 - accuracy: 0.8366\n",
      "Epoch 28/60\n",
      "326/326 [==============================] - 0s 1ms/step - loss: 0.3580 - accuracy: 0.8365\n",
      "Epoch 29/60\n",
      "326/326 [==============================] - 0s 1ms/step - loss: 0.3577 - accuracy: 0.8364\n",
      "Epoch 30/60\n",
      "326/326 [==============================] - 0s 1ms/step - loss: 0.3579 - accuracy: 0.8357\n",
      "Epoch 31/60\n",
      "326/326 [==============================] - 0s 1ms/step - loss: 0.3574 - accuracy: 0.8362\n",
      "Epoch 32/60\n",
      "326/326 [==============================] - 0s 1ms/step - loss: 0.3575 - accuracy: 0.8371\n",
      "Epoch 33/60\n",
      "326/326 [==============================] - 0s 1ms/step - loss: 0.3574 - accuracy: 0.8370\n",
      "Epoch 34/60\n",
      "326/326 [==============================] - 0s 2ms/step - loss: 0.3573 - accuracy: 0.8375\n",
      "Epoch 35/60\n",
      "326/326 [==============================] - 0s 1ms/step - loss: 0.3572 - accuracy: 0.8378\n",
      "Epoch 36/60\n",
      "326/326 [==============================] - 0s 1ms/step - loss: 0.3573 - accuracy: 0.8363\n",
      "Epoch 37/60\n",
      "326/326 [==============================] - 0s 1ms/step - loss: 0.3569 - accuracy: 0.8381\n",
      "Epoch 38/60\n",
      "326/326 [==============================] - 0s 1ms/step - loss: 0.3567 - accuracy: 0.8379\n",
      "Epoch 39/60\n",
      "326/326 [==============================] - 0s 1ms/step - loss: 0.3567 - accuracy: 0.8364\n",
      "Epoch 40/60\n",
      "326/326 [==============================] - 0s 2ms/step - loss: 0.3565 - accuracy: 0.8373\n",
      "Epoch 41/60\n",
      "326/326 [==============================] - 1s 2ms/step - loss: 0.3565 - accuracy: 0.8379\n",
      "Epoch 42/60\n",
      "326/326 [==============================] - 1s 2ms/step - loss: 0.3562 - accuracy: 0.8380\n",
      "Epoch 43/60\n",
      "326/326 [==============================] - 1s 2ms/step - loss: 0.3559 - accuracy: 0.8375\n",
      "Epoch 44/60\n",
      "326/326 [==============================] - 1s 2ms/step - loss: 0.3558 - accuracy: 0.8375\n",
      "Epoch 45/60\n",
      "326/326 [==============================] - 1s 2ms/step - loss: 0.3559 - accuracy: 0.8377\n",
      "Epoch 46/60\n",
      "326/326 [==============================] - 1s 2ms/step - loss: 0.3561 - accuracy: 0.8377\n",
      "Epoch 47/60\n",
      "326/326 [==============================] - 1s 2ms/step - loss: 0.3555 - accuracy: 0.8375\n",
      "Epoch 48/60\n",
      "326/326 [==============================] - 1s 2ms/step - loss: 0.3554 - accuracy: 0.8378\n",
      "Epoch 49/60\n",
      "326/326 [==============================] - 1s 2ms/step - loss: 0.3558 - accuracy: 0.8370\n",
      "Epoch 50/60\n",
      "326/326 [==============================] - 0s 1ms/step - loss: 0.3552 - accuracy: 0.8381\n",
      "Epoch 51/60\n",
      "326/326 [==============================] - 0s 2ms/step - loss: 0.3555 - accuracy: 0.8389\n",
      "Epoch 52/60\n",
      "326/326 [==============================] - 0s 1ms/step - loss: 0.3548 - accuracy: 0.8374\n",
      "Epoch 53/60\n",
      "326/326 [==============================] - 0s 1ms/step - loss: 0.3552 - accuracy: 0.8382\n",
      "Epoch 54/60\n",
      "326/326 [==============================] - 0s 1ms/step - loss: 0.3553 - accuracy: 0.8374\n",
      "Epoch 55/60\n",
      "326/326 [==============================] - 0s 1ms/step - loss: 0.3550 - accuracy: 0.8376\n",
      "Epoch 56/60\n",
      "326/326 [==============================] - 0s 1ms/step - loss: 0.3552 - accuracy: 0.8381\n",
      "Epoch 57/60\n",
      "326/326 [==============================] - 0s 1ms/step - loss: 0.3549 - accuracy: 0.8380\n",
      "Epoch 58/60\n",
      "326/326 [==============================] - 0s 2ms/step - loss: 0.3546 - accuracy: 0.8370\n",
      "Epoch 59/60\n",
      "326/326 [==============================] - 0s 1ms/step - loss: 0.3549 - accuracy: 0.8375\n",
      "Epoch 60/60\n",
      "326/326 [==============================] - 0s 1ms/step - loss: 0.3544 - accuracy: 0.8381\n",
      "Standard NN trained!!!~~~~~~~\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Train Deep Ensembles Model\n",
    "print(\"Training Deep Ensembles Model~~~~~~~\")\n",
    "histories,trained_models = train(Xtrain, np.array(y_train).reshape(-1,1), epochs=60, batch=100)\n",
    "losses,accuracies = model_eval(Xtest,np.array(y_test).reshape(-1,1),trained_models)\n",
    "print(\"Deep Ensembles trained!!!~~~~~~~\")\n",
    "print(\"\\n\\n\\n\\n\\n\")\n",
    "## Train standard NN\n",
    "print(\"Training standard NN Model~~~~~~~\")\n",
    "DNN_model = Sequential([\n",
    "            Dense(50,activation='sigmoid'),\n",
    "            Dense(1,activation='sigmoid')])\n",
    "DNN_model.compile(tf.keras.optimizers.Adam(learning_rate=0.01), loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
    "DNN_model.fit(Xtrain, np.array(y_train).reshape(-1,1), epochs=60, batch_size=100)\n",
    "print(\"Standard NN trained!!!~~~~~~~\")\n",
    "print(\"\\n\\n\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "509/509 [==============================] - 1s 1ms/step - loss: 0.3626 - accuracy: 0.8343\n",
      "Test results - Loss: 0.3626038134098053 - Accuracy: 0.8343467712402344%\n",
      "ECE with n_bins = 5:\n",
      "ECE_DeepEnsembles:  0.0106\n",
      "ECE_StandardNN   :  0.0138\n",
      "UEI: \n",
      "UEI_DeepEnsembles:  0.08144172025451543\n",
      "UEI_StandardNN   :  0.08388944616383547\n",
      "US_0: \n",
      "2382 3256\n",
      "US0_DeepEnsembles:  0.7315724815724816\n",
      "2318 3256\n",
      "US0_StandardNN   :  0.711916461916462\n",
      "US_1: \n",
      "183 590\n",
      "US1_DeepEnsembles:  0.3101694915254237\n",
      "185 590\n",
      "US1_StandardNN   :  0.3135593220338983\n"
     ]
    }
   ],
   "source": [
    "y_probs_combined = np.stack([model(Xtest) for model in trained_models])\n",
    "y_preds_combined = np.mean(y_probs_combined, axis=0)\n",
    "\n",
    "\n",
    "# Test the model after training\n",
    "test_results = DNN_model.evaluate(Xtest, np.array(y_test).reshape(-1,1), verbose=1)\n",
    "print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]}%')\n",
    "y_pred_1NN = DNN_model(Xtest)\n",
    "\n",
    "df = {}\n",
    "df['sa'] = Xtest[:,-1]\n",
    "df['actual'] = y_test\n",
    "df['Ensembles'] = y_preds_combined.ravel()\n",
    "df['DNN'] = np.array(y_pred_1NN).ravel()\n",
    "df = pd.DataFrame(df)\n",
    "\n",
    "print(\"ECE with n_bins = 5:\")\n",
    "print(\"ECE_DeepEnsembles: \",compute_calibration_error(np.array(y_test),y_preds_combined,n_bins=5))\n",
    "print(\"ECE_StandardNN   : \",compute_calibration_error(np.array(y_test),y_pred_1NN,n_bins=5))\n",
    "\n",
    "\n",
    "\n",
    "print(\"UEI: \")\n",
    "print(\"UEI_DeepEnsembles: \",UEI(df.sa.values, df.actual.values, np.round(df['Ensembles'].values)))\n",
    "print(\"UEI_StandardNN   : \",UEI(df.sa.values, df.actual.values, np.round(df['DNN'].values)))\n",
    "\n",
    "print(\"US_0: \")\n",
    "print(\"US0_DeepEnsembles: \",underestimation_score_1(df.actual.values, np.round(df['Ensembles'].values),df.sa.values))\n",
    "print(\"US0_StandardNN   : \",underestimation_score_1(df.actual.values, np.round(df['DNN'].values),df.sa.values))\n",
    "\n",
    "print(\"US_1: \")\n",
    "print(\"US1_DeepEnsembles: \",underestimation_score(df.actual.values, np.round(df['Ensembles'].values),df.sa.values))\n",
    "print(\"US1_StandardNN   : \",underestimation_score(df.actual.values, np.round(df['DNN'].values),df.sa.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECE with n_bins = 5:\n",
      "ECE_DeepEnsembles_Maj:  0.0084\n",
      "ECE_DeepEnsembles_Min   :  0.0124\n",
      "ECE with n_bins = 5:\n",
      "ECE_DNN_Maj:  0.0124\n",
      "ECE_DNN_Min   :  0.0156\n"
     ]
    }
   ],
   "source": [
    "from sklearn.calibration import calibration_curve\n",
    "prob_true, prob_pred = calibration_curve(y_test, y_preds_combined, n_bins=5)\n",
    "prob_true_dnn, prob_pred_dnn = calibration_curve(y_test, y_pred_1NN, n_bins=5)\n",
    "minority = df[df['sa'] == 1]\n",
    "majority = df[df['sa'] == 0]\n",
    "prob_true_maj, prob_pred_maj = calibration_curve(np.array(majority.actual), majority['Ensembles'].values.reshape(-1,1), n_bins=5)\n",
    "prob_true_min, prob_pred_min = calibration_curve(np.array(minority.actual), minority['Ensembles'].values.reshape(-1,1), n_bins=5)\n",
    "prob_true_dnn_maj, prob_pre_dnnd_maj = calibration_curve(np.array(majority.actual), majority['DNN'].values.reshape(-1,1), n_bins=5)\n",
    "prob_true_dnn_min, prob_pred_dnn_min = calibration_curve(np.array(minority.actual), minority['DNN'].values.reshape(-1,1), n_bins=5)\n",
    "\n",
    "print(\"ECE with n_bins = 5:\")\n",
    "print(\"ECE_DeepEnsembles_Maj: \",compute_calibration_error(np.array(majority.actual), majority['Ensembles'].values.reshape(-1,1), n_bins=5))\n",
    "print(\"ECE_DeepEnsembles_Min   : \",compute_calibration_error(np.array(minority.actual), minority['Ensembles'].values.reshape(-1,1), n_bins=5))\n",
    "\n",
    "print(\"ECE with n_bins = 5:\")\n",
    "print(\"ECE_DNN_Maj: \",compute_calibration_error(np.array(majority.actual), majority['DNN'].values.reshape(-1,1), n_bins=5))\n",
    "print(\"ECE_DNN_Min   : \",compute_calibration_error(np.array(minority.actual), minority['DNN'].values.reshape(-1,1), n_bins=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best threshold for s=0 that minimizes P(Y|S) - P(Yhat|S) is:  0.23232323232323235\n",
      "best threshold for s=1 that minimizes P(Y|S) - P(Yhat|S) is:  0.393939393939394\n",
      "Train:\n",
      "0.8249132397653635 0.3509321926537883 0.0017438967309386843\n",
      "Test:\n",
      "0.8140777593513912 0.36074546250230327 0.004303563666249831\n",
      "US_S_0\n",
      "626 590\n",
      "1.0610169491525423\n",
      "US_S_1\n",
      "3261 3256\n",
      "1.0015356265356266\n"
     ]
    }
   ],
   "source": [
    "## Post-processing\n",
    "\n",
    "def find_thres(group,clf_prob,truth):\n",
    "    ls_0 = {}\n",
    "    ls_1 = {}\n",
    "    thresholds = np.linspace(0, 1, num=100)\n",
    "    for thres in thresholds:\n",
    "        df = {}\n",
    "        df['sa'] = group\n",
    "        df['prob'] = clf_prob\n",
    "        df['ground_truth'] = truth\n",
    "        df['prob_pred'] =[0]*len(truth)\n",
    "        df = pd.DataFrame(df)\n",
    "        df.loc[ (df['sa'] == 0) & (df['prob'] > thres),'prob_pred'] = 1\n",
    "        df.loc[ (df['sa'] == 1) & (df['prob'] > thres),'prob_pred'] = 1\n",
    "        US_pred_0 = df_count_feat_val_match(df, 'prob_pred', 1, 'sa',0)\n",
    "        US_true_0 = df_count_feat_val_match(df, 'ground_truth', 1, 'sa',0)\n",
    "        US_pred_1 = df_count_feat_val_match(df, 'prob_pred', 1, 'sa',1)\n",
    "        US_true_1 = df_count_feat_val_match(df, 'ground_truth', 1, 'sa',1)\n",
    "        ls_0[thres] = np.abs(US_pred_0-US_true_0)\n",
    "        ls_1[thres] = np.abs(US_pred_1-US_true_1)\n",
    "    best_0 = thresholds[np.argmin(list(ls_0.values()))]\n",
    "    best_1 = thresholds[np.argmin(list(ls_1.values()))]\n",
    "    print(\"best threshold for s=0 that minimizes P(Y|S) - P(Yhat|S) is: \",best_0)\n",
    "    print(\"best threshold for s=1 that minimizes P(Y|S) - P(Yhat|S) is: \",best_1)\n",
    "    return best_0,best_1\n",
    "\n",
    "def make_pred(group,clf_prob,thres_0,thres_1):\n",
    "    y_post = []\n",
    "    for sa,predictproba in zip(group,clf_prob):\n",
    "        if sa == 0 and predictproba > thres_0:\n",
    "            y_post.append(1)\n",
    "        elif sa == 0 and predictproba <= thres_0:\n",
    "            y_post.append(0)\n",
    "        elif sa == 1 and predictproba > thres_1:\n",
    "            y_post.append(1)\n",
    "        else:\n",
    "            y_post.append(0)\n",
    "    return y_post\n",
    "\n",
    "def evaluate(y_true,y_pred,sa):\n",
    "    ## convert the probability estimates to class labels (MC Dropout)\n",
    "\n",
    "    ba = accuracy_score(y_true,y_pred)\n",
    "    us_s = UEI(sa, y_true, np.round(y_pred))\n",
    "    return ba,us_s\n",
    "\n",
    "y_probs_combined = np.stack([model(Xtrain) for model in trained_models])\n",
    "y_preds_combined = np.mean(y_probs_combined, axis=0)\n",
    "best_thres_0,best_thres_1 = find_thres(Xtrain[:,-1],np.array(y_preds_combined.ravel()),y_train)\n",
    "y_pred_post = make_pred(Xtrain[:,-1],np.array(y_preds_combined.ravel()),best_thres_0,best_thres_1)\n",
    "best_ba,best_us = evaluate(y_train,np.array(y_pred_post),Xtrain[:,-1])\n",
    "print(\"Train:\")\n",
    "print(best_ba,nll1(y_train,np.array(y_preds_combined.ravel())).numpy()/Xtrain.shape[0],best_us)\n",
    "## test\n",
    "y_probs_combined = np.stack([model(Xtest) for model in trained_models])\n",
    "y_preds_combined = np.mean(y_probs_combined, axis=0)\n",
    "y_pred_post = make_pred(Xtest[:,-1],np.array(y_preds_combined.ravel()),best_thres_0,best_thres_1)\n",
    "best_ba,best_us = evaluate(y_test,np.array(y_pred_post),Xtest[:,-1])\n",
    "print(\"Test:\")\n",
    "print(best_ba,nll1(y_test,np.array(y_preds_combined.ravel())).numpy()/Xtest.shape[0],best_us)\n",
    "\n",
    "print(\"US_S_0\")\n",
    "print(underestimation_score(y_test,y_pred_post,Xtest[:,-1]))\n",
    "print(\"US_S_1\")\n",
    "print(underestimation_score_1(y_test,y_pred_post,Xtest[:,-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:\n",
      "0.8348381549044899 0.37539749890593327 0.07408015801446045\n",
      "US_S_0\n",
      "194 590\n",
      "0.3288135593220339\n",
      "US_S_1\n",
      "2523 3256\n",
      "0.7748771498771498\n",
      "ECE with n_bins = 5:\n",
      "ECE_Platt_All:  0.0463\n",
      "ECE_Platt_Maj:  0.0355\n",
      "ECE_Platt_Min   :  0.0453\n"
     ]
    }
   ],
   "source": [
    "##Platt\n",
    "\n",
    "y_probs_combined = np.stack([model(Xtrain) for model in trained_models])\n",
    "y_preds_combined = np.mean(y_probs_combined, axis=0)\n",
    "platt = LogisticRegression(random_state=0,solver='lbfgs')\n",
    "platt.fit(y_preds_combined, y_train)\n",
    "y_probs_combined = np.stack([model(Xtest) for model in trained_models])\n",
    "y_preds_combined = np.mean(y_probs_combined, axis=0)\n",
    "platt_probs = platt.predict_proba(y_preds_combined)[:,1]\n",
    "print(\"Test:\")\n",
    "best_ba,best_us = evaluate(y_test,np.array(np.round(platt_probs)),Xtest[:,-1])\n",
    "print(best_ba,nll1(y_test,np.array(tf.cast(platt_probs, dtype=tf.float32))).numpy()/Xtest.shape[0],best_us)\n",
    "\n",
    "print(\"US_S_0\")\n",
    "print(underestimation_score(y_test,np.round(platt_probs),Xtest[:,-1]))\n",
    "print(\"US_S_1\")\n",
    "print(underestimation_score_1(y_test,np.round(platt_probs),Xtest[:,-1]))\n",
    "\n",
    "from sklearn.calibration import calibration_curve\n",
    "prob_true, prob_pred = calibration_curve(y_test, platt_probs, n_bins=5)\n",
    "df['Platt'] = platt_probs\n",
    "minority = df[df['sa'] == 1]\n",
    "majority = df[df['sa'] == 0]\n",
    "prob_true_maj, prob_pred_maj = calibration_curve(np.array(majority.actual), majority['Platt'].values.reshape(-1,1), n_bins=5)\n",
    "prob_true_min, prob_pred_min = calibration_curve(np.array(minority.actual), minority['Platt'].values.reshape(-1,1), n_bins=5)\n",
    "\n",
    "print(\"ECE with n_bins = 5:\")\n",
    "print(\"ECE_Platt_All: \",compute_calibration_error(np.array(df.actual), df['Platt'].values.reshape(-1,1), n_bins=5))\n",
    "print(\"ECE_Platt_Maj: \",compute_calibration_error(np.array(majority.actual), majority['Platt'].values.reshape(-1,1), n_bins=5))\n",
    "print(\"ECE_Platt_Min   : \",compute_calibration_error(np.array(minority.actual), minority['Platt'].values.reshape(-1,1), n_bins=5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Deep Ensembles Model~~~~~~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:23<00:00,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/47 [..............................] - ETA: 7s - loss: 0.5104 - accuracy: 0.6562"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 1ms/step - loss: 0.5298 - accuracy: 0.7213\n",
      "Test results - Loss: 0.5297950506210327 - Accuracy: 0.7213333249092102%\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.5310 - accuracy: 0.7167\n",
      "Test results - Loss: 0.5309976935386658 - Accuracy: 0.7166666388511658%\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.5299 - accuracy: 0.7180\n",
      "Test results - Loss: 0.5298608541488647 - Accuracy: 0.7179999947547913%\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.5298 - accuracy: 0.7187\n",
      "Test results - Loss: 0.5298011898994446 - Accuracy: 0.718666672706604%\n",
      "47/47 [==============================] - 0s 997us/step - loss: 0.5329 - accuracy: 0.7147\n",
      "Test results - Loss: 0.5328598022460938 - Accuracy: 0.7146666646003723%\n",
      "47/47 [==============================] - 0s 975us/step - loss: 0.5296 - accuracy: 0.7233\n",
      "Test results - Loss: 0.5296490788459778 - Accuracy: 0.7233333587646484%\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.5298 - accuracy: 0.7213\n",
      "Test results - Loss: 0.5298079252243042 - Accuracy: 0.7213333249092102%\n",
      "47/47 [==============================] - 0s 975us/step - loss: 0.5296 - accuracy: 0.7240\n",
      "Test results - Loss: 0.5296158194541931 - Accuracy: 0.7239999771118164%\n",
      "47/47 [==============================] - 0s 932us/step - loss: 0.5309 - accuracy: 0.7173\n",
      "Test results - Loss: 0.5308791399002075 - Accuracy: 0.7173333168029785%\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.5298 - accuracy: 0.7193\n",
      "Test results - Loss: 0.5297726988792419 - Accuracy: 0.7193333506584167%\n",
      "######################################################\n",
      " Loss    : 0.5303039252758026 - 0.0009738189079218755\n",
      " Accuracy: 0.7194666624069214 - 0.0028409731536502086%\n",
      "Deep Ensembles trained!!!~~~~~~~\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training standard NN Model~~~~~~~\n",
      "Epoch 1/60\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6684 - accuracy: 0.5963\n",
      "Epoch 2/60\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6398 - accuracy: 0.6286\n",
      "Epoch 3/60\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6064 - accuracy: 0.6743\n",
      "Epoch 4/60\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5765 - accuracy: 0.7094\n",
      "Epoch 5/60\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5580 - accuracy: 0.7157\n",
      "Epoch 6/60\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5502 - accuracy: 0.7129\n",
      "Epoch 7/60\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5442 - accuracy: 0.7157\n",
      "Epoch 8/60\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5418 - accuracy: 0.7209\n",
      "Epoch 9/60\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5448 - accuracy: 0.7146\n",
      "Epoch 10/60\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5411 - accuracy: 0.7206\n",
      "Epoch 11/60\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5439 - accuracy: 0.7103\n",
      "Epoch 12/60\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5428 - accuracy: 0.7200\n",
      "Epoch 13/60\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5412 - accuracy: 0.7197\n",
      "Epoch 14/60\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5400 - accuracy: 0.7209\n",
      "Epoch 15/60\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5430 - accuracy: 0.7140\n",
      "Epoch 16/60\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5411 - accuracy: 0.7149\n",
      "Epoch 17/60\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5503 - accuracy: 0.7091\n",
      "Epoch 18/60\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5501 - accuracy: 0.7060\n",
      "Epoch 19/60\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5428 - accuracy: 0.7177\n",
      "Epoch 20/60\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5418 - accuracy: 0.7194\n",
      "Epoch 21/60\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5421 - accuracy: 0.7111\n",
      "Epoch 22/60\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5419 - accuracy: 0.7183\n",
      "Epoch 23/60\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5410 - accuracy: 0.7177\n",
      "Epoch 24/60\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5408 - accuracy: 0.7191\n",
      "Epoch 25/60\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5407 - accuracy: 0.7203\n",
      "Epoch 26/60\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5398 - accuracy: 0.7160\n",
      "Epoch 27/60\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5408 - accuracy: 0.7203\n",
      "Epoch 28/60\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5445 - accuracy: 0.7137\n",
      "Epoch 29/60\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5425 - accuracy: 0.7151\n",
      "Epoch 30/60\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5434 - accuracy: 0.7146\n",
      "Epoch 31/60\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5398 - accuracy: 0.7171\n",
      "Epoch 32/60\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5395 - accuracy: 0.7249\n",
      "Epoch 33/60\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5416 - accuracy: 0.7163\n",
      "Epoch 34/60\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5413 - accuracy: 0.7191\n",
      "Epoch 35/60\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5407 - accuracy: 0.7146\n",
      "Epoch 36/60\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5410 - accuracy: 0.7186\n",
      "Epoch 37/60\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5390 - accuracy: 0.7203\n",
      "Epoch 38/60\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5390 - accuracy: 0.7189\n",
      "Epoch 39/60\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5394 - accuracy: 0.7171\n",
      "Epoch 40/60\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.5403 - accuracy: 0.7206\n",
      "Epoch 41/60\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5404 - accuracy: 0.7177\n",
      "Epoch 42/60\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5459 - accuracy: 0.7089\n",
      "Epoch 43/60\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5393 - accuracy: 0.7229\n",
      "Epoch 44/60\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5405 - accuracy: 0.7171\n",
      "Epoch 45/60\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5427 - accuracy: 0.7149\n",
      "Epoch 46/60\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5404 - accuracy: 0.7183\n",
      "Epoch 47/60\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5412 - accuracy: 0.7151\n",
      "Epoch 48/60\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5395 - accuracy: 0.7163\n",
      "Epoch 49/60\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5393 - accuracy: 0.7197\n",
      "Epoch 50/60\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5402 - accuracy: 0.7217\n",
      "Epoch 51/60\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5474 - accuracy: 0.7111\n",
      "Epoch 52/60\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5413 - accuracy: 0.7160\n",
      "Epoch 53/60\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5392 - accuracy: 0.7186\n",
      "Epoch 54/60\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5414 - accuracy: 0.7151\n",
      "Epoch 55/60\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5396 - accuracy: 0.7211\n",
      "Epoch 56/60\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5397 - accuracy: 0.7189\n",
      "Epoch 57/60\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5396 - accuracy: 0.7160\n",
      "Epoch 58/60\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5413 - accuracy: 0.7194\n",
      "Epoch 59/60\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5394 - accuracy: 0.7177\n",
      "Epoch 60/60\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5410 - accuracy: 0.7151\n",
      "Standard NN trained!!!~~~~~~~\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Synthetic Dataset\n",
    "synthetic = pd.read_csv(\"synthetic.csv\")\n",
    "synthetic['admit'] = [0 if x == False else 1 for x in synthetic['admit']]\n",
    "synthetic['gender'] = [0 if x == 'woman' else 1 for x in synthetic['gender']]\n",
    "\n",
    "\n",
    "Y = synthetic['admit'].values\n",
    "synthetic.pop('admit')\n",
    "X = synthetic.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, shuffle = True, stratify = Y,random_state=69)\n",
    "\n",
    "# Normalize data\n",
    "minmax = MinMaxScaler()\n",
    "xtrain_num = minmax.fit_transform(X_train[:,1:3])\n",
    "xtest_num = minmax.transform(X_test[:,1:3])\n",
    "\n",
    "Xtrain = np.hstack((xtrain_num,X_train[:,0].reshape(-1,1)))\n",
    "Xtest = np.hstack((xtest_num,X_test[:,0].reshape(-1,1)))\n",
    "\n",
    "## Train Deep Ensembles Model\n",
    "print(\"Training Deep Ensembles Model~~~~~~~\")\n",
    "histories,trained_models = train(Xtrain, np.array(y_train).reshape(-1,1), epochs=60, batch=100)\n",
    "losses,accuracies = model_eval(Xtest,np.array(y_test).reshape(-1,1),trained_models)\n",
    "print(\"Deep Ensembles trained!!!~~~~~~~\")\n",
    "print(\"\\n\\n\\n\\n\\n\")\n",
    "## Train standard NN\n",
    "print(\"Training standard NN Model~~~~~~~\")\n",
    "DNN_model = Sequential([\n",
    "            Dense(50,activation='sigmoid'),\n",
    "            Dense(1,activation='sigmoid')])\n",
    "DNN_model.compile(tf.keras.optimizers.Adam(learning_rate=0.01), loss='binary_crossentropy',metrics=[\"accuracy\"])\n",
    "DNN_model.fit(Xtrain, np.array(y_train).reshape(-1,1), epochs=60, batch_size=100)\n",
    "print(\"Standard NN trained!!!~~~~~~~\")\n",
    "print(\"\\n\\n\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 1ms/step - loss: 0.5305 - accuracy: 0.7193\n",
      "Test results - Loss: 0.5304629802703857 - Accuracy: 0.7193333506584167%\n",
      "ECE with n_bins = 5:\n",
      "ECE_DeepEnsembles:  0.0205\n",
      "ECE_StandardNN   :  0.0287\n",
      "UEI: \n",
      "UEI_DeepEnsembles:  0.02973004426940202\n",
      "UEI_StandardNN   :  0.040124725365472055\n",
      "US_0: \n",
      "279 294\n",
      "US0_DeepEnsembles:  0.9489795918367347\n",
      "267 294\n",
      "US0_StandardNN   :  0.9081632653061225\n",
      "US_1: \n",
      "271 312\n",
      "US1_DeepEnsembles:  0.8685897435897436\n",
      "260 312\n",
      "US1_StandardNN   :  0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "y_probs_combined = np.stack([model(Xtest) for model in trained_models])\n",
    "y_preds_combined = np.mean(y_probs_combined, axis=0)\n",
    "\n",
    "\n",
    "# Test the model after training\n",
    "test_results = DNN_model.evaluate(Xtest, np.array(y_test).reshape(-1,1), verbose=1)\n",
    "print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]}%')\n",
    "y_pred_1NN = DNN_model(Xtest)\n",
    "\n",
    "df = {}\n",
    "df['sa'] = Xtest[:,-1]\n",
    "df['actual'] = y_test\n",
    "df['Ensembles'] = y_preds_combined.ravel()\n",
    "df['DNN'] = np.array(y_pred_1NN).ravel()\n",
    "df = pd.DataFrame(df)\n",
    "\n",
    "print(\"ECE with n_bins = 5:\")\n",
    "print(\"ECE_DeepEnsembles: \",compute_calibration_error(np.array(y_test),y_preds_combined,n_bins=5))\n",
    "print(\"ECE_StandardNN   : \",compute_calibration_error(np.array(y_test),y_pred_1NN,n_bins=5))\n",
    "\n",
    "\n",
    "\n",
    "print(\"UEI: \")\n",
    "print(\"UEI_DeepEnsembles: \",UEI(df.sa.values, df.actual.values, np.round(df['Ensembles'].values)))\n",
    "print(\"UEI_StandardNN   : \",UEI(df.sa.values, df.actual.values, np.round(df['DNN'].values)))\n",
    "\n",
    "print(\"US_0: \")\n",
    "print(\"US0_DeepEnsembles: \",underestimation_score_1(df.actual.values, np.round(df['Ensembles'].values),df.sa.values))\n",
    "print(\"US0_StandardNN   : \",underestimation_score_1(df.actual.values, np.round(df['DNN'].values),df.sa.values))\n",
    "\n",
    "print(\"US_1: \")\n",
    "print(\"US1_DeepEnsembles: \",underestimation_score(df.actual.values, np.round(df['Ensembles'].values),df.sa.values))\n",
    "print(\"US1_StandardNN   : \",underestimation_score(df.actual.values, np.round(df['DNN'].values),df.sa.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECE with n_bins = 5:\n",
      "ECE_DeepEnsembles_Maj:  0.0183\n",
      "ECE_DeepEnsembles_Min   :  0.0342\n",
      "ECE with n_bins = 5:\n",
      "ECE_DNN_Maj:  0.0296\n",
      "ECE_DNN_Min   :  0.0376\n"
     ]
    }
   ],
   "source": [
    "from sklearn.calibration import calibration_curve\n",
    "prob_true, prob_pred = calibration_curve(y_test, y_preds_combined, n_bins=5)\n",
    "prob_true_dnn, prob_pred_dnn = calibration_curve(y_test, y_pred_1NN, n_bins=5)\n",
    "minority = df[df['sa'] == 1]\n",
    "majority = df[df['sa'] == 0]\n",
    "prob_true_maj, prob_pred_maj = calibration_curve(np.array(majority.actual), majority['Ensembles'].values.reshape(-1,1), n_bins=5)\n",
    "prob_true_min, prob_pred_min = calibration_curve(np.array(minority.actual), minority['Ensembles'].values.reshape(-1,1), n_bins=5)\n",
    "prob_true_dnn_maj, prob_pre_dnnd_maj = calibration_curve(np.array(majority.actual), majority['DNN'].values.reshape(-1,1), n_bins=5)\n",
    "prob_true_dnn_min, prob_pred_dnn_min = calibration_curve(np.array(minority.actual), minority['DNN'].values.reshape(-1,1), n_bins=5)\n",
    "\n",
    "print(\"ECE with n_bins = 5:\")\n",
    "print(\"ECE_DeepEnsembles_Maj: \",compute_calibration_error(np.array(majority.actual), majority['Ensembles'].values.reshape(-1,1), n_bins=5))\n",
    "print(\"ECE_DeepEnsembles_Min   : \",compute_calibration_error(np.array(minority.actual), minority['Ensembles'].values.reshape(-1,1), n_bins=5))\n",
    "\n",
    "print(\"ECE with n_bins = 5:\")\n",
    "print(\"ECE_DNN_Maj: \",compute_calibration_error(np.array(majority.actual), majority['DNN'].values.reshape(-1,1), n_bins=5))\n",
    "print(\"ECE_DNN_Min   : \",compute_calibration_error(np.array(minority.actual), minority['DNN'].values.reshape(-1,1), n_bins=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best threshold for s=0 that minimizes P(Y|S) - P(Yhat|S) is:  0.4545454545454546\n",
      "best threshold for s=1 that minimizes P(Y|S) - P(Yhat|S) is:  0.4747474747474748\n",
      "Train:\n",
      "0.7142857142857143 0.5381030970982142 0.0031689544631481833\n",
      "Test:\n",
      "0.722 0.5295528157552083 0.007039220565969829\n",
      "US_S_0\n",
      "302 312\n",
      "0.967948717948718\n",
      "US_S_1\n",
      "297 294\n",
      "1.010204081632653\n"
     ]
    }
   ],
   "source": [
    "## Post-processing\n",
    "\n",
    "def find_thres(group,clf_prob,truth):\n",
    "    ls_0 = {}\n",
    "    ls_1 = {}\n",
    "    thresholds = np.linspace(0, 1, num=100)\n",
    "    for thres in thresholds:\n",
    "        df = {}\n",
    "        df['sa'] = group\n",
    "        df['prob'] = clf_prob\n",
    "        df['ground_truth'] = truth\n",
    "        df['prob_pred'] =[0]*len(truth)\n",
    "        df = pd.DataFrame(df)\n",
    "        df.loc[ (df['sa'] == 0) & (df['prob'] > thres),'prob_pred'] = 1\n",
    "        df.loc[ (df['sa'] == 1) & (df['prob'] > thres),'prob_pred'] = 1\n",
    "        US_pred_0 = df_count_feat_val_match(df, 'prob_pred', 1, 'sa',0)\n",
    "        US_true_0 = df_count_feat_val_match(df, 'ground_truth', 1, 'sa',0)\n",
    "        US_pred_1 = df_count_feat_val_match(df, 'prob_pred', 1, 'sa',1)\n",
    "        US_true_1 = df_count_feat_val_match(df, 'ground_truth', 1, 'sa',1)\n",
    "        ls_0[thres] = np.abs(US_pred_0-US_true_0)\n",
    "        ls_1[thres] = np.abs(US_pred_1-US_true_1)\n",
    "    best_0 = thresholds[np.argmin(list(ls_0.values()))]\n",
    "    best_1 = thresholds[np.argmin(list(ls_1.values()))]\n",
    "    print(\"best threshold for s=0 that minimizes P(Y|S) - P(Yhat|S) is: \",best_0)\n",
    "    print(\"best threshold for s=1 that minimizes P(Y|S) - P(Yhat|S) is: \",best_1)\n",
    "    return best_0,best_1\n",
    "\n",
    "def make_pred(group,clf_prob,thres_0,thres_1):\n",
    "    y_post = []\n",
    "    for sa,predictproba in zip(group,clf_prob):\n",
    "        if sa == 0 and predictproba > thres_0:\n",
    "            y_post.append(1)\n",
    "        elif sa == 0 and predictproba <= thres_0:\n",
    "            y_post.append(0)\n",
    "        elif sa == 1 and predictproba > thres_1:\n",
    "            y_post.append(1)\n",
    "        else:\n",
    "            y_post.append(0)\n",
    "    return y_post\n",
    "\n",
    "def evaluate(y_true,y_pred,sa):\n",
    "    ## convert the probability estimates to class labels (MC Dropout)\n",
    "\n",
    "    ba = accuracy_score(y_true,y_pred)\n",
    "    us_s = UEI(sa, y_true, np.round(y_pred))\n",
    "    return ba,us_s\n",
    "\n",
    "y_probs_combined = np.stack([model(Xtrain) for model in trained_models])\n",
    "y_preds_combined = np.mean(y_probs_combined, axis=0)\n",
    "best_thres_0,best_thres_1 = find_thres(Xtrain[:,-1],np.array(y_preds_combined.ravel()),y_train)\n",
    "y_pred_post = make_pred(Xtrain[:,-1],np.array(y_preds_combined.ravel()),best_thres_0,best_thres_1)\n",
    "best_ba,best_us = evaluate(y_train,np.array(y_pred_post),Xtrain[:,-1])\n",
    "print(\"Train:\")\n",
    "print(best_ba,nll1(y_train,np.array(y_preds_combined.ravel())).numpy()/Xtrain.shape[0],best_us)\n",
    "## test\n",
    "y_probs_combined = np.stack([model(Xtest) for model in trained_models])\n",
    "y_preds_combined = np.mean(y_probs_combined, axis=0)\n",
    "y_pred_post = make_pred(Xtest[:,-1],np.array(y_preds_combined.ravel()),best_thres_0,best_thres_1)\n",
    "best_ba,best_us = evaluate(y_test,np.array(y_pred_post),Xtest[:,-1])\n",
    "print(\"Test:\")\n",
    "print(best_ba,nll1(y_test,np.array(y_preds_combined.ravel())).numpy()/Xtest.shape[0],best_us)\n",
    "\n",
    "print(\"US_S_0\")\n",
    "print(underestimation_score(y_test,y_pred_post,Xtest[:,-1]))\n",
    "print(\"US_S_1\")\n",
    "print(underestimation_score_1(y_test,y_pred_post,Xtest[:,-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:\n",
      "0.7193333333333334 0.538548583984375 0.03360978154071994\n",
      "US_S_0\n",
      "267 312\n",
      "0.8557692307692307\n",
      "US_S_1\n",
      "274 294\n",
      "0.9319727891156463\n",
      "ECE with n_bins = 5:\n",
      "ECE_Platt_All:  0.0391\n",
      "ECE_Platt_Maj:  0.0315\n",
      "ECE_Platt_Min   :  0.0534\n"
     ]
    }
   ],
   "source": [
    "##Platt\n",
    "\n",
    "y_probs_combined = np.stack([model(Xtrain) for model in trained_models])\n",
    "y_preds_combined = np.mean(y_probs_combined, axis=0)\n",
    "platt = LogisticRegression(random_state=0,solver='lbfgs')\n",
    "platt.fit(y_preds_combined, y_train)\n",
    "y_probs_combined = np.stack([model(Xtest) for model in trained_models])\n",
    "y_preds_combined = np.mean(y_probs_combined, axis=0)\n",
    "platt_probs = platt.predict_proba(y_preds_combined)[:,1]\n",
    "print(\"Test:\")\n",
    "best_ba,best_us = evaluate(y_test,np.array(np.round(platt_probs)),Xtest[:,-1])\n",
    "print(best_ba,nll1(y_test,np.array(tf.cast(platt_probs, dtype=tf.float32))).numpy()/Xtest.shape[0],best_us)\n",
    "\n",
    "print(\"US_S_0\")\n",
    "print(underestimation_score(y_test,np.round(platt_probs),Xtest[:,-1]))\n",
    "print(\"US_S_1\")\n",
    "print(underestimation_score_1(y_test,np.round(platt_probs),Xtest[:,-1]))\n",
    "\n",
    "from sklearn.calibration import calibration_curve\n",
    "prob_true, prob_pred = calibration_curve(y_test, platt_probs, n_bins=5)\n",
    "df['Platt'] = platt_probs\n",
    "minority = df[df['sa'] == 1]\n",
    "majority = df[df['sa'] == 0]\n",
    "prob_true_maj, prob_pred_maj = calibration_curve(np.array(majority.actual), majority['Platt'].values.reshape(-1,1), n_bins=5)\n",
    "prob_true_min, prob_pred_min = calibration_curve(np.array(minority.actual), minority['Platt'].values.reshape(-1,1), n_bins=5)\n",
    "\n",
    "print(\"ECE with n_bins = 5:\")\n",
    "print(\"ECE_Platt_All: \",compute_calibration_error(np.array(df.actual), df['Platt'].values.reshape(-1,1), n_bins=5))\n",
    "print(\"ECE_Platt_Maj: \",compute_calibration_error(np.array(majority.actual), majority['Platt'].values.reshape(-1,1), n_bins=5))\n",
    "print(\"ECE_Platt_Min   : \",compute_calibration_error(np.array(minority.actual), minority['Platt'].values.reshape(-1,1), n_bins=5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exemplar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic = pd.read_csv(\"medium_exemplar.csv\")\n",
    "y = synthetic['Label']\n",
    "synthetic.pop('Label')\n",
    "X = synthetic\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify = y,shuffle = True,random_state=50)\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "# Define which columns should be encoded vs scaled\n",
    "columns_to_encode = ['Location', 'NewHome', 'FTB', 'EmpSector','Occ','HouseComp','Education']\n",
    "columns_to_scale  = ['Exp:Inc','LoanValue','LTV','LoanTerm','Interest','HouseVal','MRTI']\n",
    "\n",
    "# Instantiate encoder/scaler\n",
    "scaler = StandardScaler()\n",
    "ohe    = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Train\n",
    "scaled_columns  = scaler.fit_transform(X_train[columns_to_scale]) \n",
    "encoded_columns =   ohe.fit_transform(X_train[columns_to_encode])\n",
    "Xtrain = np.concatenate([scaled_columns, encoded_columns,X_train['age'].values.reshape(-1,1)], axis=1)\n",
    "\n",
    "# Test\n",
    "scaled_columns  = scaler.transform(X_test[columns_to_scale]) \n",
    "encoded_columns =   ohe.transform(X_test[columns_to_encode])\n",
    "Xtest = np.concatenate([scaled_columns, encoded_columns,X_test['age'].values.reshape(-1,1)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Deep Ensembles Model~~~~~~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [01:29<00:00,  8.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  1/125 [..............................] - ETA: 16s - loss: 0.0011 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 1ms/step - loss: 0.2379 - accuracy: 0.9421\n",
      "Test results - Loss: 0.23785428702831268 - Accuracy: 0.9420654773712158%\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.2306 - accuracy: 0.9426\n",
      "Test results - Loss: 0.23063170909881592 - Accuracy: 0.9425692558288574%\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.2465 - accuracy: 0.9408\n",
      "Test results - Loss: 0.24650584161281586 - Accuracy: 0.9408060312271118%\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.2599 - accuracy: 0.9401\n",
      "Test results - Loss: 0.25992974638938904 - Accuracy: 0.9400503635406494%\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.2576 - accuracy: 0.9403\n",
      "Test results - Loss: 0.25763165950775146 - Accuracy: 0.9403022527694702%\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.2505 - accuracy: 0.9413\n",
      "Test results - Loss: 0.25048136711120605 - Accuracy: 0.9413098096847534%\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.2555 - accuracy: 0.9418\n",
      "Test results - Loss: 0.25552064180374146 - Accuracy: 0.941813588142395%\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.2631 - accuracy: 0.9406\n",
      "Test results - Loss: 0.26305118203163147 - Accuracy: 0.940554141998291%\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.2546 - accuracy: 0.9403\n",
      "Test results - Loss: 0.2546221613883972 - Accuracy: 0.9403022527694702%\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.2522 - accuracy: 0.9383\n",
      "Test results - Loss: 0.25220584869384766 - Accuracy: 0.9382871389389038%\n",
      "######################################################\n",
      " Loss    : 0.2508434444665909 - 0.00954913074777035\n",
      " Accuracy: 0.9408060312271118 - 0.0011597851060579627%\n",
      "Deep Ensembles trained!!!~~~~~~~\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training standard NN Model~~~~~~~\n",
      "Epoch 1/60\n",
      "93/93 [==============================] - 1s 1ms/step - loss: 0.2674 - accuracy: 0.8848\n",
      "Epoch 2/60\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 0.1607 - accuracy: 0.9342\n",
      "Epoch 3/60\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 0.1546 - accuracy: 0.9363\n",
      "Epoch 4/60\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 0.1542 - accuracy: 0.9381\n",
      "Epoch 5/60\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 0.1531 - accuracy: 0.9364\n",
      "Epoch 6/60\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 0.1457 - accuracy: 0.9432\n",
      "Epoch 7/60\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 0.1389 - accuracy: 0.9441\n",
      "Epoch 8/60\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 0.1307 - accuracy: 0.9470\n",
      "Epoch 9/60\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.1252 - accuracy: 0.9485\n",
      "Epoch 10/60\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 0.1210 - accuracy: 0.9505\n",
      "Epoch 11/60\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 0.1167 - accuracy: 0.9529\n",
      "Epoch 12/60\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.1161 - accuracy: 0.9507\n",
      "Epoch 13/60\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 0.1123 - accuracy: 0.9529\n",
      "Epoch 14/60\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 0.1097 - accuracy: 0.9530\n",
      "Epoch 15/60\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 0.1073 - accuracy: 0.9556\n",
      "Epoch 16/60\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 0.1048 - accuracy: 0.9561\n",
      "Epoch 17/60\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 0.1035 - accuracy: 0.9559\n",
      "Epoch 18/60\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 0.1024 - accuracy: 0.9563\n",
      "Epoch 19/60\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 0.1019 - accuracy: 0.9559\n",
      "Epoch 20/60\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 0.0980 - accuracy: 0.9576\n",
      "Epoch 21/60\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 0.0951 - accuracy: 0.9600\n",
      "Epoch 22/60\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 0.0942 - accuracy: 0.9610\n",
      "Epoch 23/60\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 0.0910 - accuracy: 0.9621\n",
      "Epoch 24/60\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 0.0900 - accuracy: 0.9634\n",
      "Epoch 25/60\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 0.0872 - accuracy: 0.9636\n",
      "Epoch 26/60\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 0.0858 - accuracy: 0.9652\n",
      "Epoch 27/60\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 0.0828 - accuracy: 0.9650\n",
      "Epoch 28/60\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 0.0808 - accuracy: 0.9664\n",
      "Epoch 29/60\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 0.0780 - accuracy: 0.9670\n",
      "Epoch 30/60\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 0.0770 - accuracy: 0.9686\n",
      "Epoch 31/60\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 0.0733 - accuracy: 0.9712\n",
      "Epoch 32/60\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 0.0699 - accuracy: 0.9730\n",
      "Epoch 33/60\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 0.0677 - accuracy: 0.9735\n",
      "Epoch 34/60\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 0.0668 - accuracy: 0.9738\n",
      "Epoch 35/60\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 0.0627 - accuracy: 0.9755\n",
      "Epoch 36/60\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 0.0597 - accuracy: 0.9770\n",
      "Epoch 37/60\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 0.0583 - accuracy: 0.9781\n",
      "Epoch 38/60\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 0.0545 - accuracy: 0.9796\n",
      "Epoch 39/60\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 0.0520 - accuracy: 0.9822\n",
      "Epoch 40/60\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 0.0504 - accuracy: 0.9830\n",
      "Epoch 41/60\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 0.0480 - accuracy: 0.9834\n",
      "Epoch 42/60\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 0.0452 - accuracy: 0.9855\n",
      "Epoch 43/60\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 0.0429 - accuracy: 0.9867\n",
      "Epoch 44/60\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 0.0413 - accuracy: 0.9868\n",
      "Epoch 45/60\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 0.0391 - accuracy: 0.9888\n",
      "Epoch 46/60\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 0.0368 - accuracy: 0.9901\n",
      "Epoch 47/60\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 0.0350 - accuracy: 0.9901\n",
      "Epoch 48/60\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 0.0334 - accuracy: 0.9904\n",
      "Epoch 49/60\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 0.0315 - accuracy: 0.9911\n",
      "Epoch 50/60\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 0.0292 - accuracy: 0.9930\n",
      "Epoch 51/60\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 0.0282 - accuracy: 0.9924\n",
      "Epoch 52/60\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 0.0271 - accuracy: 0.9940\n",
      "Epoch 53/60\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 0.0252 - accuracy: 0.9949\n",
      "Epoch 54/60\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 0.0239 - accuracy: 0.9945\n",
      "Epoch 55/60\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 0.0233 - accuracy: 0.9946\n",
      "Epoch 56/60\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 0.0218 - accuracy: 0.9954\n",
      "Epoch 57/60\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 0.0201 - accuracy: 0.9967\n",
      "Epoch 58/60\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 0.0191 - accuracy: 0.9971\n",
      "Epoch 59/60\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 0.0177 - accuracy: 0.9977\n",
      "Epoch 60/60\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 0.0170 - accuracy: 0.9973\n",
      "Standard NN trained!!!~~~~~~~\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Train Deep Ensembles Model\n",
    "print(\"Training Deep Ensembles Model~~~~~~~\")\n",
    "histories,trained_models = train(Xtrain, np.array(y_train).reshape(-1,1), epochs=80, batch=100)\n",
    "losses,accuracies = model_eval(Xtest,np.array(y_test).reshape(-1,1),trained_models)\n",
    "print(\"Deep Ensembles trained!!!~~~~~~~\")\n",
    "print(\"\\n\\n\\n\\n\\n\")\n",
    "## Train standard NN\n",
    "print(\"Training standard NN Model~~~~~~~\")\n",
    "DNN_model = Sequential([\n",
    "            Dense(50,activation='sigmoid'),\n",
    "            Dense(1,activation='sigmoid')])\n",
    "DNN_model.compile(tf.keras.optimizers.Adam(learning_rate=0.01), loss='binary_crossentropy',metrics=[\"accuracy\"])\n",
    "DNN_model.fit(Xtrain, np.array(y_train).reshape(-1,1), epochs=60, batch_size=100)\n",
    "print(\"Standard NN trained!!!~~~~~~~\")\n",
    "print(\"\\n\\n\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1809 - accuracy: 0.9441\n",
      "Test results - Loss: 0.18091952800750732 - Accuracy: 0.9440805912017822%\n",
      "ECE with n_bins = 5:\n",
      "ECE_DeepEnsembles:  0.0286\n",
      "ECE_StandardNN   :  0.0517\n",
      "UEI: \n",
      "UEI_DeepEnsembles:  0.0074331019442006405\n",
      "UEI_StandardNN   :  0.01133721373191398\n",
      "US_0: \n",
      "690 691\n",
      "US0_DeepEnsembles:  0.9985528219971056\n",
      "677 691\n",
      "US0_StandardNN   :  0.9797395079594791\n",
      "US_1: \n",
      "113 127\n",
      "US1_DeepEnsembles:  0.889763779527559\n",
      "107 127\n",
      "US1_StandardNN   :  0.84251968503937\n"
     ]
    }
   ],
   "source": [
    "y_probs_combined = np.stack([model(Xtest) for model in trained_models])\n",
    "y_preds_combined = np.mean(y_probs_combined, axis=0)\n",
    "\n",
    "\n",
    "# Test the model after training\n",
    "test_results = DNN_model.evaluate(Xtest, np.array(y_test).reshape(-1,1), verbose=1)\n",
    "print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]}%')\n",
    "y_pred_1NN = DNN_model(Xtest)\n",
    "\n",
    "df = {}\n",
    "df['sa'] = Xtest[:,-1]\n",
    "df['actual'] = y_test\n",
    "df['Ensembles'] = y_preds_combined.ravel()\n",
    "df['DNN'] = np.array(y_pred_1NN).ravel()\n",
    "df = pd.DataFrame(df)\n",
    "\n",
    "print(\"ECE with n_bins = 5:\")\n",
    "print(\"ECE_DeepEnsembles: \",compute_calibration_error(np.array(y_test),y_preds_combined,n_bins=5))\n",
    "print(\"ECE_StandardNN   : \",compute_calibration_error(np.array(y_test),y_pred_1NN,n_bins=5))\n",
    "\n",
    "\n",
    "\n",
    "print(\"UEI: \")\n",
    "print(\"UEI_DeepEnsembles: \",UEI(df.sa.values, df.actual.values, np.round(df['Ensembles'].values)))\n",
    "print(\"UEI_StandardNN   : \",UEI(df.sa.values, df.actual.values, np.round(df['DNN'].values)))\n",
    "\n",
    "print(\"US_0: \")\n",
    "print(\"US0_DeepEnsembles: \",underestimation_score_1(df.actual.values, np.round(df['Ensembles'].values),df.sa.values))\n",
    "print(\"US0_StandardNN   : \",underestimation_score_1(df.actual.values, np.round(df['DNN'].values),df.sa.values))\n",
    "\n",
    "print(\"US_1: \")\n",
    "print(\"US1_DeepEnsembles: \",underestimation_score(df.actual.values, np.round(df['Ensembles'].values),df.sa.values))\n",
    "print(\"US1_StandardNN   : \",underestimation_score(df.actual.values, np.round(df['DNN'].values),df.sa.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECE with n_bins = 5:\n",
      "ECE_DeepEnsembles_Maj:  0.0068\n",
      "ECE_DeepEnsembles_Min   :  0.0169\n",
      "ECE with n_bins = 5:\n",
      "ECE_DNN_Maj:  0.0134\n",
      "ECE_DNN_Min   :  0.0247\n"
     ]
    }
   ],
   "source": [
    "from sklearn.calibration import calibration_curve\n",
    "prob_true, prob_pred = calibration_curve(y_test, y_preds_combined, n_bins=5)\n",
    "prob_true_dnn, prob_pred_dnn = calibration_curve(y_test, y_pred_1NN, n_bins=5)\n",
    "minority = df[df['sa'] == 1]\n",
    "majority = df[df['sa'] == 0]\n",
    "prob_true_maj, prob_pred_maj = calibration_curve(np.array(majority.actual), majority['Ensembles'].values.reshape(-1,1), n_bins=5)\n",
    "prob_true_min, prob_pred_min = calibration_curve(np.array(minority.actual), minority['Ensembles'].values.reshape(-1,1), n_bins=5)\n",
    "prob_true_dnn_maj, prob_pre_dnnd_maj = calibration_curve(np.array(majority.actual), majority['DNN'].values.reshape(-1,1), n_bins=5)\n",
    "prob_true_dnn_min, prob_pred_dnn_min = calibration_curve(np.array(minority.actual), minority['DNN'].values.reshape(-1,1), n_bins=5)\n",
    "\n",
    "print(\"ECE with n_bins = 5:\")\n",
    "print(\"ECE_DeepEnsembles_Maj: \",compute_calibration_error(np.array(majority.actual), majority['Ensembles'].values.reshape(-1,1), n_bins=5))\n",
    "print(\"ECE_DeepEnsembles_Min   : \",compute_calibration_error(np.array(minority.actual), minority['Ensembles'].values.reshape(-1,1), n_bins=5))\n",
    "\n",
    "print(\"ECE with n_bins = 5:\")\n",
    "print(\"ECE_DNN_Maj: \",compute_calibration_error(np.array(majority.actual), majority['DNN'].values.reshape(-1,1), n_bins=5))\n",
    "print(\"ECE_DNN_Min   : \",compute_calibration_error(np.array(minority.actual), minority['DNN'].values.reshape(-1,1), n_bins=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best threshold for s=0 that minimizes P(Y|S) - P(Yhat|S) is:  0.3434343434343435\n",
      "best threshold for s=1 that minimizes P(Y|S) - P(Yhat|S) is:  0.42424242424242425\n",
      "Train:\n",
      "1.0 0.004052993301541537 0.0\n",
      "Test:\n",
      "0.9455919395465995 0.14969553142710956 0.004258463858254712\n",
      "US_S_0\n",
      "134 127\n",
      "1.0551181102362204\n",
      "US_S_1\n",
      "700 691\n",
      "1.0130246020260492\n"
     ]
    }
   ],
   "source": [
    "## Post-processing\n",
    "\n",
    "def find_thres(group,clf_prob,truth):\n",
    "    ls_0 = {}\n",
    "    ls_1 = {}\n",
    "    thresholds = np.linspace(0, 1, num=100)\n",
    "    for thres in thresholds:\n",
    "        df = {}\n",
    "        df['sa'] = group\n",
    "        df['prob'] = clf_prob\n",
    "        df['ground_truth'] = truth\n",
    "        df['prob_pred'] =[0]*len(truth)\n",
    "        df = pd.DataFrame(df)\n",
    "        df.loc[ (df['sa'] == 0) & (df['prob'] > thres),'prob_pred'] = 1\n",
    "        df.loc[ (df['sa'] == 1) & (df['prob'] > thres),'prob_pred'] = 1\n",
    "        US_pred_0 = df_count_feat_val_match(df, 'prob_pred', 1, 'sa',0)\n",
    "        US_true_0 = df_count_feat_val_match(df, 'ground_truth', 1, 'sa',0)\n",
    "        US_pred_1 = df_count_feat_val_match(df, 'prob_pred', 1, 'sa',1)\n",
    "        US_true_1 = df_count_feat_val_match(df, 'ground_truth', 1, 'sa',1)\n",
    "        ls_0[thres] = np.abs(US_pred_0-US_true_0)\n",
    "        ls_1[thres] = np.abs(US_pred_1-US_true_1)\n",
    "    best_0 = thresholds[np.argmin(list(ls_0.values()))]\n",
    "    best_1 = thresholds[np.argmin(list(ls_1.values()))]\n",
    "    print(\"best threshold for s=0 that minimizes P(Y|S) - P(Yhat|S) is: \",best_0)\n",
    "    print(\"best threshold for s=1 that minimizes P(Y|S) - P(Yhat|S) is: \",best_1)\n",
    "    return best_0,best_1\n",
    "\n",
    "def make_pred(group,clf_prob,thres_0,thres_1):\n",
    "    y_post = []\n",
    "    for sa,predictproba in zip(group,clf_prob):\n",
    "        if sa == 0 and predictproba > thres_0:\n",
    "            y_post.append(1)\n",
    "        elif sa == 0 and predictproba <= thres_0:\n",
    "            y_post.append(0)\n",
    "        elif sa == 1 and predictproba > thres_1:\n",
    "            y_post.append(1)\n",
    "        else:\n",
    "            y_post.append(0)\n",
    "    return y_post\n",
    "\n",
    "def evaluate(y_true,y_pred,sa):\n",
    "    ## convert the probability estimates to class labels (MC Dropout)\n",
    "\n",
    "    ba = accuracy_score(y_true,y_pred)\n",
    "    us_s = UEI(sa, y_true, np.round(y_pred))\n",
    "    return ba,us_s\n",
    "\n",
    "y_probs_combined = np.stack([model(Xtrain) for model in trained_models])\n",
    "y_preds_combined = np.mean(y_probs_combined, axis=0)\n",
    "best_thres_0,best_thres_1 = find_thres(Xtrain[:,-1],np.array(y_preds_combined.ravel()),y_train)\n",
    "y_pred_post = make_pred(Xtrain[:,-1],np.array(y_preds_combined.ravel()),best_thres_0,best_thres_1)\n",
    "best_ba,best_us = evaluate(y_train,np.array(y_pred_post),Xtrain[:,-1])\n",
    "print(\"Train:\")\n",
    "print(best_ba,nll1(y_train,np.array(y_preds_combined.ravel())).numpy()/Xtrain.shape[0],best_us)\n",
    "## test\n",
    "y_probs_combined = np.stack([model(Xtest) for model in trained_models])\n",
    "y_preds_combined = np.mean(y_probs_combined, axis=0)\n",
    "y_pred_post = make_pred(Xtest[:,-1],np.array(y_preds_combined.ravel()),best_thres_0,best_thres_1)\n",
    "best_ba,best_us = evaluate(y_test,np.array(y_pred_post),Xtest[:,-1])\n",
    "print(\"Test:\")\n",
    "print(best_ba,nll1(y_test,np.array(y_preds_combined.ravel())).numpy()/Xtest.shape[0],best_us)\n",
    "\n",
    "print(\"US_S_0\")\n",
    "print(underestimation_score(y_test,y_pred_post,Xtest[:,-1]))\n",
    "print(\"US_S_1\")\n",
    "print(underestimation_score_1(y_test,y_pred_post,Xtest[:,-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:\n",
      "0.947103274559194 0.752966646823835 0.006425558433901589\n",
      "US_S_0\n",
      "115 127\n",
      "0.905511811023622\n",
      "US_S_1\n",
      "695 691\n",
      "1.0057887120115774\n",
      "ECE with n_bins = 5:\n",
      "ECE_Platt_All:  0.0573\n",
      "ECE_Platt_Maj:  0.0237\n",
      "ECE_Platt_Min   :  0.0609\n"
     ]
    }
   ],
   "source": [
    "## IR\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "ir = IsotonicRegression()\n",
    "y_probs_combined = np.stack([model(Xtrain) for model in trained_models])\n",
    "y_preds_combined = np.mean(y_probs_combined, axis=0)\n",
    "ir.fit(y_preds_combined, y_train)\n",
    "y_probs_combined = np.stack([model(Xtest) for model in trained_models])\n",
    "y_preds_combined = np.mean(y_probs_combined, axis=0)\n",
    "platt_probs = ir.predict(y_preds_combined)\n",
    "print(\"Test:\")\n",
    "best_ba,best_us = evaluate(y_test,np.array(np.round(platt_probs)),Xtest[:,-1])\n",
    "print(best_ba,nll1(y_test,np.array(tf.cast(platt_probs, dtype=tf.float32))).numpy()/Xtest.shape[0],best_us)\n",
    "\n",
    "print(\"US_S_0\")\n",
    "print(underestimation_score(y_test,np.round(platt_probs),Xtest[:,-1]))\n",
    "print(\"US_S_1\")\n",
    "print(underestimation_score_1(y_test,np.round(platt_probs),Xtest[:,-1]))\n",
    "\n",
    "from sklearn.calibration import calibration_curve\n",
    "prob_true, prob_pred = calibration_curve(y_test, platt_probs, n_bins=5)\n",
    "df['Platt'] = platt_probs\n",
    "minority = df[df['sa'] == 1]\n",
    "majority = df[df['sa'] == 0]\n",
    "prob_true_maj, prob_pred_maj = calibration_curve(np.array(majority.actual), majority['Platt'].values.reshape(-1,1), n_bins=5)\n",
    "prob_true_min, prob_pred_min = calibration_curve(np.array(minority.actual), minority['Platt'].values.reshape(-1,1), n_bins=5)\n",
    "\n",
    "print(\"ECE with n_bins = 5:\")\n",
    "print(\"ECE_Platt_All: \",compute_calibration_error(np.array(df.actual), df['Platt'].values.reshape(-1,1), n_bins=5))\n",
    "print(\"ECE_Platt_Maj: \",compute_calibration_error(np.array(majority.actual), majority['Platt'].values.reshape(-1,1), n_bins=5))\n",
    "print(\"ECE_Platt_Min   : \",compute_calibration_error(np.array(minority.actual), minority['Platt'].values.reshape(-1,1), n_bins=5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:\n",
      "0.947103274559194 0.752966646823835 0.006425558433901589\n",
      "US_S_0\n",
      "115 127\n",
      "0.905511811023622\n",
      "US_S_1\n",
      "695 691\n",
      "1.0057887120115774\n",
      "ECE with n_bins = 5:\n",
      "ECE_Platt_All:  0.0573\n",
      "ECE_Platt_Maj:  0.0237\n",
      "ECE_Platt_Min   :  0.0609\n"
     ]
    }
   ],
   "source": [
    "##Platt\n",
    "\n",
    "y_probs_combined = np.stack([model(Xtrain) for model in trained_models])\n",
    "y_preds_combined = np.mean(y_probs_combined, axis=0)\n",
    "platt = LogisticRegression(random_state=0,solver='lbfgs')\n",
    "ir.fit(y_preds_combined, y_train)\n",
    "y_probs_combined = np.stack([model(Xtest) for model in trained_models])\n",
    "y_preds_combined = np.mean(y_probs_combined, axis=0)\n",
    "platt_probs = ir.predict(y_preds_combined)\n",
    "print(\"Test:\")\n",
    "best_ba,best_us = evaluate(y_test,np.array(np.round(platt_probs)),Xtest[:,-1])\n",
    "print(best_ba,nll1(y_test,np.array(tf.cast(platt_probs, dtype=tf.float32))).numpy()/Xtest.shape[0],best_us)\n",
    "\n",
    "print(\"US_S_0\")\n",
    "print(underestimation_score(y_test,np.round(platt_probs),Xtest[:,-1]))\n",
    "print(\"US_S_1\")\n",
    "print(underestimation_score_1(y_test,np.round(platt_probs),Xtest[:,-1]))\n",
    "\n",
    "from sklearn.calibration import calibration_curve\n",
    "prob_true, prob_pred = calibration_curve(y_test, platt_probs, n_bins=5)\n",
    "df['Platt'] = platt_probs\n",
    "minority = df[df['sa'] == 1]\n",
    "majority = df[df['sa'] == 0]\n",
    "prob_true_maj, prob_pred_maj = calibration_curve(np.array(majority.actual), majority['Platt'].values.reshape(-1,1), n_bins=5)\n",
    "prob_true_min, prob_pred_min = calibration_curve(np.array(minority.actual), minority['Platt'].values.reshape(-1,1), n_bins=5)\n",
    "\n",
    "print(\"ECE with n_bins = 5:\")\n",
    "print(\"ECE_Platt_All: \",compute_calibration_error(np.array(df.actual), df['Platt'].values.reshape(-1,1), n_bins=5))\n",
    "print(\"ECE_Platt_Maj: \",compute_calibration_error(np.array(majority.actual), majority['Platt'].values.reshape(-1,1), n_bins=5))\n",
    "print(\"ECE_Platt_Min   : \",compute_calibration_error(np.array(minority.actual), minority['Platt'].values.reshape(-1,1), n_bins=5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bike Sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike = pd.read_csv('bikeclean.csv')\n",
    "bike['Y'] = bike['casual'].apply(lambda x: 1 if x > 1200 else 0)\n",
    "y = bike['Y']\n",
    "bike.pop('Y')\n",
    "bike.pop('casual')\n",
    "X = bike\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, \n",
    "                                                    shuffle = True, random_state=0, stratify = y)\n",
    "\n",
    "\n",
    "Xtrain_num = X_train[['temp','atemp','hum','windspeed']]\n",
    "Xtest_num = X_test[['temp','atemp','hum','windspeed']]\n",
    "x_train_cat = X_train[['season','yr','mnth','weekday','holiday','weathersit'\n",
    "                                              ]]\n",
    "x_test_cat = X_test[['season','yr','mnth','weekday','holiday','weathersit'\n",
    "                                              ]]\n",
    "std = StandardScaler()\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "Xtrain_num = std.fit_transform(Xtrain_num)\n",
    "Xtest_num = std.transform(Xtest_num)\n",
    "x_train_cat = ohe.fit_transform(x_train_cat)\n",
    "x_test_cat = ohe.transform(x_test_cat)\n",
    "\n",
    "Xtrain = np.hstack((Xtrain_num,x_train_cat,X_train['workingday'].values.reshape(-1,1)))\n",
    "Xtest = np.hstack((Xtest_num,x_test_cat,X_test['workingday'].values.reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Deep Ensembles Model~~~~~~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2414 - accuracy: 0.9062"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2153 - accuracy: 0.9091\n",
      "Test results - Loss: 0.21527424454689026 - Accuracy: 0.9090909361839294%\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1980 - accuracy: 0.9227\n",
      "Test results - Loss: 0.1980215609073639 - Accuracy: 0.9227272868156433%\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1975 - accuracy: 0.9273\n",
      "Test results - Loss: 0.19749389588832855 - Accuracy: 0.9272727370262146%\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2049 - accuracy: 0.9091\n",
      "Test results - Loss: 0.20486944913864136 - Accuracy: 0.9090909361839294%\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2177 - accuracy: 0.9091\n",
      "Test results - Loss: 0.2176767885684967 - Accuracy: 0.9090909361839294%\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2020 - accuracy: 0.9182\n",
      "Test results - Loss: 0.2020074874162674 - Accuracy: 0.918181836605072%\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2115 - accuracy: 0.9136\n",
      "Test results - Loss: 0.2114613950252533 - Accuracy: 0.9136363863945007%\n",
      "7/7 [==============================] - 0s 1000us/step - loss: 0.2049 - accuracy: 0.9182\n",
      "Test results - Loss: 0.2049345076084137 - Accuracy: 0.918181836605072%\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1976 - accuracy: 0.9273\n",
      "Test results - Loss: 0.19757391512393951 - Accuracy: 0.9272727370262146%\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2104 - accuracy: 0.9136\n",
      "Test results - Loss: 0.21038299798965454 - Accuracy: 0.9136363863945007%\n",
      "######################################################\n",
      " Loss    : 0.20596962422132492 - 0.007048042729572222\n",
      " Accuracy: 0.9168182015419006 - 0.006757297531786616%\n",
      "Deep Ensembles trained!!!~~~~~~~\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training standard NN Model~~~~~~~\n",
      "Epoch 1/60\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4911 - accuracy: 0.7789\n",
      "Epoch 2/60\n",
      "6/6 [==============================] - 0s 1000us/step - loss: 0.4090 - accuracy: 0.8023\n",
      "Epoch 3/60\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.3591 - accuracy: 0.8376\n",
      "Epoch 4/60\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.3211 - accuracy: 0.8669\n",
      "Epoch 5/60\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.2863 - accuracy: 0.8845\n",
      "Epoch 6/60\n",
      "6/6 [==============================] - 0s 0s/step - loss: 0.2598 - accuracy: 0.9139\n",
      "Epoch 7/60\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.2301 - accuracy: 0.9276\n",
      "Epoch 8/60\n",
      "6/6 [==============================] - 0s 1000us/step - loss: 0.2093 - accuracy: 0.9276\n",
      "Epoch 9/60\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1938 - accuracy: 0.9295\n",
      "Epoch 10/60\n",
      "6/6 [==============================] - 0s 1000us/step - loss: 0.1841 - accuracy: 0.9295\n",
      "Epoch 11/60\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1764 - accuracy: 0.9354\n",
      "Epoch 12/60\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1694 - accuracy: 0.9413\n",
      "Epoch 13/60\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1684 - accuracy: 0.9393\n",
      "Epoch 14/60\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1680 - accuracy: 0.9393\n",
      "Epoch 15/60\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1618 - accuracy: 0.9432\n",
      "Epoch 16/60\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1609 - accuracy: 0.9472\n",
      "Epoch 17/60\n",
      "6/6 [==============================] - 0s 1000us/step - loss: 0.1584 - accuracy: 0.9452\n",
      "Epoch 18/60\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1566 - accuracy: 0.9452\n",
      "Epoch 19/60\n",
      "6/6 [==============================] - 0s 1000us/step - loss: 0.1538 - accuracy: 0.9472\n",
      "Epoch 20/60\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1545 - accuracy: 0.9452\n",
      "Epoch 21/60\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1505 - accuracy: 0.9511\n",
      "Epoch 22/60\n",
      "6/6 [==============================] - 0s 1000us/step - loss: 0.1531 - accuracy: 0.9432\n",
      "Epoch 23/60\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1478 - accuracy: 0.9491\n",
      "Epoch 24/60\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1556 - accuracy: 0.9530\n",
      "Epoch 25/60\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1563 - accuracy: 0.9511\n",
      "Epoch 26/60\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1497 - accuracy: 0.9491\n",
      "Epoch 27/60\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1528 - accuracy: 0.9393\n",
      "Epoch 28/60\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1470 - accuracy: 0.9452\n",
      "Epoch 29/60\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1503 - accuracy: 0.9491\n",
      "Epoch 30/60\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1481 - accuracy: 0.9491\n",
      "Epoch 31/60\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1456 - accuracy: 0.9511\n",
      "Epoch 32/60\n",
      "6/6 [==============================] - 0s 1000us/step - loss: 0.1465 - accuracy: 0.9511\n",
      "Epoch 33/60\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1462 - accuracy: 0.9511\n",
      "Epoch 34/60\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1445 - accuracy: 0.9511\n",
      "Epoch 35/60\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1427 - accuracy: 0.9530\n",
      "Epoch 36/60\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1440 - accuracy: 0.9511\n",
      "Epoch 37/60\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1481 - accuracy: 0.9452\n",
      "Epoch 38/60\n",
      "6/6 [==============================] - 0s 1000us/step - loss: 0.1506 - accuracy: 0.9472\n",
      "Epoch 39/60\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1468 - accuracy: 0.9491\n",
      "Epoch 40/60\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1409 - accuracy: 0.9569\n",
      "Epoch 41/60\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1430 - accuracy: 0.9511\n",
      "Epoch 42/60\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1463 - accuracy: 0.9472\n",
      "Epoch 43/60\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1415 - accuracy: 0.9530\n",
      "Epoch 44/60\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1387 - accuracy: 0.9530\n",
      "Epoch 45/60\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1420 - accuracy: 0.9472\n",
      "Epoch 46/60\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1425 - accuracy: 0.9472\n",
      "Epoch 47/60\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1379 - accuracy: 0.9472\n",
      "Epoch 48/60\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1364 - accuracy: 0.9550\n",
      "Epoch 49/60\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1386 - accuracy: 0.9569\n",
      "Epoch 50/60\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1354 - accuracy: 0.9511\n",
      "Epoch 51/60\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1396 - accuracy: 0.9511\n",
      "Epoch 52/60\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1365 - accuracy: 0.9550\n",
      "Epoch 53/60\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1335 - accuracy: 0.9550\n",
      "Epoch 54/60\n",
      "6/6 [==============================] - 0s 1000us/step - loss: 0.1325 - accuracy: 0.9569\n",
      "Epoch 55/60\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1381 - accuracy: 0.9530\n",
      "Epoch 56/60\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1320 - accuracy: 0.9550\n",
      "Epoch 57/60\n",
      "6/6 [==============================] - 0s 1000us/step - loss: 0.1335 - accuracy: 0.9589\n",
      "Epoch 58/60\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1305 - accuracy: 0.9628\n",
      "Epoch 59/60\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1294 - accuracy: 0.9589\n",
      "Epoch 60/60\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1300 - accuracy: 0.9550\n",
      "Standard NN trained!!!~~~~~~~\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Train Deep Ensembles Model\n",
    "print(\"Training Deep Ensembles Model~~~~~~~\")\n",
    "histories,trained_models = train(Xtrain, np.array(y_train).reshape(-1,1), epochs=80, batch=100)\n",
    "losses,accuracies = model_eval(Xtest,np.array(y_test).reshape(-1,1),trained_models)\n",
    "print(\"Deep Ensembles trained!!!~~~~~~~\")\n",
    "print(\"\\n\\n\\n\\n\\n\")\n",
    "## Train standard NN\n",
    "print(\"Training standard NN Model~~~~~~~\")\n",
    "DNN_model = Sequential([\n",
    "            Dense(50,activation='sigmoid'),\n",
    "            Dense(1,activation='sigmoid')])\n",
    "DNN_model.compile(tf.keras.optimizers.Adam(learning_rate=0.01), loss='binary_crossentropy',metrics=[\"accuracy\"])\n",
    "DNN_model.fit(Xtrain, np.array(y_train).reshape(-1,1), epochs=60, batch_size=100)\n",
    "print(\"Standard NN trained!!!~~~~~~~\")\n",
    "print(\"\\n\\n\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2152 - accuracy: 0.9182\n",
      "Test results - Loss: 0.21521154046058655 - Accuracy: 0.918181836605072%\n",
      "ECE with n_bins = 5:\n",
      "ECE_DeepEnsembles:  0.0408\n",
      "ECE_StandardNN   :  0.0484\n",
      "UEI: \n",
      "UEI_DeepEnsembles:  0.021135612709917657\n",
      "UEI_StandardNN   :  0.05438859433348943\n",
      "US_0: \n",
      "11 14\n",
      "US0_DeepEnsembles:  0.7857142857142857\n",
      "7 14\n",
      "US0_StandardNN   :  0.5\n",
      "US_1: \n",
      "34 34\n",
      "US1_DeepEnsembles:  1.0\n",
      "35 34\n",
      "US1_StandardNN   :  1.0294117647058822\n"
     ]
    }
   ],
   "source": [
    "y_probs_combined = np.stack([model(Xtest) for model in trained_models])\n",
    "y_preds_combined = np.mean(y_probs_combined, axis=0)\n",
    "\n",
    "\n",
    "# Test the model after training\n",
    "test_results = DNN_model.evaluate(Xtest, np.array(y_test).reshape(-1,1), verbose=1)\n",
    "print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]}%')\n",
    "y_pred_1NN = DNN_model(Xtest)\n",
    "\n",
    "df = {}\n",
    "df['sa'] = Xtest[:,-1]\n",
    "df['actual'] = y_test\n",
    "df['Ensembles'] = y_preds_combined.ravel()\n",
    "df['DNN'] = np.array(y_pred_1NN).ravel()\n",
    "df = pd.DataFrame(df)\n",
    "\n",
    "print(\"ECE with n_bins = 5:\")\n",
    "print(\"ECE_DeepEnsembles: \",compute_calibration_error(np.array(y_test),y_preds_combined,n_bins=5))\n",
    "print(\"ECE_StandardNN   : \",compute_calibration_error(np.array(y_test),y_pred_1NN,n_bins=5))\n",
    "\n",
    "\n",
    "\n",
    "print(\"UEI: \")\n",
    "print(\"UEI_DeepEnsembles: \",UEI(df.sa.values, df.actual.values, np.round(df['Ensembles'].values)))\n",
    "print(\"UEI_StandardNN   : \",UEI(df.sa.values, df.actual.values, np.round(df['DNN'].values)))\n",
    "\n",
    "print(\"US_0: \")\n",
    "print(\"US0_DeepEnsembles: \",underestimation_score_1(df.actual.values, np.round(df['Ensembles'].values),df.sa.values))\n",
    "print(\"US0_StandardNN   : \",underestimation_score_1(df.actual.values, np.round(df['DNN'].values),df.sa.values))\n",
    "\n",
    "print(\"US_1: \")\n",
    "print(\"US1_DeepEnsembles: \",underestimation_score(df.actual.values, np.round(df['Ensembles'].values),df.sa.values))\n",
    "print(\"US1_StandardNN   : \",underestimation_score(df.actual.values, np.round(df['DNN'].values),df.sa.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECE with n_bins = 5:\n",
      "ECE_DeepEnsembles_Maj:  0.068\n",
      "ECE_DeepEnsembles_Min   :  0.0429\n",
      "ECE with n_bins = 5:\n",
      "ECE_DNN_Maj:  0.0594\n",
      "ECE_DNN_Min   :  0.0405\n"
     ]
    }
   ],
   "source": [
    "from sklearn.calibration import calibration_curve\n",
    "prob_true, prob_pred = calibration_curve(y_test, y_preds_combined, n_bins=5)\n",
    "prob_true_dnn, prob_pred_dnn = calibration_curve(y_test, y_pred_1NN, n_bins=5)\n",
    "minority = df[df['sa'] == 1]\n",
    "majority = df[df['sa'] == 0]\n",
    "prob_true_maj, prob_pred_maj = calibration_curve(np.array(majority.actual), majority['Ensembles'].values.reshape(-1,1), n_bins=5)\n",
    "prob_true_min, prob_pred_min = calibration_curve(np.array(minority.actual), minority['Ensembles'].values.reshape(-1,1), n_bins=5)\n",
    "prob_true_dnn_maj, prob_pre_dnnd_maj = calibration_curve(np.array(majority.actual), majority['DNN'].values.reshape(-1,1), n_bins=5)\n",
    "prob_true_dnn_min, prob_pred_dnn_min = calibration_curve(np.array(minority.actual), minority['DNN'].values.reshape(-1,1), n_bins=5)\n",
    "\n",
    "print(\"ECE with n_bins = 5:\")\n",
    "print(\"ECE_DeepEnsembles_Maj: \",compute_calibration_error(np.array(majority.actual), majority['Ensembles'].values.reshape(-1,1), n_bins=5))\n",
    "print(\"ECE_DeepEnsembles_Min   : \",compute_calibration_error(np.array(minority.actual), minority['Ensembles'].values.reshape(-1,1), n_bins=5))\n",
    "\n",
    "print(\"ECE with n_bins = 5:\")\n",
    "print(\"ECE_DNN_Maj: \",compute_calibration_error(np.array(majority.actual), majority['DNN'].values.reshape(-1,1), n_bins=5))\n",
    "print(\"ECE_DNN_Min   : \",compute_calibration_error(np.array(minority.actual), minority['DNN'].values.reshape(-1,1), n_bins=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best threshold for s=0 that minimizes P(Y|S) - P(Yhat|S) is:  0.5858585858585859\n",
      "best threshold for s=1 that minimizes P(Y|S) - P(Yhat|S) is:  0.30303030303030304\n",
      "Train:\n",
      "0.9549902152641878 0.11372657671366652 0.003483241409492529\n",
      "Test:\n",
      "0.9090909090909091 0.20049315365878018 0.018875777701165098\n",
      "US_S_0\n",
      "31 34\n",
      "0.9117647058823529\n",
      "US_S_1\n",
      "13 14\n",
      "0.9285714285714286\n"
     ]
    }
   ],
   "source": [
    "## Post-processing\n",
    "\n",
    "def find_thres(group,clf_prob,truth):\n",
    "    ls_0 = {}\n",
    "    ls_1 = {}\n",
    "    thresholds = np.linspace(0, 1, num=100)\n",
    "    for thres in thresholds:\n",
    "        df = {}\n",
    "        df['sa'] = group\n",
    "        df['prob'] = clf_prob\n",
    "        df['ground_truth'] = truth\n",
    "        df['prob_pred'] =[0]*len(truth)\n",
    "        df = pd.DataFrame(df)\n",
    "        df.loc[ (df['sa'] == 0) & (df['prob'] > thres),'prob_pred'] = 1\n",
    "        df.loc[ (df['sa'] == 1) & (df['prob'] > thres),'prob_pred'] = 1\n",
    "        US_pred_0 = df_count_feat_val_match(df, 'prob_pred', 1, 'sa',0)\n",
    "        US_true_0 = df_count_feat_val_match(df, 'ground_truth', 1, 'sa',0)\n",
    "        US_pred_1 = df_count_feat_val_match(df, 'prob_pred', 1, 'sa',1)\n",
    "        US_true_1 = df_count_feat_val_match(df, 'ground_truth', 1, 'sa',1)\n",
    "        ls_0[thres] = np.abs(US_pred_0-US_true_0)\n",
    "        ls_1[thres] = np.abs(US_pred_1-US_true_1)\n",
    "    best_0 = thresholds[np.argmin(list(ls_0.values()))]\n",
    "    best_1 = thresholds[np.argmin(list(ls_1.values()))]\n",
    "    print(\"best threshold for s=0 that minimizes P(Y|S) - P(Yhat|S) is: \",best_0)\n",
    "    print(\"best threshold for s=1 that minimizes P(Y|S) - P(Yhat|S) is: \",best_1)\n",
    "    return best_0,best_1\n",
    "\n",
    "def make_pred(group,clf_prob,thres_0,thres_1):\n",
    "    y_post = []\n",
    "    for sa,predictproba in zip(group,clf_prob):\n",
    "        if sa == 0 and predictproba > thres_0:\n",
    "            y_post.append(1)\n",
    "        elif sa == 0 and predictproba <= thres_0:\n",
    "            y_post.append(0)\n",
    "        elif sa == 1 and predictproba > thres_1:\n",
    "            y_post.append(1)\n",
    "        else:\n",
    "            y_post.append(0)\n",
    "    return y_post\n",
    "\n",
    "def evaluate(y_true,y_pred,sa):\n",
    "    ## convert the probability estimates to class labels (MC Dropout)\n",
    "\n",
    "    ba = accuracy_score(y_true,y_pred)\n",
    "    us_s = UEI(sa, y_true, np.round(y_pred))\n",
    "    return ba,us_s\n",
    "\n",
    "y_probs_combined = np.stack([model(Xtrain) for model in trained_models])\n",
    "y_preds_combined = np.mean(y_probs_combined, axis=0)\n",
    "best_thres_0,best_thres_1 = find_thres(Xtrain[:,-1],np.array(y_preds_combined.ravel()),y_train)\n",
    "y_pred_post = make_pred(Xtrain[:,-1],np.array(y_preds_combined.ravel()),best_thres_0,best_thres_1)\n",
    "best_ba,best_us = evaluate(y_train,np.array(y_pred_post),Xtrain[:,-1])\n",
    "print(\"Train:\")\n",
    "print(best_ba,nll1(y_train,np.array(y_preds_combined.ravel())).numpy()/Xtrain.shape[0],best_us)\n",
    "## test\n",
    "y_probs_combined = np.stack([model(Xtest) for model in trained_models])\n",
    "y_preds_combined = np.mean(y_probs_combined, axis=0)\n",
    "y_pred_post = make_pred(Xtest[:,-1],np.array(y_preds_combined.ravel()),best_thres_0,best_thres_1)\n",
    "best_ba,best_us = evaluate(y_test,np.array(y_pred_post),Xtest[:,-1])\n",
    "print(\"Test:\")\n",
    "print(best_ba,nll1(y_test,np.array(y_preds_combined.ravel())).numpy()/Xtest.shape[0],best_us)\n",
    "\n",
    "print(\"US_S_0\")\n",
    "print(underestimation_score(y_test,y_pred_post,Xtest[:,-1]))\n",
    "print(\"US_S_1\")\n",
    "print(underestimation_score_1(y_test,y_pred_post,Xtest[:,-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmc=pd.read_csv('cmc.data.txt',names=['Wife Age','Wife Education','Husband Education','Children',\n",
    "                                                'Wife religion','Wife working','Husband Occupation','SOLI',\n",
    "                                                'Media Exposure','Contraceptive Method'])\n",
    "cmc['cmc_Y'] = cmc['Contraceptive Method'].apply(lambda x: 0 if x == 1 else 1)\n",
    "cmc['cmc_Y'].value_counts()\n",
    "cmc.pop('Contraceptive Method')\n",
    "\n",
    "cmc['mediaexposure_S'] = cmc['Media Exposure'].apply(lambda x: 0 if x == 1 else 1)\n",
    "cmc['mediaexposure_S'].value_counts()\n",
    "cmc.pop('Media Exposure')\n",
    "y = cmc['cmc_Y']\n",
    "cmc.pop('cmc_Y')\n",
    "X = cmc\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, \n",
    "                                                    shuffle = True, random_state=40, stratify = y)\n",
    "\n",
    "Xtrain_num = X_train[['Wife Age','Children']]\n",
    "x_train_cat = X_train[['Wife Education','Husband Education',\n",
    "                                                'Wife religion','Wife working','Husband Occupation','SOLI',\n",
    "                                                'mediaexposure_S']]\n",
    "Xtest_num = X_test[['Wife Age','Children']]\n",
    "x_test_cat = X_test[['Wife Education','Husband Education',\n",
    "                                                'Wife religion','Wife working','Husband Occupation','SOLI',\n",
    "                                                'mediaexposure_S']]\n",
    "std = StandardScaler()\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "Xtrain_num = std.fit_transform(Xtrain_num)\n",
    "Xtest_num = std.transform(Xtest_num)\n",
    "x_train_cat = ohe.fit_transform(x_train_cat)\n",
    "x_test_cat = ohe.transform(x_test_cat)\n",
    "\n",
    "Xtrain = np.hstack((Xtrain_num,x_train_cat))\n",
    "Xtest = np.hstack((Xtest_num,x_test_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Deep Ensembles Model~~~~~~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:11<00:00,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 1ms/step - loss: 0.6296 - accuracy: 0.6878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test results - Loss: 0.6296017169952393 - Accuracy: 0.6877828240394592%\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.6393 - accuracy: 0.6855\n",
      "Test results - Loss: 0.6392503380775452 - Accuracy: 0.685520350933075%\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.6377 - accuracy: 0.6878\n",
      "Test results - Loss: 0.6376606225967407 - Accuracy: 0.6877828240394592%\n",
      "14/14 [==============================] - 0s 923us/step - loss: 0.6261 - accuracy: 0.6923\n",
      "Test results - Loss: 0.6261333227157593 - Accuracy: 0.692307710647583%\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.6355 - accuracy: 0.6878\n",
      "Test results - Loss: 0.6355178356170654 - Accuracy: 0.6877828240394592%\n",
      "14/14 [==============================] - 0s 1000us/step - loss: 0.6311 - accuracy: 0.6855\n",
      "Test results - Loss: 0.6310931444168091 - Accuracy: 0.685520350933075%\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.6378 - accuracy: 0.6923\n",
      "Test results - Loss: 0.6378251910209656 - Accuracy: 0.692307710647583%\n",
      "14/14 [==============================] - 0s 1000us/step - loss: 0.6437 - accuracy: 0.6833\n",
      "Test results - Loss: 0.643653392791748 - Accuracy: 0.6832579374313354%\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6115 - accuracy: 0.6900\n",
      "Test results - Loss: 0.6115207076072693 - Accuracy: 0.6900452375411987%\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.6400 - accuracy: 0.6923\n",
      "Test results - Loss: 0.6400400400161743 - Accuracy: 0.692307710647583%\n",
      "######################################################\n",
      " Loss    : 0.6332296311855317 - 0.008812692065771212\n",
      " Accuracy: 0.6884615480899811 - 0.00304381037295396%\n",
      "Deep Ensembles trained!!!~~~~~~~\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training standard NN Model~~~~~~~\n",
      "Epoch 1/80\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.6870 - accuracy: 0.5723\n",
      "Epoch 2/80\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.6339 - accuracy: 0.6537\n",
      "Epoch 3/80\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.6130 - accuracy: 0.6731\n",
      "Epoch 4/80\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.6094 - accuracy: 0.6731\n",
      "Epoch 5/80\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.6003 - accuracy: 0.6799\n",
      "Epoch 6/80\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5976 - accuracy: 0.6935\n",
      "Epoch 7/80\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5945 - accuracy: 0.6887\n",
      "Epoch 8/80\n",
      "11/11 [==============================] - 0s 1000us/step - loss: 0.5940 - accuracy: 0.6887\n",
      "Epoch 9/80\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5927 - accuracy: 0.6925\n",
      "Epoch 10/80\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5909 - accuracy: 0.6838\n",
      "Epoch 11/80\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5922 - accuracy: 0.6896\n",
      "Epoch 12/80\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5855 - accuracy: 0.6974\n",
      "Epoch 13/80\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5840 - accuracy: 0.6954\n",
      "Epoch 14/80\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5803 - accuracy: 0.7003\n",
      "Epoch 15/80\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5826 - accuracy: 0.7071\n",
      "Epoch 16/80\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5707 - accuracy: 0.7061\n",
      "Epoch 17/80\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5661 - accuracy: 0.7042\n",
      "Epoch 18/80\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5650 - accuracy: 0.7139\n",
      "Epoch 19/80\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5610 - accuracy: 0.7216\n",
      "Epoch 20/80\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5533 - accuracy: 0.7255\n",
      "Epoch 21/80\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5498 - accuracy: 0.7294\n",
      "Epoch 22/80\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5439 - accuracy: 0.7439\n",
      "Epoch 23/80\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5428 - accuracy: 0.7439\n",
      "Epoch 24/80\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5394 - accuracy: 0.7439\n",
      "Epoch 25/80\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5425 - accuracy: 0.7401\n",
      "Epoch 26/80\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5353 - accuracy: 0.7498\n",
      "Epoch 27/80\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5364 - accuracy: 0.7449\n",
      "Epoch 28/80\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5336 - accuracy: 0.7585\n",
      "Epoch 29/80\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5363 - accuracy: 0.7527\n",
      "Epoch 30/80\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5308 - accuracy: 0.7556\n",
      "Epoch 31/80\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5310 - accuracy: 0.7478\n",
      "Epoch 32/80\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5310 - accuracy: 0.7488\n",
      "Epoch 33/80\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5285 - accuracy: 0.7536\n",
      "Epoch 34/80\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5281 - accuracy: 0.7527\n",
      "Epoch 35/80\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5257 - accuracy: 0.7556\n",
      "Epoch 36/80\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5275 - accuracy: 0.7507\n",
      "Epoch 37/80\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5247 - accuracy: 0.7595\n",
      "Epoch 38/80\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5290 - accuracy: 0.7371\n",
      "Epoch 39/80\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5351 - accuracy: 0.7468\n",
      "Epoch 40/80\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5235 - accuracy: 0.7517\n",
      "Epoch 41/80\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5250 - accuracy: 0.7449\n",
      "Epoch 42/80\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5296 - accuracy: 0.7488\n",
      "Epoch 43/80\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5324 - accuracy: 0.7381\n",
      "Epoch 44/80\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5208 - accuracy: 0.7478\n",
      "Epoch 45/80\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5176 - accuracy: 0.7478\n",
      "Epoch 46/80\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5191 - accuracy: 0.7575\n",
      "Epoch 47/80\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5177 - accuracy: 0.7604\n",
      "Epoch 48/80\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5163 - accuracy: 0.7556\n",
      "Epoch 49/80\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5169 - accuracy: 0.7488\n",
      "Epoch 50/80\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5135 - accuracy: 0.7604\n",
      "Epoch 51/80\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5178 - accuracy: 0.7498\n",
      "Epoch 52/80\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5165 - accuracy: 0.7536\n",
      "Epoch 53/80\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5119 - accuracy: 0.7565\n",
      "Epoch 54/80\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5125 - accuracy: 0.7595\n",
      "Epoch 55/80\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5110 - accuracy: 0.7527\n",
      "Epoch 56/80\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5080 - accuracy: 0.7595\n",
      "Epoch 57/80\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5072 - accuracy: 0.7614\n",
      "Epoch 58/80\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5070 - accuracy: 0.7575\n",
      "Epoch 59/80\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5041 - accuracy: 0.7604\n",
      "Epoch 60/80\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5038 - accuracy: 0.7614\n",
      "Epoch 61/80\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5036 - accuracy: 0.7546\n",
      "Epoch 62/80\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5077 - accuracy: 0.7585\n",
      "Epoch 63/80\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5078 - accuracy: 0.7604\n",
      "Epoch 64/80\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5047 - accuracy: 0.7624\n",
      "Epoch 65/80\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5001 - accuracy: 0.7672\n",
      "Epoch 66/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4988 - accuracy: 0.7565\n",
      "Epoch 67/80\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4973 - accuracy: 0.7556\n",
      "Epoch 68/80\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4985 - accuracy: 0.7692\n",
      "Epoch 69/80\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4954 - accuracy: 0.7711\n",
      "Epoch 70/80\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4938 - accuracy: 0.7614\n",
      "Epoch 71/80\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4944 - accuracy: 0.7662\n",
      "Epoch 72/80\n",
      "11/11 [==============================] - 0s 900us/step - loss: 0.4916 - accuracy: 0.7692\n",
      "Epoch 73/80\n",
      "11/11 [==============================] - 0s 1000us/step - loss: 0.4986 - accuracy: 0.7653\n",
      "Epoch 74/80\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5028 - accuracy: 0.7517\n",
      "Epoch 75/80\n",
      "11/11 [==============================] - 0s 1000us/step - loss: 0.4929 - accuracy: 0.7701\n",
      "Epoch 76/80\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4862 - accuracy: 0.7730\n",
      "Epoch 77/80\n",
      "11/11 [==============================] - 0s 1000us/step - loss: 0.4857 - accuracy: 0.7662\n",
      "Epoch 78/80\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4840 - accuracy: 0.7672\n",
      "Epoch 79/80\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4859 - accuracy: 0.7827\n",
      "Epoch 80/80\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4953 - accuracy: 0.7643\n",
      "Standard NN trained!!!~~~~~~~\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Train Deep Ensembles Model\n",
    "print(\"Training Deep Ensembles Model~~~~~~~\")\n",
    "histories,trained_models = train(Xtrain, np.array(y_train).reshape(-1,1), epochs=80, batch=100)\n",
    "losses,accuracies = model_eval(Xtest,np.array(y_test).reshape(-1,1),trained_models)\n",
    "print(\"Deep Ensembles trained!!!~~~~~~~\")\n",
    "print(\"\\n\\n\\n\\n\\n\")\n",
    "## Train standard NN\n",
    "print(\"Training standard NN Model~~~~~~~\")\n",
    "DNN_model = Sequential([\n",
    "            Dense(50,activation='sigmoid'),\n",
    "            Dense(1,activation='sigmoid')])\n",
    "DNN_model.compile(tf.keras.optimizers.Adam(learning_rate=0.01), loss='binary_crossentropy',metrics=[\"accuracy\"])\n",
    "DNN_model.fit(Xtrain, np.array(y_train).reshape(-1,1), epochs=80, batch_size=100)\n",
    "print(\"Standard NN trained!!!~~~~~~~\")\n",
    "print(\"\\n\\n\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 1ms/step - loss: 0.6352 - accuracy: 0.6855\n",
      "Test results - Loss: 0.6352317333221436 - Accuracy: 0.685520350933075%\n",
      "ECE with n_bins = 5:\n",
      "ECE_DeepEnsembles:  0.08\n",
      "ECE_StandardNN   :  0.0881\n",
      "UEI: \n",
      "UEI_DeepEnsembles:  0.0890089849383604\n",
      "UEI_StandardNN   :  0.10278855295313079\n",
      "US_0: \n",
      "274 236\n",
      "US0_DeepEnsembles:  1.1610169491525424\n",
      "291 236\n",
      "US0_StandardNN   :  1.2330508474576272\n",
      "US_1: \n",
      "7 17\n",
      "US1_DeepEnsembles:  0.4117647058823529\n",
      "11 17\n",
      "US1_StandardNN   :  0.6470588235294118\n"
     ]
    }
   ],
   "source": [
    "y_probs_combined = np.stack([model(Xtest) for model in trained_models])\n",
    "y_preds_combined = np.mean(y_probs_combined, axis=0)\n",
    "\n",
    "\n",
    "# Test the model after training\n",
    "test_results = DNN_model.evaluate(Xtest, np.array(y_test).reshape(-1,1), verbose=1)\n",
    "print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]}%')\n",
    "y_pred_1NN = DNN_model(Xtest)\n",
    "\n",
    "df = {}\n",
    "df['sa'] = Xtest[:,-1]\n",
    "df['actual'] = y_test\n",
    "df['Ensembles'] = y_preds_combined.ravel()\n",
    "df['DNN'] = np.array(y_pred_1NN).ravel()\n",
    "df = pd.DataFrame(df)\n",
    "\n",
    "print(\"ECE with n_bins = 5:\")\n",
    "print(\"ECE_DeepEnsembles: \",compute_calibration_error(np.array(y_test),y_preds_combined,n_bins=5))\n",
    "print(\"ECE_StandardNN   : \",compute_calibration_error(np.array(y_test),y_pred_1NN,n_bins=5))\n",
    "\n",
    "\n",
    "\n",
    "print(\"UEI: \")\n",
    "print(\"UEI_DeepEnsembles: \",UEI(df.sa.values, df.actual.values, np.round(df['Ensembles'].values)))\n",
    "print(\"UEI_StandardNN   : \",UEI(df.sa.values, df.actual.values, np.round(df['DNN'].values)))\n",
    "\n",
    "print(\"US_0: \")\n",
    "print(\"US0_DeepEnsembles: \",underestimation_score_1(df.actual.values, np.round(df['Ensembles'].values),df.sa.values))\n",
    "print(\"US0_StandardNN   : \",underestimation_score_1(df.actual.values, np.round(df['DNN'].values),df.sa.values))\n",
    "\n",
    "print(\"US_1: \")\n",
    "print(\"US1_DeepEnsembles: \",underestimation_score(df.actual.values, np.round(df['Ensembles'].values),df.sa.values))\n",
    "print(\"US1_StandardNN   : \",underestimation_score(df.actual.values, np.round(df['DNN'].values),df.sa.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECE with n_bins = 5:\n",
      "ECE_DeepEnsembles_Maj:  0.2104\n",
      "ECE_DeepEnsembles_Min   :  0.0693\n",
      "ECE with n_bins = 5:\n",
      "ECE_DNN_Maj:  0.1656\n",
      "ECE_DNN_Min   :  0.0855\n"
     ]
    }
   ],
   "source": [
    "from sklearn.calibration import calibration_curve\n",
    "prob_true, prob_pred = calibration_curve(y_test, y_preds_combined, n_bins=5)\n",
    "prob_true_dnn, prob_pred_dnn = calibration_curve(y_test, y_pred_1NN, n_bins=5)\n",
    "minority = df[df['sa'] == 1]\n",
    "majority = df[df['sa'] == 0]\n",
    "prob_true_maj, prob_pred_maj = calibration_curve(np.array(majority.actual), majority['Ensembles'].values.reshape(-1,1), n_bins=5)\n",
    "prob_true_min, prob_pred_min = calibration_curve(np.array(minority.actual), minority['Ensembles'].values.reshape(-1,1), n_bins=5)\n",
    "prob_true_dnn_maj, prob_pre_dnnd_maj = calibration_curve(np.array(majority.actual), majority['DNN'].values.reshape(-1,1), n_bins=5)\n",
    "prob_true_dnn_min, prob_pred_dnn_min = calibration_curve(np.array(minority.actual), minority['DNN'].values.reshape(-1,1), n_bins=5)\n",
    "\n",
    "print(\"ECE with n_bins = 5:\")\n",
    "print(\"ECE_DeepEnsembles_Maj: \",compute_calibration_error(np.array(majority.actual), majority['Ensembles'].values.reshape(-1,1), n_bins=5))\n",
    "print(\"ECE_DeepEnsembles_Min   : \",compute_calibration_error(np.array(minority.actual), minority['Ensembles'].values.reshape(-1,1), n_bins=5))\n",
    "\n",
    "print(\"ECE with n_bins = 5:\")\n",
    "print(\"ECE_DNN_Maj: \",compute_calibration_error(np.array(majority.actual), majority['DNN'].values.reshape(-1,1), n_bins=5))\n",
    "print(\"ECE_DNN_Min   : \",compute_calibration_error(np.array(minority.actual), minority['DNN'].values.reshape(-1,1), n_bins=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best threshold for s=0 that minimizes P(Y|S) - P(Yhat|S) is:  0.36363636363636365\n",
      "best threshold for s=1 that minimizes P(Y|S) - P(Yhat|S) is:  0.595959595959596\n",
      "Train:\n",
      "0.7575169738118331 0.4785048506077231 0.003685406310241171\n",
      "Test:\n",
      "0.6855203619909502 0.6284881177531109 0.0180032173184978\n",
      "US_S_0\n",
      "14 17\n",
      "0.8235294117647058\n",
      "US_S_1\n",
      "240 236\n",
      "1.0169491525423728\n"
     ]
    }
   ],
   "source": [
    "## Post-processing\n",
    "\n",
    "def find_thres(group,clf_prob,truth):\n",
    "    ls_0 = {}\n",
    "    ls_1 = {}\n",
    "    thresholds = np.linspace(0, 1, num=100)\n",
    "    for thres in thresholds:\n",
    "        df = {}\n",
    "        df['sa'] = group\n",
    "        df['prob'] = clf_prob\n",
    "        df['ground_truth'] = truth\n",
    "        df['prob_pred'] =[0]*len(truth)\n",
    "        df = pd.DataFrame(df)\n",
    "        df.loc[ (df['sa'] == 0) & (df['prob'] > thres),'prob_pred'] = 1\n",
    "        df.loc[ (df['sa'] == 1) & (df['prob'] > thres),'prob_pred'] = 1\n",
    "        US_pred_0 = df_count_feat_val_match(df, 'prob_pred', 1, 'sa',0)\n",
    "        US_true_0 = df_count_feat_val_match(df, 'ground_truth', 1, 'sa',0)\n",
    "        US_pred_1 = df_count_feat_val_match(df, 'prob_pred', 1, 'sa',1)\n",
    "        US_true_1 = df_count_feat_val_match(df, 'ground_truth', 1, 'sa',1)\n",
    "        ls_0[thres] = np.abs(US_pred_0-US_true_0)\n",
    "        ls_1[thres] = np.abs(US_pred_1-US_true_1)\n",
    "    best_0 = thresholds[np.argmin(list(ls_0.values()))]\n",
    "    best_1 = thresholds[np.argmin(list(ls_1.values()))]\n",
    "    print(\"best threshold for s=0 that minimizes P(Y|S) - P(Yhat|S) is: \",best_0)\n",
    "    print(\"best threshold for s=1 that minimizes P(Y|S) - P(Yhat|S) is: \",best_1)\n",
    "    return best_0,best_1\n",
    "\n",
    "def make_pred(group,clf_prob,thres_0,thres_1):\n",
    "    y_post = []\n",
    "    for sa,predictproba in zip(group,clf_prob):\n",
    "        if sa == 0 and predictproba > thres_0:\n",
    "            y_post.append(1)\n",
    "        elif sa == 0 and predictproba <= thres_0:\n",
    "            y_post.append(0)\n",
    "        elif sa == 1 and predictproba > thres_1:\n",
    "            y_post.append(1)\n",
    "        else:\n",
    "            y_post.append(0)\n",
    "    return y_post\n",
    "\n",
    "def evaluate(y_true,y_pred,sa):\n",
    "    ## convert the probability estimates to class labels (MC Dropout)\n",
    "\n",
    "    ba = accuracy_score(y_true,y_pred)\n",
    "    us_s = UEI(sa, y_true, np.round(y_pred))\n",
    "    return ba,us_s\n",
    "\n",
    "y_probs_combined = np.stack([model(Xtrain) for model in trained_models])\n",
    "y_preds_combined = np.mean(y_probs_combined, axis=0)\n",
    "best_thres_0,best_thres_1 = find_thres(Xtrain[:,-1],np.array(y_preds_combined.ravel()),y_train)\n",
    "y_pred_post = make_pred(Xtrain[:,-1],np.array(y_preds_combined.ravel()),best_thres_0,best_thres_1)\n",
    "best_ba,best_us = evaluate(y_train,np.array(y_pred_post),Xtrain[:,-1])\n",
    "print(\"Train:\")\n",
    "print(best_ba,nll1(y_train,np.array(y_preds_combined.ravel())).numpy()/Xtrain.shape[0],best_us)\n",
    "## test\n",
    "y_probs_combined = np.stack([model(Xtest) for model in trained_models])\n",
    "y_preds_combined = np.mean(y_probs_combined, axis=0)\n",
    "y_pred_post = make_pred(Xtest[:,-1],np.array(y_preds_combined.ravel()),best_thres_0,best_thres_1)\n",
    "best_ba,best_us = evaluate(y_test,np.array(y_pred_post),Xtest[:,-1])\n",
    "print(\"Test:\")\n",
    "print(best_ba,nll1(y_test,np.array(y_preds_combined.ravel())).numpy()/Xtest.shape[0],best_us)\n",
    "\n",
    "print(\"US_S_0\")\n",
    "print(underestimation_score(y_test,y_pred_post,Xtest[:,-1]))\n",
    "print(\"US_S_1\")\n",
    "print(underestimation_score_1(y_test,y_pred_post,Xtest[:,-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# German"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data',header = None, delim_whitespace = True)\n",
    "dataset.columns=[\"Existing-Account-Status\",\"Month-Duration\",\"Credit-History\",\"Purpose\",\"Credit-Amount\",\"Saving-Acount\",\"Present-Employment\",\"Instalment-Rate\",\"Sex\",\"Guarantors\",\"Residence\",\"Property\",\"Age\",\"Installment\",\"Housing\",\"Existing-Credits\",\"Job\",\"Num-People\",\"Telephone\",\"Foreign-Worker\",\"Status\"]\n",
    "dataset.dropna(inplace=True)\n",
    "dataset['Status'] = dataset['Status'].apply(lambda x: 1 if x == 1 else 0)\n",
    "dataset['Age'] = dataset['Age'].apply(lambda x: 1 if x >= 25 else 0)\n",
    "y = dataset['Status']\n",
    "dataset.pop('Status')\n",
    "X = dataset\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, \n",
    "                                                    shuffle = True, random_state=40, stratify = y)\n",
    "Xtrain_num = X_train[[\"Month-Duration\",\"Credit-Amount\",\"Instalment-Rate\",\"Residence\",'Existing-Credits','Num-People']]\n",
    "x_train_cat = X_train[['Existing-Account-Status','Credit-History','Purpose','Saving-Acount', 'Present-Employment', 'Sex','Guarantors','Property','Installment','Housing','Job','Telephone','Foreign-Worker']]\n",
    "Xtest_num = X_test[[\"Month-Duration\",\"Credit-Amount\",\"Instalment-Rate\",\"Residence\",'Existing-Credits','Num-People']]\n",
    "x_test_cat = X_test[['Existing-Account-Status','Credit-History','Purpose','Saving-Acount', 'Present-Employment', 'Sex','Guarantors','Property','Installment','Housing','Job','Telephone','Foreign-Worker']]\n",
    "\n",
    "std = StandardScaler()\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "Xtrain_num = std.fit_transform(Xtrain_num)\n",
    "Xtest_num = std.transform(Xtest_num)\n",
    "x_train_cat = ohe.fit_transform(x_train_cat)\n",
    "x_test_cat = ohe.transform(x_test_cat)\n",
    "\n",
    "Xtrain = np.hstack((Xtrain_num,x_train_cat,X_train['Age'].values.reshape(-1,1)))\n",
    "Xtest = np.hstack((Xtest_num,x_test_cat,X_test['Age'].values.reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Deep Ensembles Model~~~~~~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:08<00:00,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6677 - accuracy: 0.7333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test results - Loss: 0.6677393913269043 - Accuracy: 0.7333333492279053%\n",
      "10/10 [==============================] - 0s 741us/step - loss: 0.6929 - accuracy: 0.7467\n",
      "Test results - Loss: 0.6929311156272888 - Accuracy: 0.746666669845581%\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6538 - accuracy: 0.7467\n",
      "Test results - Loss: 0.6537696123123169 - Accuracy: 0.746666669845581%\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7021 - accuracy: 0.7100\n",
      "Test results - Loss: 0.7021345496177673 - Accuracy: 0.7099999785423279%\n",
      "10/10 [==============================] - 0s 1000us/step - loss: 0.6689 - accuracy: 0.7133\n",
      "Test results - Loss: 0.668850839138031 - Accuracy: 0.7133333086967468%\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6583 - accuracy: 0.7333\n",
      "Test results - Loss: 0.6583468914031982 - Accuracy: 0.7333333492279053%\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7322 - accuracy: 0.7267\n",
      "Test results - Loss: 0.7321683764457703 - Accuracy: 0.7266666889190674%\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7097 - accuracy: 0.7167\n",
      "Test results - Loss: 0.7097263932228088 - Accuracy: 0.7166666388511658%\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6748 - accuracy: 0.7500\n",
      "Test results - Loss: 0.6748441457748413 - Accuracy: 0.75%\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6385 - accuracy: 0.7333\n",
      "Test results - Loss: 0.6384856104850769 - Accuracy: 0.7333333492279053%\n",
      "######################################################\n",
      " Loss    : 0.6798996925354004 - 0.027283316165740496\n",
      " Accuracy: 0.7310000002384186 - 0.013585132879486862%\n",
      "Deep Ensembles trained!!!~~~~~~~\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training standard NN Model~~~~~~~\n",
      "Epoch 1/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6343 - accuracy: 0.6671\n",
      "Epoch 2/80\n",
      "7/7 [==============================] - 0s 1000us/step - loss: 0.5456 - accuracy: 0.7300\n",
      "Epoch 3/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5029 - accuracy: 0.7486\n",
      "Epoch 4/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4848 - accuracy: 0.7543\n",
      "Epoch 5/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4645 - accuracy: 0.7771\n",
      "Epoch 6/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4512 - accuracy: 0.7914\n",
      "Epoch 7/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4456 - accuracy: 0.7857\n",
      "Epoch 8/80\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4425 - accuracy: 0.7871\n",
      "Epoch 9/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4390 - accuracy: 0.8014\n",
      "Epoch 10/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4345 - accuracy: 0.8000\n",
      "Epoch 11/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4324 - accuracy: 0.7986\n",
      "Epoch 12/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4310 - accuracy: 0.7957\n",
      "Epoch 13/80\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.7957\n",
      "Epoch 14/80\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.8000\n",
      "Epoch 15/80\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.7914\n",
      "Epoch 16/80\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.7971\n",
      "Epoch 17/80\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4245 - accuracy: 0.8014\n",
      "Epoch 18/80\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4217 - accuracy: 0.8029\n",
      "Epoch 19/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4232 - accuracy: 0.7943\n",
      "Epoch 20/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4214 - accuracy: 0.8000\n",
      "Epoch 21/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4192 - accuracy: 0.7986\n",
      "Epoch 22/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4206 - accuracy: 0.8000\n",
      "Epoch 23/80\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4176 - accuracy: 0.8214\n",
      "Epoch 24/80\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4153 - accuracy: 0.7986\n",
      "Epoch 25/80\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4144 - accuracy: 0.8143\n",
      "Epoch 26/80\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4125 - accuracy: 0.8143\n",
      "Epoch 27/80\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4137 - accuracy: 0.7929\n",
      "Epoch 28/80\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4100 - accuracy: 0.8143\n",
      "Epoch 29/80\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4073 - accuracy: 0.8186\n",
      "Epoch 30/80\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4073 - accuracy: 0.8043\n",
      "Epoch 31/80\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3994 - accuracy: 0.8186\n",
      "Epoch 32/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3989 - accuracy: 0.8143\n",
      "Epoch 33/80\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3965 - accuracy: 0.8171\n",
      "Epoch 34/80\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3912 - accuracy: 0.8300\n",
      "Epoch 35/80\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3901 - accuracy: 0.8086\n",
      "Epoch 36/80\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3870 - accuracy: 0.8329\n",
      "Epoch 37/80\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3818 - accuracy: 0.8257\n",
      "Epoch 38/80\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3769 - accuracy: 0.8229\n",
      "Epoch 39/80\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3735 - accuracy: 0.8371\n",
      "Epoch 40/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3683 - accuracy: 0.8400\n",
      "Epoch 41/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3627 - accuracy: 0.8471\n",
      "Epoch 42/80\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3587 - accuracy: 0.8486\n",
      "Epoch 43/80\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3541 - accuracy: 0.8471\n",
      "Epoch 44/80\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3501 - accuracy: 0.8471\n",
      "Epoch 45/80\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3428 - accuracy: 0.8514\n",
      "Epoch 46/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3385 - accuracy: 0.8543\n",
      "Epoch 47/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3335 - accuracy: 0.8571\n",
      "Epoch 48/80\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3282 - accuracy: 0.8614\n",
      "Epoch 49/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3233 - accuracy: 0.8657\n",
      "Epoch 50/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3180 - accuracy: 0.8614\n",
      "Epoch 51/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3122 - accuracy: 0.8714\n",
      "Epoch 52/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3088 - accuracy: 0.8700\n",
      "Epoch 53/80\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3024 - accuracy: 0.8843\n",
      "Epoch 54/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2948 - accuracy: 0.8814\n",
      "Epoch 55/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2879 - accuracy: 0.8943\n",
      "Epoch 56/80\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2805 - accuracy: 0.8929\n",
      "Epoch 57/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2745 - accuracy: 0.8914\n",
      "Epoch 58/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2697 - accuracy: 0.9000\n",
      "Epoch 59/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2627 - accuracy: 0.9014\n",
      "Epoch 60/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2583 - accuracy: 0.9043\n",
      "Epoch 61/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2526 - accuracy: 0.9114\n",
      "Epoch 62/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2499 - accuracy: 0.9014\n",
      "Epoch 63/80\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2476 - accuracy: 0.9186\n",
      "Epoch 64/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2420 - accuracy: 0.9157\n",
      "Epoch 65/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2305 - accuracy: 0.9214\n",
      "Epoch 66/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2220 - accuracy: 0.9214\n",
      "Epoch 67/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2173 - accuracy: 0.9257\n",
      "Epoch 68/80\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2132 - accuracy: 0.9271\n",
      "Epoch 69/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2064 - accuracy: 0.9329\n",
      "Epoch 70/80\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2001 - accuracy: 0.9386\n",
      "Epoch 71/80\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1962 - accuracy: 0.9429\n",
      "Epoch 72/80\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1922 - accuracy: 0.9443\n",
      "Epoch 73/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1881 - accuracy: 0.9486\n",
      "Epoch 74/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1832 - accuracy: 0.9514\n",
      "Epoch 75/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1775 - accuracy: 0.9529\n",
      "Epoch 76/80\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1724 - accuracy: 0.9543\n",
      "Epoch 77/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1668 - accuracy: 0.9600\n",
      "Epoch 78/80\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1613 - accuracy: 0.9657\n",
      "Epoch 79/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1558 - accuracy: 0.9629\n",
      "Epoch 80/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1514 - accuracy: 0.9671\n",
      "Standard NN trained!!!~~~~~~~\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Train Deep Ensembles Model\n",
    "print(\"Training Deep Ensembles Model~~~~~~~\")\n",
    "histories,trained_models = train(Xtrain, np.array(y_train).reshape(-1,1), epochs=80, batch=100)\n",
    "losses,accuracies = model_eval(Xtest,np.array(y_test).reshape(-1,1),trained_models)\n",
    "print(\"Deep Ensembles trained!!!~~~~~~~\")\n",
    "print(\"\\n\\n\\n\\n\\n\")\n",
    "## Train standard NN\n",
    "print(\"Training standard NN Model~~~~~~~\")\n",
    "DNN_model = Sequential([\n",
    "            Dense(50,activation='sigmoid'),\n",
    "            Dense(1,activation='sigmoid')])\n",
    "DNN_model.compile(tf.keras.optimizers.Adam(learning_rate=0.01), loss='binary_crossentropy',metrics=[\"accuracy\"])\n",
    "DNN_model.fit(Xtrain, np.array(y_train).reshape(-1,1), epochs=80, batch_size=100)\n",
    "print(\"Standard NN trained!!!~~~~~~~\")\n",
    "print(\"\\n\\n\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7219 - accuracy: 0.7267\n",
      "Test results - Loss: 0.7218554615974426 - Accuracy: 0.7266666889190674%\n",
      "ECE with n_bins = 5:\n",
      "ECE_DeepEnsembles:  0.1349\n",
      "ECE_StandardNN   :  0.1558\n",
      "UEI: \n",
      "UEI_DeepEnsembles:  0.021275742719243332\n",
      "UEI_StandardNN   :  0.02362591039193105\n",
      "US_0: \n",
      "191 185\n",
      "US0_DeepEnsembles:  1.0324324324324323\n",
      "193 185\n",
      "US0_StandardNN   :  1.0432432432432432\n",
      "US_1: \n",
      "23 25\n",
      "US1_DeepEnsembles:  0.92\n",
      "25 25\n",
      "US1_StandardNN   :  1.0\n"
     ]
    }
   ],
   "source": [
    "y_probs_combined = np.stack([model(Xtest) for model in trained_models])\n",
    "y_preds_combined = np.mean(y_probs_combined, axis=0)\n",
    "\n",
    "\n",
    "# Test the model after training\n",
    "test_results = DNN_model.evaluate(Xtest, np.array(y_test).reshape(-1,1), verbose=1)\n",
    "print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]}%')\n",
    "y_pred_1NN = DNN_model(Xtest)\n",
    "\n",
    "df = {}\n",
    "df['sa'] = Xtest[:,-1]\n",
    "df['actual'] = y_test\n",
    "df['Ensembles'] = y_preds_combined.ravel()\n",
    "df['DNN'] = np.array(y_pred_1NN).ravel()\n",
    "df = pd.DataFrame(df)\n",
    "\n",
    "print(\"ECE with n_bins = 5:\")\n",
    "print(\"ECE_DeepEnsembles: \",compute_calibration_error(np.array(y_test),y_preds_combined,n_bins=5))\n",
    "print(\"ECE_StandardNN   : \",compute_calibration_error(np.array(y_test),y_pred_1NN,n_bins=5))\n",
    "\n",
    "\n",
    "\n",
    "print(\"UEI: \")\n",
    "print(\"UEI_DeepEnsembles: \",UEI(df.sa.values, df.actual.values, np.round(df['Ensembles'].values)))\n",
    "print(\"UEI_StandardNN   : \",UEI(df.sa.values, df.actual.values, np.round(df['DNN'].values)))\n",
    "\n",
    "print(\"US_0: \")\n",
    "print(\"US0_DeepEnsembles: \",underestimation_score_1(df.actual.values, np.round(df['Ensembles'].values),df.sa.values))\n",
    "print(\"US0_StandardNN   : \",underestimation_score_1(df.actual.values, np.round(df['DNN'].values),df.sa.values))\n",
    "\n",
    "print(\"US_1: \")\n",
    "print(\"US1_DeepEnsembles: \",underestimation_score(df.actual.values, np.round(df['Ensembles'].values),df.sa.values))\n",
    "print(\"US1_StandardNN   : \",underestimation_score(df.actual.values, np.round(df['DNN'].values),df.sa.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECE with n_bins = 5:\n",
      "ECE_DeepEnsembles_Maj:  0.1735\n",
      "ECE_DeepEnsembles_Min   :  0.1348\n",
      "ECE with n_bins = 5:\n",
      "ECE_DNN_Maj:  0.1581\n",
      "ECE_DNN_Min   :  0.165\n"
     ]
    }
   ],
   "source": [
    "from sklearn.calibration import calibration_curve\n",
    "prob_true, prob_pred = calibration_curve(y_test, y_preds_combined, n_bins=5)\n",
    "prob_true_dnn, prob_pred_dnn = calibration_curve(y_test, y_pred_1NN, n_bins=5)\n",
    "minority = df[df['sa'] == 1]\n",
    "majority = df[df['sa'] == 0]\n",
    "prob_true_maj, prob_pred_maj = calibration_curve(np.array(majority.actual), majority['Ensembles'].values.reshape(-1,1), n_bins=5)\n",
    "prob_true_min, prob_pred_min = calibration_curve(np.array(minority.actual), minority['Ensembles'].values.reshape(-1,1), n_bins=5)\n",
    "prob_true_dnn_maj, prob_pre_dnnd_maj = calibration_curve(np.array(majority.actual), majority['DNN'].values.reshape(-1,1), n_bins=5)\n",
    "prob_true_dnn_min, prob_pred_dnn_min = calibration_curve(np.array(minority.actual), minority['DNN'].values.reshape(-1,1), n_bins=5)\n",
    "\n",
    "print(\"ECE with n_bins = 5:\")\n",
    "print(\"ECE_DeepEnsembles_Maj: \",compute_calibration_error(np.array(majority.actual), majority['Ensembles'].values.reshape(-1,1), n_bins=5))\n",
    "print(\"ECE_DeepEnsembles_Min   : \",compute_calibration_error(np.array(minority.actual), minority['Ensembles'].values.reshape(-1,1), n_bins=5))\n",
    "\n",
    "print(\"ECE with n_bins = 5:\")\n",
    "print(\"ECE_DNN_Maj: \",compute_calibration_error(np.array(majority.actual), majority['DNN'].values.reshape(-1,1), n_bins=5))\n",
    "print(\"ECE_DNN_Min   : \",compute_calibration_error(np.array(minority.actual), minority['DNN'].values.reshape(-1,1), n_bins=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best threshold for s=0 that minimizes P(Y|S) - P(Yhat|S) is:  0.494949494949495\n",
      "best threshold for s=1 that minimizes P(Y|S) - P(Yhat|S) is:  0.5858585858585859\n",
      "Train:\n",
      "0.9657142857142857 0.16171357291085378 0.0\n",
      "Test:\n",
      "0.73 0.642433115641276 0.023242002652238684\n",
      "US_S_0\n",
      "23 25\n",
      "0.92\n",
      "US_S_1\n",
      "178 185\n",
      "0.9621621621621622\n"
     ]
    }
   ],
   "source": [
    "## Post-processing\n",
    "\n",
    "def find_thres(group,clf_prob,truth):\n",
    "    ls_0 = {}\n",
    "    ls_1 = {}\n",
    "    thresholds = np.linspace(0, 1, num=100)\n",
    "    for thres in thresholds:\n",
    "        df = {}\n",
    "        df['sa'] = group\n",
    "        df['prob'] = clf_prob\n",
    "        df['ground_truth'] = truth\n",
    "        df['prob_pred'] =[0]*len(truth)\n",
    "        df = pd.DataFrame(df)\n",
    "        df.loc[ (df['sa'] == 0) & (df['prob'] > thres),'prob_pred'] = 1\n",
    "        df.loc[ (df['sa'] == 1) & (df['prob'] > thres),'prob_pred'] = 1\n",
    "        US_pred_0 = df_count_feat_val_match(df, 'prob_pred', 1, 'sa',0)\n",
    "        US_true_0 = df_count_feat_val_match(df, 'ground_truth', 1, 'sa',0)\n",
    "        US_pred_1 = df_count_feat_val_match(df, 'prob_pred', 1, 'sa',1)\n",
    "        US_true_1 = df_count_feat_val_match(df, 'ground_truth', 1, 'sa',1)\n",
    "        ls_0[thres] = np.abs(US_pred_0-US_true_0)\n",
    "        ls_1[thres] = np.abs(US_pred_1-US_true_1)\n",
    "    best_0 = thresholds[np.argmin(list(ls_0.values()))]\n",
    "    best_1 = thresholds[np.argmin(list(ls_1.values()))]\n",
    "    print(\"best threshold for s=0 that minimizes P(Y|S) - P(Yhat|S) is: \",best_0)\n",
    "    print(\"best threshold for s=1 that minimizes P(Y|S) - P(Yhat|S) is: \",best_1)\n",
    "    return best_0,best_1\n",
    "\n",
    "def make_pred(group,clf_prob,thres_0,thres_1):\n",
    "    y_post = []\n",
    "    for sa,predictproba in zip(group,clf_prob):\n",
    "        if sa == 0 and predictproba > thres_0:\n",
    "            y_post.append(1)\n",
    "        elif sa == 0 and predictproba <= thres_0:\n",
    "            y_post.append(0)\n",
    "        elif sa == 1 and predictproba > thres_1:\n",
    "            y_post.append(1)\n",
    "        else:\n",
    "            y_post.append(0)\n",
    "    return y_post\n",
    "\n",
    "def evaluate(y_true,y_pred,sa):\n",
    "    ## convert the probability estimates to class labels (MC Dropout)\n",
    "\n",
    "    ba = accuracy_score(y_true,y_pred)\n",
    "    us_s = UEI(sa, y_true, np.round(y_pred))\n",
    "    return ba,us_s\n",
    "\n",
    "y_probs_combined = np.stack([model(Xtrain) for model in trained_models])\n",
    "y_preds_combined = np.mean(y_probs_combined, axis=0)\n",
    "best_thres_0,best_thres_1 = find_thres(Xtrain[:,-1],np.array(y_preds_combined.ravel()),y_train)\n",
    "y_pred_post = make_pred(Xtrain[:,-1],np.array(y_preds_combined.ravel()),best_thres_0,best_thres_1)\n",
    "best_ba,best_us = evaluate(y_train,np.array(y_pred_post),Xtrain[:,-1])\n",
    "print(\"Train:\")\n",
    "print(best_ba,nll1(y_train,np.array(y_preds_combined.ravel())).numpy()/Xtrain.shape[0],best_us)\n",
    "## test\n",
    "y_probs_combined = np.stack([model(Xtest) for model in trained_models])\n",
    "y_preds_combined = np.mean(y_probs_combined, axis=0)\n",
    "y_pred_post = make_pred(Xtest[:,-1],np.array(y_preds_combined.ravel()),best_thres_0,best_thres_1)\n",
    "best_ba,best_us = evaluate(y_test,np.array(y_pred_post),Xtest[:,-1])\n",
    "print(\"Test:\")\n",
    "print(best_ba,nll1(y_test,np.array(y_preds_combined.ravel())).numpy()/Xtest.shape[0],best_us)\n",
    "\n",
    "print(\"US_S_0\")\n",
    "print(underestimation_score(y_test,y_pred_post,Xtest[:,-1]))\n",
    "print(\"US_S_1\")\n",
    "print(underestimation_score_1(y_test,y_pred_post,Xtest[:,-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('communities_crime.csv')\n",
    "dataset.pop('state') ## these categorical variables are no use in predicting\n",
    "dataset.pop('communityname')\n",
    "dataset.pop('fold')\n",
    "dataset.pop('ViolentCrimesPerPop') ## class label is created based on violentcrimesperpop attribute so it makes sense to remove it\n",
    "y = dataset['class']\n",
    "dataset.pop('class')\n",
    "X = dataset\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, \n",
    "                                                    shuffle = True, random_state=40, stratify = y)\n",
    "Xtrain_num = X_train[[\"population\",\"householdsize\",\"racepctblack\",\"racePctWhite\",\"racePctAsian\",\"racePctHisp\",\"agePct12t21\",\"agePct12t29\",\"agePct16t24\",\"agePct65up\",\"numbUrban\",\"pctUrban\",\"medIncome\",\"pctWWage\",\"pctWFarmSelf\",\"pctWInvInc\",\"pctWSocSec\",\"pctWPubAsst\",\"pctWRetire\",\"medFamInc\",\"perCapInc\",\"whitePerCap\",\"blackPerCap\",\"indianPerCap\",\"AsianPerCap\",\"HispPerCap\",\"NumUnderPov\",\"PctPopUnderPov\",\"PctLess9thGrade\",\"PctNotHSGrad\",\"PctBSorMore\",\"PctUnemployed\",\"PctEmploy\",\"PctEmplManu\",\"PctEmplProfServ\",\"PctOccupManu\",\"PctOccupMgmtProf\",\"MalePctDivorce\",\"MalePctNevMarr\",\"FemalePctDiv\",\"TotalPctDiv\",\"PersPerFam\",\"PctFam2Par\",\"PctKids2Par\",\"PctYoungKids2Par\",\"PctTeen2Par\",\"PctWorkMomYoungKids\",\"PctWorkMom\",\"NumIlleg\",\"PctIlleg\",\"NumImmig\",\"PctImmigRecent\",\"PctImmigRec5\",\"PctImmigRec8\",\"PctImmigRec10\",\"PctRecentImmig\",\"PctRecImmig5\",\"PctRecImmig8\",\"PctRecImmig10\",\"PctSpeakEnglOnly\",\"PctNotSpeakEnglWell\",\"PctLargHouseFam\",\"PctLargHouseOccup\",\"PersPerOccupHous\",\"PersPerOwnOccHous\",\"PersPerRentOccHous\",\"PctPersOwnOccup\",\"PctPersDenseHous\",\"PctHousLess3BR\",\"MedNumBR\",\"HousVacant\",\"PctHousOccup\",\"PctHousOwnOcc\",\"PctVacantBoarded\",\"PctVacMore6Mos\",\"MedYrHousBuilt\",\"PctHousNoPhone\",\"PctWOFullPlumb\",\"OwnOccLowQuart\",\"OwnOccMedVal\",\"OwnOccHiQuart\",\"RentLowQ\",\"RentMedian\",\"RentHighQ\",\"MedRent\",\"MedRentPctHousInc\",\"MedOwnCostPctInc\",\"MedOwnCostPctIncNoMtg\",\"NumInShelters\",\"NumStreet\",\"PctForeignBorn\",\"PctBornSameState\",\"PctSameHouse85\",\"PctSameCity85\",\"PctSameState85\",\"LandArea\",\"PopDens\",\"PctUsePubTrans\",\"LemasPctOfficDrugUn\"\n",
    "                     ]]# x_train_cat = X_train[['fam_inc','tier']]\n",
    "Xtest_num = X_test[[\"population\",\"householdsize\",\"racepctblack\",\"racePctWhite\",\"racePctAsian\",\"racePctHisp\",\"agePct12t21\",\"agePct12t29\",\"agePct16t24\",\"agePct65up\",\"numbUrban\",\"pctUrban\",\"medIncome\",\"pctWWage\",\"pctWFarmSelf\",\"pctWInvInc\",\"pctWSocSec\",\"pctWPubAsst\",\"pctWRetire\",\"medFamInc\",\"perCapInc\",\"whitePerCap\",\"blackPerCap\",\"indianPerCap\",\"AsianPerCap\",\"HispPerCap\",\"NumUnderPov\",\"PctPopUnderPov\",\"PctLess9thGrade\",\"PctNotHSGrad\",\"PctBSorMore\",\"PctUnemployed\",\"PctEmploy\",\"PctEmplManu\",\"PctEmplProfServ\",\"PctOccupManu\",\"PctOccupMgmtProf\",\"MalePctDivorce\",\"MalePctNevMarr\",\"FemalePctDiv\",\"TotalPctDiv\",\"PersPerFam\",\"PctFam2Par\",\"PctKids2Par\",\"PctYoungKids2Par\",\"PctTeen2Par\",\"PctWorkMomYoungKids\",\"PctWorkMom\",\"NumIlleg\",\"PctIlleg\",\"NumImmig\",\"PctImmigRecent\",\"PctImmigRec5\",\"PctImmigRec8\",\"PctImmigRec10\",\"PctRecentImmig\",\"PctRecImmig5\",\"PctRecImmig8\",\"PctRecImmig10\",\"PctSpeakEnglOnly\",\"PctNotSpeakEnglWell\",\"PctLargHouseFam\",\"PctLargHouseOccup\",\"PersPerOccupHous\",\"PersPerOwnOccHous\",\"PersPerRentOccHous\",\"PctPersOwnOccup\",\"PctPersDenseHous\",\"PctHousLess3BR\",\"MedNumBR\",\"HousVacant\",\"PctHousOccup\",\"PctHousOwnOcc\",\"PctVacantBoarded\",\"PctVacMore6Mos\",\"MedYrHousBuilt\",\"PctHousNoPhone\",\"PctWOFullPlumb\",\"OwnOccLowQuart\",\"OwnOccMedVal\",\"OwnOccHiQuart\",\"RentLowQ\",\"RentMedian\",\"RentHighQ\",\"MedRent\",\"MedRentPctHousInc\",\"MedOwnCostPctInc\",\"MedOwnCostPctIncNoMtg\",\"NumInShelters\",\"NumStreet\",\"PctForeignBorn\",\"PctBornSameState\",\"PctSameHouse85\",\"PctSameCity85\",\"PctSameState85\",\"LandArea\",\"PopDens\",\"PctUsePubTrans\",\"LemasPctOfficDrugUn\"\n",
    "                   ]]\n",
    "\n",
    "std = MinMaxScaler()\n",
    "# ohe = OneHotEncoder(sparse=False)\n",
    "Xtrain_num = std.fit_transform(Xtrain_num)\n",
    "Xtest_num = std.transform(Xtest_num)\n",
    "# x_train_cat = ohe.fit_transform(x_train_cat)\n",
    "# x_test_cat = ohe.transform(x_test_cat)\n",
    "\n",
    "Xtrain = np.hstack((Xtrain_num,X_train['Black'].values.reshape(-1,1)))\n",
    "Xtest = np.hstack((Xtest_num,X_test['Black'].values.reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Deep Ensembles Model~~~~~~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:11<00:00,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 839us/step - loss: 0.1322 - accuracy: 0.9418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test results - Loss: 0.1321849524974823 - Accuracy: 0.9418254494667053%\n",
      "32/32 [==============================] - 0s 806us/step - loss: 0.1330 - accuracy: 0.9488\n",
      "Test results - Loss: 0.13300293684005737 - Accuracy: 0.9488465189933777%\n",
      "32/32 [==============================] - 0s 839us/step - loss: 0.1318 - accuracy: 0.9468\n",
      "Test results - Loss: 0.13181757926940918 - Accuracy: 0.9468405246734619%\n",
      "32/32 [==============================] - 0s 871us/step - loss: 0.1333 - accuracy: 0.9458\n",
      "Test results - Loss: 0.13329793512821198 - Accuracy: 0.9458374977111816%\n",
      "32/32 [==============================] - 0s 871us/step - loss: 0.1416 - accuracy: 0.9498\n",
      "Test results - Loss: 0.14160077273845673 - Accuracy: 0.949849545955658%\n",
      "32/32 [==============================] - 0s 871us/step - loss: 0.1333 - accuracy: 0.9448\n",
      "Test results - Loss: 0.13334858417510986 - Accuracy: 0.9448345303535461%\n",
      "32/32 [==============================] - 0s 839us/step - loss: 0.1386 - accuracy: 0.9498\n",
      "Test results - Loss: 0.13864058256149292 - Accuracy: 0.949849545955658%\n",
      "32/32 [==============================] - 0s 935us/step - loss: 0.1336 - accuracy: 0.9438\n",
      "Test results - Loss: 0.13364996016025543 - Accuracy: 0.9438315033912659%\n",
      "32/32 [==============================] - 0s 935us/step - loss: 0.1313 - accuracy: 0.9438\n",
      "Test results - Loss: 0.1312551647424698 - Accuracy: 0.9438315033912659%\n",
      "32/32 [==============================] - 0s 968us/step - loss: 0.1359 - accuracy: 0.9458\n",
      "Test results - Loss: 0.1358862817287445 - Accuracy: 0.9458374977111816%\n",
      "######################################################\n",
      " Loss    : 0.134468474984169 - 0.0031352113509634637\n",
      " Accuracy: 0.9461384117603302 - 0.0025787272598238775%\n",
      "Deep Ensembles trained!!!~~~~~~~\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training standard NN Model~~~~~~~\n",
      "Epoch 1/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3969 - accuracy: 0.8546\n",
      "Epoch 2/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2895 - accuracy: 0.9388\n",
      "Epoch 3/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2580 - accuracy: 0.9388\n",
      "Epoch 4/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2260 - accuracy: 0.9388\n",
      "Epoch 5/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2090 - accuracy: 0.9388\n",
      "Epoch 6/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1898 - accuracy: 0.9388\n",
      "Epoch 7/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1700 - accuracy: 0.9418\n",
      "Epoch 8/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1557 - accuracy: 0.9468\n",
      "Epoch 9/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1467 - accuracy: 0.9468\n",
      "Epoch 10/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1411 - accuracy: 0.9468\n",
      "Epoch 11/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1368 - accuracy: 0.9509\n",
      "Epoch 12/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1339 - accuracy: 0.9529\n",
      "Epoch 13/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1323 - accuracy: 0.9509\n",
      "Epoch 14/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1315 - accuracy: 0.9539\n",
      "Epoch 15/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1316 - accuracy: 0.9539\n",
      "Epoch 16/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1288 - accuracy: 0.9519\n",
      "Epoch 17/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1280 - accuracy: 0.9529\n",
      "Epoch 18/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1296 - accuracy: 0.9539\n",
      "Epoch 19/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1270 - accuracy: 0.9519\n",
      "Epoch 20/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1271 - accuracy: 0.9539\n",
      "Epoch 21/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1244 - accuracy: 0.9549\n",
      "Epoch 22/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1244 - accuracy: 0.9559\n",
      "Epoch 23/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1235 - accuracy: 0.9549\n",
      "Epoch 24/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1232 - accuracy: 0.9559\n",
      "Epoch 25/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1220 - accuracy: 0.9569\n",
      "Epoch 26/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1219 - accuracy: 0.9519\n",
      "Epoch 27/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1240 - accuracy: 0.9529\n",
      "Epoch 28/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1249 - accuracy: 0.9559\n",
      "Epoch 29/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1198 - accuracy: 0.9559\n",
      "Epoch 30/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1231 - accuracy: 0.9549\n",
      "Epoch 31/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1225 - accuracy: 0.9539\n",
      "Epoch 32/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1200 - accuracy: 0.9569\n",
      "Epoch 33/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1197 - accuracy: 0.9569\n",
      "Epoch 34/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1217 - accuracy: 0.9569\n",
      "Epoch 35/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1191 - accuracy: 0.9579\n",
      "Epoch 36/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1180 - accuracy: 0.9569\n",
      "Epoch 37/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1167 - accuracy: 0.9579\n",
      "Epoch 38/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1220 - accuracy: 0.9539\n",
      "Epoch 39/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1224 - accuracy: 0.9529\n",
      "Epoch 40/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1168 - accuracy: 0.9559\n",
      "Epoch 41/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1168 - accuracy: 0.9579\n",
      "Epoch 42/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1168 - accuracy: 0.9589\n",
      "Epoch 43/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1164 - accuracy: 0.9579\n",
      "Epoch 44/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1158 - accuracy: 0.9559\n",
      "Epoch 45/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1170 - accuracy: 0.9579\n",
      "Epoch 46/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1154 - accuracy: 0.9569\n",
      "Epoch 47/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1144 - accuracy: 0.9599\n",
      "Epoch 48/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1145 - accuracy: 0.9559\n",
      "Epoch 49/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1158 - accuracy: 0.9569\n",
      "Epoch 50/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1166 - accuracy: 0.9579\n",
      "Epoch 51/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1156 - accuracy: 0.9569\n",
      "Epoch 52/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1138 - accuracy: 0.9569\n",
      "Epoch 53/80\n",
      "10/10 [==============================] - 0s 778us/step - loss: 0.1130 - accuracy: 0.9589\n",
      "Epoch 54/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1141 - accuracy: 0.9589\n",
      "Epoch 55/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1160 - accuracy: 0.9559\n",
      "Epoch 56/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1148 - accuracy: 0.9579\n",
      "Epoch 57/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1163 - accuracy: 0.9579\n",
      "Epoch 58/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1124 - accuracy: 0.9579\n",
      "Epoch 59/80\n",
      "10/10 [==============================] - 0s 985us/step - loss: 0.1130 - accuracy: 0.9589\n",
      "Epoch 60/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1141 - accuracy: 0.9569\n",
      "Epoch 61/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1138 - accuracy: 0.9589\n",
      "Epoch 62/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1132 - accuracy: 0.9579\n",
      "Epoch 63/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1097 - accuracy: 0.9589\n",
      "Epoch 64/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1138 - accuracy: 0.9589\n",
      "Epoch 65/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1112 - accuracy: 0.9569\n",
      "Epoch 66/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1127 - accuracy: 0.9599\n",
      "Epoch 67/80\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1098 - accuracy: 0.9589\n",
      "Epoch 68/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1107 - accuracy: 0.9569\n",
      "Epoch 69/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1084 - accuracy: 0.9599\n",
      "Epoch 70/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1107 - accuracy: 0.9569\n",
      "Epoch 71/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1104 - accuracy: 0.9599\n",
      "Epoch 72/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1064 - accuracy: 0.9619\n",
      "Epoch 73/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1061 - accuracy: 0.9599\n",
      "Epoch 74/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1074 - accuracy: 0.9589\n",
      "Epoch 75/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1094 - accuracy: 0.9579\n",
      "Epoch 76/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1095 - accuracy: 0.9579\n",
      "Epoch 77/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1075 - accuracy: 0.9599\n",
      "Epoch 78/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1052 - accuracy: 0.9599\n",
      "Epoch 79/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1061 - accuracy: 0.9589\n",
      "Epoch 80/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1055 - accuracy: 0.9599\n",
      "Standard NN trained!!!~~~~~~~\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Train Deep Ensembles Model\n",
    "print(\"Training Deep Ensembles Model~~~~~~~\")\n",
    "histories,trained_models = train(Xtrain, np.array(y_train).reshape(-1,1), epochs=80, batch=100)\n",
    "losses,accuracies = model_eval(Xtest,np.array(y_test).reshape(-1,1),trained_models)\n",
    "print(\"Deep Ensembles trained!!!~~~~~~~\")\n",
    "print(\"\\n\\n\\n\\n\\n\")\n",
    "## Train standard NN\n",
    "print(\"Training standard NN Model~~~~~~~\")\n",
    "DNN_model = Sequential([\n",
    "            Dense(50,activation='sigmoid'),\n",
    "            Dense(1,activation='sigmoid')])\n",
    "DNN_model.compile(tf.keras.optimizers.Adam(learning_rate=0.01), loss='binary_crossentropy',metrics=[\"accuracy\"])\n",
    "DNN_model.fit(Xtrain, np.array(y_train).reshape(-1,1), epochs=80, batch_size=100)\n",
    "print(\"Standard NN trained!!!~~~~~~~\")\n",
    "print(\"\\n\\n\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1318 - accuracy: 0.9458\n",
      "Test results - Loss: 0.13182878494262695 - Accuracy: 0.9458374977111816%\n",
      "ECE with n_bins = 5:\n",
      "ECE_DeepEnsembles:  0.0057\n",
      "ECE_StandardNN   :  0.0244\n",
      "UEI: \n",
      "UEI_DeepEnsembles:  0.05164268123882618\n",
      "UEI_StandardNN   :  0.04431847364317985\n",
      "US_0: \n",
      "38 58\n",
      "US0_DeepEnsembles:  0.6551724137931034\n",
      "45 58\n",
      "US0_StandardNN   :  0.7758620689655172\n",
      "US_1: \n",
      "0 3\n",
      "US1_DeepEnsembles:  0.0\n",
      "0 3\n",
      "US1_StandardNN   :  0.0\n"
     ]
    }
   ],
   "source": [
    "y_probs_combined = np.stack([model(Xtest) for model in trained_models])\n",
    "y_preds_combined = np.mean(y_probs_combined, axis=0)\n",
    "\n",
    "\n",
    "# Test the model after training\n",
    "test_results = DNN_model.evaluate(Xtest, np.array(y_test).reshape(-1,1), verbose=1)\n",
    "print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]}%')\n",
    "y_pred_1NN = DNN_model(Xtest)\n",
    "\n",
    "df = {}\n",
    "df['sa'] = Xtest[:,-1]\n",
    "df['actual'] = y_test\n",
    "df['Ensembles'] = y_preds_combined.ravel()\n",
    "df['DNN'] = np.array(y_pred_1NN).ravel()\n",
    "df = pd.DataFrame(df)\n",
    "\n",
    "print(\"ECE with n_bins = 5:\")\n",
    "print(\"ECE_DeepEnsembles: \",compute_calibration_error(np.array(y_test),y_preds_combined,n_bins=5))\n",
    "print(\"ECE_StandardNN   : \",compute_calibration_error(np.array(y_test),y_pred_1NN,n_bins=5))\n",
    "\n",
    "\n",
    "\n",
    "print(\"UEI: \")\n",
    "print(\"UEI_DeepEnsembles: \",UEI(df.sa.values, df.actual.values, np.round(df['Ensembles'].values)))\n",
    "print(\"UEI_StandardNN   : \",UEI(df.sa.values, df.actual.values, np.round(df['DNN'].values)))\n",
    "\n",
    "print(\"US_0: \")\n",
    "print(\"US0_DeepEnsembles: \",underestimation_score_1(df.actual.values, np.round(df['Ensembles'].values),df.sa.values))\n",
    "print(\"US0_StandardNN   : \",underestimation_score_1(df.actual.values, np.round(df['DNN'].values),df.sa.values))\n",
    "\n",
    "print(\"US_1: \")\n",
    "print(\"US1_DeepEnsembles: \",underestimation_score(df.actual.values, np.round(df['Ensembles'].values),df.sa.values))\n",
    "print(\"US1_StandardNN   : \",underestimation_score(df.actual.values, np.round(df['DNN'].values),df.sa.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECE with n_bins = 5:\n",
      "ECE_DeepEnsembles_Maj:  0.0062\n",
      "ECE_DeepEnsembles_Min   :  0.012\n",
      "ECE with n_bins = 5:\n",
      "ECE_DNN_Maj:  0.005\n",
      "ECE_DNN_Min   :  0.0295\n"
     ]
    }
   ],
   "source": [
    "from sklearn.calibration import calibration_curve\n",
    "prob_true, prob_pred = calibration_curve(y_test, y_preds_combined, n_bins=5)\n",
    "prob_true_dnn, prob_pred_dnn = calibration_curve(y_test, y_pred_1NN, n_bins=5)\n",
    "minority = df[df['sa'] == 1]\n",
    "majority = df[df['sa'] == 0]\n",
    "prob_true_maj, prob_pred_maj = calibration_curve(np.array(majority.actual), majority['Ensembles'].values.reshape(-1,1), n_bins=5)\n",
    "prob_true_min, prob_pred_min = calibration_curve(np.array(minority.actual), minority['Ensembles'].values.reshape(-1,1), n_bins=5)\n",
    "prob_true_dnn_maj, prob_pre_dnnd_maj = calibration_curve(np.array(majority.actual), majority['DNN'].values.reshape(-1,1), n_bins=5)\n",
    "prob_true_dnn_min, prob_pred_dnn_min = calibration_curve(np.array(minority.actual), minority['DNN'].values.reshape(-1,1), n_bins=5)\n",
    "\n",
    "print(\"ECE with n_bins = 5:\")\n",
    "print(\"ECE_DeepEnsembles_Maj: \",compute_calibration_error(np.array(majority.actual), majority['Ensembles'].values.reshape(-1,1), n_bins=5))\n",
    "print(\"ECE_DeepEnsembles_Min   : \",compute_calibration_error(np.array(minority.actual), minority['Ensembles'].values.reshape(-1,1), n_bins=5))\n",
    "\n",
    "print(\"ECE with n_bins = 5:\")\n",
    "print(\"ECE_DNN_Maj: \",compute_calibration_error(np.array(majority.actual), majority['DNN'].values.reshape(-1,1), n_bins=5))\n",
    "print(\"ECE_DNN_Min   : \",compute_calibration_error(np.array(minority.actual), minority['DNN'].values.reshape(-1,1), n_bins=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best threshold for s=0 that minimizes P(Y|S) - P(Yhat|S) is:  0.07070707070707072\n",
      "best threshold for s=1 that minimizes P(Y|S) - P(Yhat|S) is:  0.3434343434343435\n",
      "Train:\n",
      "0.954864593781344 0.10026729357995863 0.005310894385419993\n",
      "Test:\n",
      "0.9388164493480441 0.1313958354555855 0.0015635611847964678\n",
      "US_S_0\n",
      "3 3\n",
      "1.0\n",
      "US_S_1\n",
      "57 58\n",
      "0.9827586206896551\n"
     ]
    }
   ],
   "source": [
    "## Post-processing\n",
    "\n",
    "def find_thres(group,clf_prob,truth):\n",
    "    ls_0 = {}\n",
    "    ls_1 = {}\n",
    "    thresholds = np.linspace(0, 1, num=100)\n",
    "    for thres in thresholds:\n",
    "        df = {}\n",
    "        df['sa'] = group\n",
    "        df['prob'] = clf_prob\n",
    "        df['ground_truth'] = truth\n",
    "        df['prob_pred'] =[0]*len(truth)\n",
    "        df = pd.DataFrame(df)\n",
    "        df.loc[ (df['sa'] == 0) & (df['prob'] > thres),'prob_pred'] = 1\n",
    "        df.loc[ (df['sa'] == 1) & (df['prob'] > thres),'prob_pred'] = 1\n",
    "        US_pred_0 = df_count_feat_val_match(df, 'prob_pred', 1, 'sa',0)\n",
    "        US_true_0 = df_count_feat_val_match(df, 'ground_truth', 1, 'sa',0)\n",
    "        US_pred_1 = df_count_feat_val_match(df, 'prob_pred', 1, 'sa',1)\n",
    "        US_true_1 = df_count_feat_val_match(df, 'ground_truth', 1, 'sa',1)\n",
    "        ls_0[thres] = np.abs(US_pred_0-US_true_0)\n",
    "        ls_1[thres] = np.abs(US_pred_1-US_true_1)\n",
    "    best_0 = thresholds[np.argmin(list(ls_0.values()))]\n",
    "    best_1 = thresholds[np.argmin(list(ls_1.values()))]\n",
    "    print(\"best threshold for s=0 that minimizes P(Y|S) - P(Yhat|S) is: \",best_0)\n",
    "    print(\"best threshold for s=1 that minimizes P(Y|S) - P(Yhat|S) is: \",best_1)\n",
    "    return best_0,best_1\n",
    "\n",
    "def make_pred(group,clf_prob,thres_0,thres_1):\n",
    "    y_post = []\n",
    "    for sa,predictproba in zip(group,clf_prob):\n",
    "        if sa == 0 and predictproba > thres_0:\n",
    "            y_post.append(1)\n",
    "        elif sa == 0 and predictproba <= thres_0:\n",
    "            y_post.append(0)\n",
    "        elif sa == 1 and predictproba > thres_1:\n",
    "            y_post.append(1)\n",
    "        else:\n",
    "            y_post.append(0)\n",
    "    return y_post\n",
    "\n",
    "def evaluate(y_true,y_pred,sa):\n",
    "    ## convert the probability estimates to class labels (MC Dropout)\n",
    "\n",
    "    ba = accuracy_score(y_true,y_pred)\n",
    "    us_s = UEI(sa, y_true, np.round(y_pred))\n",
    "    return ba,us_s\n",
    "\n",
    "y_probs_combined = np.stack([model(Xtrain) for model in trained_models])\n",
    "y_preds_combined = np.mean(y_probs_combined, axis=0)\n",
    "best_thres_0,best_thres_1 = find_thres(Xtrain[:,-1],np.array(y_preds_combined.ravel()),y_train)\n",
    "y_pred_post = make_pred(Xtrain[:,-1],np.array(y_preds_combined.ravel()),best_thres_0,best_thres_1)\n",
    "best_ba,best_us = evaluate(y_train,np.array(y_pred_post),Xtrain[:,-1])\n",
    "print(\"Train:\")\n",
    "print(best_ba,nll1(y_train,np.array(y_preds_combined.ravel())).numpy()/Xtrain.shape[0],best_us)\n",
    "## test\n",
    "y_probs_combined = np.stack([model(Xtest) for model in trained_models])\n",
    "y_preds_combined = np.mean(y_probs_combined, axis=0)\n",
    "y_pred_post = make_pred(Xtest[:,-1],np.array(y_preds_combined.ravel()),best_thres_0,best_thres_1)\n",
    "best_ba,best_us = evaluate(y_test,np.array(y_pred_post),Xtest[:,-1])\n",
    "print(\"Test:\")\n",
    "print(best_ba,nll1(y_test,np.array(y_preds_combined.ravel())).numpy()/Xtest.shape[0],best_us)\n",
    "\n",
    "print(\"US_S_0\")\n",
    "print(underestimation_score(y_test,y_pred_post,Xtest[:,-1]))\n",
    "print(\"US_S_1\")\n",
    "print(underestimation_score_1(y_test,y_pred_post,Xtest[:,-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset =    pd.read_csv(\"titanic.csv\")\n",
    "dataset.pop('PassengerId')\n",
    "dataset.pop('Name')\n",
    "dataset.pop('Ticket')\n",
    "dataset['Cabin'] = dataset['Cabin'].fillna(dataset['Cabin'].mode()[0])\n",
    "dataset['Embarked'] = dataset['Embarked'].fillna(dataset['Embarked'].mode()[0])\n",
    "dataset['Age'] = dataset['Age'].fillna(dataset['Age'].mean())\n",
    "dataset['Sex'] = dataset['Sex'].apply(lambda x: 1 if x == 'female' else 0)\n",
    "y = dataset['Survived']\n",
    "dataset.pop('Survived')\n",
    "X = dataset\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, \n",
    "                                                    shuffle = True, random_state=40, stratify = y)\n",
    "Xtrain_num = X_train[[\"Age\",\"Fare\"]]\n",
    "x_train_cat = X_train[['Pclass','SibSp','Parch','Embarked']]\n",
    "Xtest_num = X_test[[\"Age\",\"Fare\"]]\n",
    "x_test_cat = X_test[['Pclass','SibSp','Parch','Embarked']]\n",
    "\n",
    "std = StandardScaler()\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "Xtrain_num = std.fit_transform(Xtrain_num)\n",
    "Xtest_num = std.transform(Xtest_num)\n",
    "x_train_cat = ohe.fit_transform(x_train_cat)\n",
    "x_test_cat = ohe.transform(x_test_cat)\n",
    "\n",
    "Xtrain = np.hstack((Xtrain_num,x_train_cat,X_train['Sex'].values.reshape(-1,1)))\n",
    "Xtest = np.hstack((Xtest_num,x_test_cat,X_test['Sex'].values.reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Deep Ensembles Model~~~~~~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:08<00:00,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4230 - accuracy: 0.8321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test results - Loss: 0.42300447821617126 - Accuracy: 0.8320895433425903%\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.4270 - accuracy: 0.8358\n",
      "Test results - Loss: 0.4270463287830353 - Accuracy: 0.8358209133148193%\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4256 - accuracy: 0.8284\n",
      "Test results - Loss: 0.4256352186203003 - Accuracy: 0.8283582329750061%\n",
      "9/9 [==============================] - 0s 992us/step - loss: 0.4216 - accuracy: 0.8358\n",
      "Test results - Loss: 0.42159801721572876 - Accuracy: 0.8358209133148193%\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.8284\n",
      "Test results - Loss: 0.42488232254981995 - Accuracy: 0.8283582329750061%\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.8246\n",
      "Test results - Loss: 0.4276380240917206 - Accuracy: 0.8246268630027771%\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.4206 - accuracy: 0.8358\n",
      "Test results - Loss: 0.4205840826034546 - Accuracy: 0.8358209133148193%\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4171 - accuracy: 0.8284\n",
      "Test results - Loss: 0.417116641998291 - Accuracy: 0.8283582329750061%\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4181 - accuracy: 0.8321\n",
      "Test results - Loss: 0.418097585439682 - Accuracy: 0.8320895433425903%\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.8246\n",
      "Test results - Loss: 0.43459752202033997 - Accuracy: 0.8246268630027771%\n",
      "######################################################\n",
      " Loss    : 0.42402002215385437 - 0.004887938492545773\n",
      " Accuracy: 0.8305970251560211 - 0.004155050987927258%\n",
      "Deep Ensembles trained!!!~~~~~~~\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training standard NN Model~~~~~~~\n",
      "Epoch 1/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7037 - accuracy: 0.5329\n",
      "Epoch 2/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6217 - accuracy: 0.6469\n",
      "Epoch 3/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5746 - accuracy: 0.7335\n",
      "Epoch 4/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5482 - accuracy: 0.7528\n",
      "Epoch 5/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5277 - accuracy: 0.7496\n",
      "Epoch 6/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5118 - accuracy: 0.7496\n",
      "Epoch 7/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4972 - accuracy: 0.7592\n",
      "Epoch 8/80\n",
      "7/7 [==============================] - 0s 1000us/step - loss: 0.4870 - accuracy: 0.7689\n",
      "Epoch 9/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4762 - accuracy: 0.7801\n",
      "Epoch 10/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4684 - accuracy: 0.7865\n",
      "Epoch 11/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4666 - accuracy: 0.7945\n",
      "Epoch 12/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4590 - accuracy: 0.8026\n",
      "Epoch 13/80\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4513 - accuracy: 0.8218\n",
      "Epoch 14/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4482 - accuracy: 0.7994\n",
      "Epoch 15/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4434 - accuracy: 0.8090\n",
      "Epoch 16/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4419 - accuracy: 0.8074\n",
      "Epoch 17/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4419 - accuracy: 0.8090\n",
      "Epoch 18/80\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.8090\n",
      "Epoch 19/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4390 - accuracy: 0.8106\n",
      "Epoch 20/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4412 - accuracy: 0.8122\n",
      "Epoch 21/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4443 - accuracy: 0.8026\n",
      "Epoch 22/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4455 - accuracy: 0.8154\n",
      "Epoch 23/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4369 - accuracy: 0.8202\n",
      "Epoch 24/80\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4471 - accuracy: 0.7978\n",
      "Epoch 25/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4407 - accuracy: 0.8122\n",
      "Epoch 26/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4393 - accuracy: 0.8106\n",
      "Epoch 27/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4391 - accuracy: 0.8010\n",
      "Epoch 28/80\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.8122\n",
      "Epoch 29/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4363 - accuracy: 0.8090\n",
      "Epoch 30/80\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.8058\n",
      "Epoch 31/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4361 - accuracy: 0.8154\n",
      "Epoch 32/80\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.8090\n",
      "Epoch 33/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4359 - accuracy: 0.8154\n",
      "Epoch 34/80\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.8074\n",
      "Epoch 35/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4364 - accuracy: 0.8058\n",
      "Epoch 36/80\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.8090\n",
      "Epoch 37/80\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.8106\n",
      "Epoch 38/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4331 - accuracy: 0.8058\n",
      "Epoch 39/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4334 - accuracy: 0.8106\n",
      "Epoch 40/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4316 - accuracy: 0.8106\n",
      "Epoch 41/80\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.8074\n",
      "Epoch 42/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4370 - accuracy: 0.8266\n",
      "Epoch 43/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4326 - accuracy: 0.8283\n",
      "Epoch 44/80\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.8042\n",
      "Epoch 45/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.8058\n",
      "Epoch 46/80\n",
      "7/7 [==============================] - 0s 893us/step - loss: 0.4278 - accuracy: 0.8090\n",
      "Epoch 47/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4300 - accuracy: 0.8122\n",
      "Epoch 48/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4351 - accuracy: 0.8138\n",
      "Epoch 49/80\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.8154\n",
      "Epoch 50/80\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.8090\n",
      "Epoch 51/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4386 - accuracy: 0.8122\n",
      "Epoch 52/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.8090\n",
      "Epoch 53/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4264 - accuracy: 0.8106\n",
      "Epoch 54/80\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4222 - accuracy: 0.8074\n",
      "Epoch 55/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4217 - accuracy: 0.8074\n",
      "Epoch 56/80\n",
      "7/7 [==============================] - 0s 885us/step - loss: 0.4214 - accuracy: 0.8090\n",
      "Epoch 57/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4205 - accuracy: 0.8090\n",
      "Epoch 58/80\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4205 - accuracy: 0.8074\n",
      "Epoch 59/80\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4209 - accuracy: 0.8058\n",
      "Epoch 60/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4201 - accuracy: 0.8074\n",
      "Epoch 61/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4184 - accuracy: 0.8090\n",
      "Epoch 62/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4281 - accuracy: 0.8186\n",
      "Epoch 63/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4191 - accuracy: 0.8170\n",
      "Epoch 64/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4193 - accuracy: 0.8154\n",
      "Epoch 65/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4136 - accuracy: 0.8138\n",
      "Epoch 66/80\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4131 - accuracy: 0.8170\n",
      "Epoch 67/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4125 - accuracy: 0.8138\n",
      "Epoch 68/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4111 - accuracy: 0.8122\n",
      "Epoch 69/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4111 - accuracy: 0.8154\n",
      "Epoch 70/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4097 - accuracy: 0.8154\n",
      "Epoch 71/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4089 - accuracy: 0.8202\n",
      "Epoch 72/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4100 - accuracy: 0.8234\n",
      "Epoch 73/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4070 - accuracy: 0.8138\n",
      "Epoch 74/80\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4079 - accuracy: 0.8186\n",
      "Epoch 75/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4056 - accuracy: 0.8154\n",
      "Epoch 76/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4053 - accuracy: 0.8170\n",
      "Epoch 77/80\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4084 - accuracy: 0.8186\n",
      "Epoch 78/80\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4033 - accuracy: 0.8283\n",
      "Epoch 79/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4039 - accuracy: 0.8202\n",
      "Epoch 80/80\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4091 - accuracy: 0.8283\n",
      "Standard NN trained!!!~~~~~~~\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Train Deep Ensembles Model\n",
    "print(\"Training Deep Ensembles Model~~~~~~~\")\n",
    "histories,trained_models = train(Xtrain, np.array(y_train).reshape(-1,1), epochs=80, batch=100)\n",
    "losses,accuracies = model_eval(Xtest,np.array(y_test).reshape(-1,1),trained_models)\n",
    "print(\"Deep Ensembles trained!!!~~~~~~~\")\n",
    "print(\"\\n\\n\\n\\n\\n\")\n",
    "## Train standard NN\n",
    "print(\"Training standard NN Model~~~~~~~\")\n",
    "DNN_model = Sequential([\n",
    "            Dense(50,activation='sigmoid'),\n",
    "            Dense(1,activation='sigmoid')])\n",
    "DNN_model.compile(tf.keras.optimizers.Adam(learning_rate=0.01), loss='binary_crossentropy',metrics=[\"accuracy\"])\n",
    "DNN_model.fit(Xtrain, np.array(y_train).reshape(-1,1), epochs=80, batch_size=100)\n",
    "print(\"Standard NN trained!!!~~~~~~~\")\n",
    "print(\"\\n\\n\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4286 - accuracy: 0.8396\n",
      "Test results - Loss: 0.4285733699798584 - Accuracy: 0.8395522236824036%\n",
      "ECE with n_bins = 5:\n",
      "ECE_DeepEnsembles:  0.0482\n",
      "ECE_StandardNN   :  0.0527\n",
      "UEI: \n",
      "UEI_DeepEnsembles:  0.1167477928561946\n",
      "UEI_StandardNN   :  0.14642789345286653\n",
      "US_0: \n",
      "78 73\n",
      "US0_DeepEnsembles:  1.0684931506849316\n",
      "73 73\n",
      "US0_StandardNN   :  1.0\n",
      "US_1: \n",
      "9 30\n",
      "US1_DeepEnsembles:  0.3\n",
      "5 30\n",
      "US1_StandardNN   :  0.16666666666666666\n"
     ]
    }
   ],
   "source": [
    "y_probs_combined = np.stack([model(Xtest) for model in trained_models])\n",
    "y_preds_combined = np.mean(y_probs_combined, axis=0)\n",
    "\n",
    "\n",
    "# Test the model after training\n",
    "test_results = DNN_model.evaluate(Xtest, np.array(y_test).reshape(-1,1), verbose=1)\n",
    "print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]}%')\n",
    "y_pred_1NN = DNN_model(Xtest)\n",
    "\n",
    "df = {}\n",
    "df['sa'] = Xtest[:,-1]\n",
    "df['actual'] = y_test\n",
    "df['Ensembles'] = y_preds_combined.ravel()\n",
    "df['DNN'] = np.array(y_pred_1NN).ravel()\n",
    "df = pd.DataFrame(df)\n",
    "\n",
    "print(\"ECE with n_bins = 5:\")\n",
    "print(\"ECE_DeepEnsembles: \",compute_calibration_error(np.array(y_test),y_preds_combined,n_bins=5))\n",
    "print(\"ECE_StandardNN   : \",compute_calibration_error(np.array(y_test),y_pred_1NN,n_bins=5))\n",
    "\n",
    "\n",
    "\n",
    "print(\"UEI: \")\n",
    "print(\"UEI_DeepEnsembles: \",UEI(df.sa.values, df.actual.values, np.round(df['Ensembles'].values)))\n",
    "print(\"UEI_StandardNN   : \",UEI(df.sa.values, df.actual.values, np.round(df['DNN'].values)))\n",
    "\n",
    "print(\"US_0: \")\n",
    "print(\"US0_DeepEnsembles: \",underestimation_score_1(df.actual.values, np.round(df['Ensembles'].values),df.sa.values))\n",
    "print(\"US0_StandardNN   : \",underestimation_score_1(df.actual.values, np.round(df['DNN'].values),df.sa.values))\n",
    "\n",
    "print(\"US_1: \")\n",
    "print(\"US1_DeepEnsembles: \",underestimation_score(df.actual.values, np.round(df['Ensembles'].values),df.sa.values))\n",
    "print(\"US1_StandardNN   : \",underestimation_score(df.actual.values, np.round(df['DNN'].values),df.sa.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECE with n_bins = 5:\n",
      "ECE_DeepEnsembles_Maj:  0.0653\n",
      "ECE_DeepEnsembles_Min   :  0.0653\n",
      "ECE with n_bins = 5:\n",
      "ECE_DNN_Maj:  0.059\n",
      "ECE_DNN_Min   :  0.0895\n"
     ]
    }
   ],
   "source": [
    "from sklearn.calibration import calibration_curve\n",
    "prob_true, prob_pred = calibration_curve(y_test, y_preds_combined, n_bins=5)\n",
    "prob_true_dnn, prob_pred_dnn = calibration_curve(y_test, y_pred_1NN, n_bins=5)\n",
    "minority = df[df['sa'] == 1]\n",
    "majority = df[df['sa'] == 0]\n",
    "prob_true_maj, prob_pred_maj = calibration_curve(np.array(majority.actual), majority['Ensembles'].values.reshape(-1,1), n_bins=5)\n",
    "prob_true_min, prob_pred_min = calibration_curve(np.array(minority.actual), minority['Ensembles'].values.reshape(-1,1), n_bins=5)\n",
    "prob_true_dnn_maj, prob_pre_dnnd_maj = calibration_curve(np.array(majority.actual), majority['DNN'].values.reshape(-1,1), n_bins=5)\n",
    "prob_true_dnn_min, prob_pred_dnn_min = calibration_curve(np.array(minority.actual), minority['DNN'].values.reshape(-1,1), n_bins=5)\n",
    "\n",
    "print(\"ECE with n_bins = 5:\")\n",
    "print(\"ECE_DeepEnsembles_Maj: \",compute_calibration_error(np.array(majority.actual), majority['Ensembles'].values.reshape(-1,1), n_bins=5))\n",
    "print(\"ECE_DeepEnsembles_Min   : \",compute_calibration_error(np.array(minority.actual), minority['Ensembles'].values.reshape(-1,1), n_bins=5))\n",
    "\n",
    "print(\"ECE with n_bins = 5:\")\n",
    "print(\"ECE_DNN_Maj: \",compute_calibration_error(np.array(majority.actual), majority['DNN'].values.reshape(-1,1), n_bins=5))\n",
    "print(\"ECE_DNN_Min   : \",compute_calibration_error(np.array(minority.actual), minority['DNN'].values.reshape(-1,1), n_bins=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best threshold for s=0 that minimizes P(Y|S) - P(Yhat|S) is:  0.30303030303030304\n",
      "best threshold for s=1 that minimizes P(Y|S) - P(Yhat|S) is:  0.595959595959596\n",
      "Train:\n",
      "0.8170144462279294 0.4023619723740971 0.005528302235753482\n",
      "Test:\n",
      "0.7910447761194029 0.4217132739166715 0.0517414915071609\n",
      "US_S_0\n",
      "40 30\n",
      "1.3333333333333333\n",
      "US_S_1\n",
      "67 73\n",
      "0.9178082191780822\n"
     ]
    }
   ],
   "source": [
    "## Post-processing\n",
    "\n",
    "def find_thres(group,clf_prob,truth):\n",
    "    ls_0 = {}\n",
    "    ls_1 = {}\n",
    "    thresholds = np.linspace(0, 1, num=100)\n",
    "    for thres in thresholds:\n",
    "        df = {}\n",
    "        df['sa'] = group\n",
    "        df['prob'] = clf_prob\n",
    "        df['ground_truth'] = truth\n",
    "        df['prob_pred'] =[0]*len(truth)\n",
    "        df = pd.DataFrame(df)\n",
    "        df.loc[ (df['sa'] == 0) & (df['prob'] > thres),'prob_pred'] = 1\n",
    "        df.loc[ (df['sa'] == 1) & (df['prob'] > thres),'prob_pred'] = 1\n",
    "        US_pred_0 = df_count_feat_val_match(df, 'prob_pred', 1, 'sa',0)\n",
    "        US_true_0 = df_count_feat_val_match(df, 'ground_truth', 1, 'sa',0)\n",
    "        US_pred_1 = df_count_feat_val_match(df, 'prob_pred', 1, 'sa',1)\n",
    "        US_true_1 = df_count_feat_val_match(df, 'ground_truth', 1, 'sa',1)\n",
    "        ls_0[thres] = np.abs(US_pred_0-US_true_0)\n",
    "        ls_1[thres] = np.abs(US_pred_1-US_true_1)\n",
    "    best_0 = thresholds[np.argmin(list(ls_0.values()))]\n",
    "    best_1 = thresholds[np.argmin(list(ls_1.values()))]\n",
    "    print(\"best threshold for s=0 that minimizes P(Y|S) - P(Yhat|S) is: \",best_0)\n",
    "    print(\"best threshold for s=1 that minimizes P(Y|S) - P(Yhat|S) is: \",best_1)\n",
    "    return best_0,best_1\n",
    "\n",
    "def make_pred(group,clf_prob,thres_0,thres_1):\n",
    "    y_post = []\n",
    "    for sa,predictproba in zip(group,clf_prob):\n",
    "        if sa == 0 and predictproba > thres_0:\n",
    "            y_post.append(1)\n",
    "        elif sa == 0 and predictproba <= thres_0:\n",
    "            y_post.append(0)\n",
    "        elif sa == 1 and predictproba > thres_1:\n",
    "            y_post.append(1)\n",
    "        else:\n",
    "            y_post.append(0)\n",
    "    return y_post\n",
    "\n",
    "def evaluate(y_true,y_pred,sa):\n",
    "    ## convert the probability estimates to class labels (MC Dropout)\n",
    "\n",
    "    ba = accuracy_score(y_true,y_pred)\n",
    "    us_s = UEI(sa, y_true, np.round(y_pred))\n",
    "    return ba,us_s\n",
    "\n",
    "y_probs_combined = np.stack([model(Xtrain) for model in trained_models])\n",
    "y_preds_combined = np.mean(y_probs_combined, axis=0)\n",
    "best_thres_0,best_thres_1 = find_thres(Xtrain[:,-1],np.array(y_preds_combined.ravel()),y_train)\n",
    "y_pred_post = make_pred(Xtrain[:,-1],np.array(y_preds_combined.ravel()),best_thres_0,best_thres_1)\n",
    "best_ba,best_us = evaluate(y_train,np.array(y_pred_post),Xtrain[:,-1])\n",
    "print(\"Train:\")\n",
    "print(best_ba,nll1(y_train,np.array(y_preds_combined.ravel())).numpy()/Xtrain.shape[0],best_us)\n",
    "## test\n",
    "y_probs_combined = np.stack([model(Xtest) for model in trained_models])\n",
    "y_preds_combined = np.mean(y_probs_combined, axis=0)\n",
    "y_pred_post = make_pred(Xtest[:,-1],np.array(y_preds_combined.ravel()),best_thres_0,best_thres_1)\n",
    "best_ba,best_us = evaluate(y_test,np.array(y_pred_post),Xtest[:,-1])\n",
    "print(\"Test:\")\n",
    "print(best_ba,nll1(y_test,np.array(y_preds_combined.ravel())).numpy()/Xtest.shape[0],best_us)\n",
    "\n",
    "print(\"US_S_0\")\n",
    "print(underestimation_score(y_test,y_pred_post,Xtest[:,-1]))\n",
    "print(\"US_S_1\")\n",
    "print(underestimation_score_1(y_test,y_pred_post,Xtest[:,-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bank Marketing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset =   pd.read_csv(\"bank-full.csv\",sep=\";\")\n",
    "dataset['age'] = dataset['age'].apply(lambda x: 1 if x >= 25 and x <= 60 else 0)\n",
    "dataset['y'] = dataset['y'].apply(lambda x: 1 if x == \"yes\" else 0)\n",
    "dataset['default'] = dataset['default'].apply(lambda x: 0 if x == \"no\" else 1)\n",
    "dataset['housing'] = dataset['housing'].apply(lambda x: 0 if x == \"no\" else 1)\n",
    "dataset['loan'] = dataset['loan'].apply(lambda x: 0 if x == \"no\" else 1)\n",
    "y = dataset['y']\n",
    "dataset.pop('y')\n",
    "X = dataset\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, \n",
    "                                                    shuffle = True, random_state=40, stratify = y)\n",
    "Xtrain_num = X_train[[\"balance\",\"day\",\"duration\",\"campaign\",\"pdays\",\"previous\"]]\n",
    "x_train_cat = X_train[['job','marital','education',\"contact\",\"month\",\"poutcome\"]]\n",
    "Xtest_num = X_test[[\"balance\",\"day\",\"duration\",\"campaign\",\"pdays\",\"previous\"]]\n",
    "x_test_cat = X_test[['job','marital','education',\"contact\",\"month\",\"poutcome\"]]\n",
    "\n",
    "std = StandardScaler()\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "Xtrain_num = std.fit_transform(Xtrain_num)\n",
    "Xtest_num = std.transform(Xtest_num)\n",
    "x_train_cat = ohe.fit_transform(x_train_cat)\n",
    "x_test_cat = ohe.transform(x_test_cat)\n",
    "\n",
    "Xtrain = np.hstack((Xtrain_num,x_train_cat,X_train['default'].values.reshape(-1,1),X_train['housing'].values.reshape(-1,1),X_train['loan'].values.reshape(-1,1),X_train['age'].values.reshape(-1,1)))\n",
    "Xtest = np.hstack((Xtest_num,x_test_cat,X_test['default'].values.reshape(-1,1),X_test['housing'].values.reshape(-1,1),X_test['loan'].values.reshape(-1,1),X_test['age'].values.reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Deep Ensembles Model~~~~~~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [05:17<00:00, 31.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "424/424 [==============================] - 1s 1ms/step - loss: 0.2671 - accuracy: 0.8990\n",
      "Test results - Loss: 0.26712551712989807 - Accuracy: 0.8989973664283752%\n",
      "424/424 [==============================] - 1s 1ms/step - loss: 0.2585 - accuracy: 0.9001\n",
      "Test results - Loss: 0.25854116678237915 - Accuracy: 0.9001032114028931%\n",
      "424/424 [==============================] - 1s 1ms/step - loss: 0.2678 - accuracy: 0.8958\n",
      "Test results - Loss: 0.2677769362926483 - Accuracy: 0.8957534432411194%\n",
      "424/424 [==============================] - 1s 1ms/step - loss: 0.2634 - accuracy: 0.8981\n",
      "Test results - Loss: 0.2634066343307495 - Accuracy: 0.8981126546859741%\n",
      "424/424 [==============================] - 1s 1ms/step - loss: 0.2629 - accuracy: 0.9009\n",
      "Test results - Loss: 0.2629166841506958 - Accuracy: 0.900914192199707%\n",
      "424/424 [==============================] - 1s 1ms/step - loss: 0.2637 - accuracy: 0.9022\n",
      "Test results - Loss: 0.2636667490005493 - Accuracy: 0.9021674990653992%\n",
      "424/424 [==============================] - 1s 1ms/step - loss: 0.2627 - accuracy: 0.8986\n",
      "Test results - Loss: 0.26269951462745667 - Accuracy: 0.8985549807548523%\n",
      "424/424 [==============================] - 1s 1ms/step - loss: 0.2599 - accuracy: 0.8986\n",
      "Test results - Loss: 0.25989508628845215 - Accuracy: 0.8986287117004395%\n",
      "424/424 [==============================] - 1s 1ms/step - loss: 0.2587 - accuracy: 0.8978\n",
      "Test results - Loss: 0.258680135011673 - Accuracy: 0.8978177309036255%\n",
      "424/424 [==============================] - 1s 1ms/step - loss: 0.2595 - accuracy: 0.8973\n",
      "Test results - Loss: 0.2594720125198364 - Accuracy: 0.8973016738891602%\n",
      "######################################################\n",
      " Loss    : 0.26241804361343385 - 0.00312712376264945\n",
      " Accuracy: 0.8988351464271546 - 0.0017489419331984581%\n",
      "Deep Ensembles trained!!!~~~~~~~\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training standard NN Model~~~~~~~\n",
      "Epoch 1/80\n",
      "317/317 [==============================] - 1s 1ms/step - loss: 0.2438 - accuracy: 0.8989\n",
      "Epoch 2/80\n",
      "317/317 [==============================] - 0s 2ms/step - loss: 0.2239 - accuracy: 0.9010\n",
      "Epoch 3/80\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 0.2183 - accuracy: 0.9040\n",
      "Epoch 4/80\n",
      "317/317 [==============================] - 0s 2ms/step - loss: 0.2144 - accuracy: 0.9052\n",
      "Epoch 5/80\n",
      "317/317 [==============================] - 0s 2ms/step - loss: 0.2113 - accuracy: 0.9064\n",
      "Epoch 6/80\n",
      "317/317 [==============================] - 0s 2ms/step - loss: 0.2075 - accuracy: 0.9078\n",
      "Epoch 7/80\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 0.2040 - accuracy: 0.9092\n",
      "Epoch 8/80\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 0.2018 - accuracy: 0.9109\n",
      "Epoch 9/80\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 0.1992 - accuracy: 0.9107\n",
      "Epoch 10/80\n",
      "317/317 [==============================] - 0s 2ms/step - loss: 0.1970 - accuracy: 0.9113\n",
      "Epoch 11/80\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 0.1952 - accuracy: 0.9118\n",
      "Epoch 12/80\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 0.1930 - accuracy: 0.9131\n",
      "Epoch 13/80\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 0.1911 - accuracy: 0.9135\n",
      "Epoch 14/80\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 0.1894 - accuracy: 0.9145\n",
      "Epoch 15/80\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 0.1867 - accuracy: 0.9160\n",
      "Epoch 16/80\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 0.1859 - accuracy: 0.9154\n",
      "Epoch 17/80\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 0.1831 - accuracy: 0.9165\n",
      "Epoch 18/80\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 0.1818 - accuracy: 0.9169\n",
      "Epoch 19/80\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 0.1792 - accuracy: 0.9185\n",
      "Epoch 20/80\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 0.1786 - accuracy: 0.9189\n",
      "Epoch 21/80\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 0.1771 - accuracy: 0.9200\n",
      "Epoch 22/80\n",
      "317/317 [==============================] - 0s 2ms/step - loss: 0.1752 - accuracy: 0.9209\n",
      "Epoch 23/80\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 0.1734 - accuracy: 0.9218\n",
      "Epoch 24/80\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 0.1719 - accuracy: 0.9226\n",
      "Epoch 25/80\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 0.1712 - accuracy: 0.9221\n",
      "Epoch 26/80\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 0.1694 - accuracy: 0.9234\n",
      "Epoch 27/80\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 0.1677 - accuracy: 0.9251\n",
      "Epoch 28/80\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 0.1669 - accuracy: 0.9254\n",
      "Epoch 29/80\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 0.1654 - accuracy: 0.9258\n",
      "Epoch 30/80\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 0.1646 - accuracy: 0.9268\n",
      "Epoch 31/80\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 0.1636 - accuracy: 0.9272\n",
      "Epoch 32/80\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 0.1618 - accuracy: 0.9287\n",
      "Epoch 33/80\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 0.1611 - accuracy: 0.9276\n",
      "Epoch 34/80\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 0.1602 - accuracy: 0.9288\n",
      "Epoch 35/80\n",
      "317/317 [==============================] - 0s 2ms/step - loss: 0.1585 - accuracy: 0.9305\n",
      "Epoch 36/80\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 0.1577 - accuracy: 0.9310\n",
      "Epoch 37/80\n",
      "317/317 [==============================] - 0s 2ms/step - loss: 0.1571 - accuracy: 0.9305\n",
      "Epoch 38/80\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 0.1566 - accuracy: 0.9311\n",
      "Epoch 39/80\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 0.1550 - accuracy: 0.9311\n",
      "Epoch 40/80\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 0.1543 - accuracy: 0.9323\n",
      "Epoch 41/80\n",
      "317/317 [==============================] - 0s 2ms/step - loss: 0.1536 - accuracy: 0.9325\n",
      "Epoch 42/80\n",
      "317/317 [==============================] - 0s 2ms/step - loss: 0.1531 - accuracy: 0.9331\n",
      "Epoch 43/80\n",
      "317/317 [==============================] - 0s 2ms/step - loss: 0.1520 - accuracy: 0.9333\n",
      "Epoch 44/80\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 0.1517 - accuracy: 0.9331\n",
      "Epoch 45/80\n",
      "317/317 [==============================] - 0s 2ms/step - loss: 0.1503 - accuracy: 0.9343\n",
      "Epoch 46/80\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 0.1504 - accuracy: 0.9332\n",
      "Epoch 47/80\n",
      "317/317 [==============================] - 0s 2ms/step - loss: 0.1502 - accuracy: 0.9347\n",
      "Epoch 48/80\n",
      "317/317 [==============================] - 0s 2ms/step - loss: 0.1485 - accuracy: 0.9357\n",
      "Epoch 49/80\n",
      "317/317 [==============================] - 0s 2ms/step - loss: 0.1488 - accuracy: 0.9343\n",
      "Epoch 50/80\n",
      "317/317 [==============================] - 0s 2ms/step - loss: 0.1479 - accuracy: 0.9342\n",
      "Epoch 51/80\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 0.1467 - accuracy: 0.9367\n",
      "Epoch 52/80\n",
      "317/317 [==============================] - 0s 2ms/step - loss: 0.1469 - accuracy: 0.9351\n",
      "Epoch 53/80\n",
      "317/317 [==============================] - 0s 2ms/step - loss: 0.1466 - accuracy: 0.9363\n",
      "Epoch 54/80\n",
      "317/317 [==============================] - 0s 2ms/step - loss: 0.1453 - accuracy: 0.9369\n",
      "Epoch 55/80\n",
      "317/317 [==============================] - 0s 2ms/step - loss: 0.1451 - accuracy: 0.9362\n",
      "Epoch 56/80\n",
      "317/317 [==============================] - 0s 2ms/step - loss: 0.1442 - accuracy: 0.9376\n",
      "Epoch 57/80\n",
      "317/317 [==============================] - 0s 2ms/step - loss: 0.1429 - accuracy: 0.9379\n",
      "Epoch 58/80\n",
      "317/317 [==============================] - 0s 2ms/step - loss: 0.1433 - accuracy: 0.9378\n",
      "Epoch 59/80\n",
      "317/317 [==============================] - 0s 2ms/step - loss: 0.1423 - accuracy: 0.9387\n",
      "Epoch 60/80\n",
      "317/317 [==============================] - 0s 2ms/step - loss: 0.1420 - accuracy: 0.9391\n",
      "Epoch 61/80\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 0.1417 - accuracy: 0.9394\n",
      "Epoch 62/80\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 0.1410 - accuracy: 0.9393\n",
      "Epoch 63/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "317/317 [==============================] - 0s 2ms/step - loss: 0.1404 - accuracy: 0.9393\n",
      "Epoch 64/80\n",
      "317/317 [==============================] - 0s 2ms/step - loss: 0.1400 - accuracy: 0.9402\n",
      "Epoch 65/80\n",
      "317/317 [==============================] - 0s 2ms/step - loss: 0.1399 - accuracy: 0.9393\n",
      "Epoch 66/80\n",
      "317/317 [==============================] - 0s 2ms/step - loss: 0.1397 - accuracy: 0.9392\n",
      "Epoch 67/80\n",
      "317/317 [==============================] - 0s 2ms/step - loss: 0.1394 - accuracy: 0.9387\n",
      "Epoch 68/80\n",
      "317/317 [==============================] - 0s 2ms/step - loss: 0.1389 - accuracy: 0.9408\n",
      "Epoch 69/80\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 0.1381 - accuracy: 0.9403\n",
      "Epoch 70/80\n",
      "317/317 [==============================] - 0s 2ms/step - loss: 0.1372 - accuracy: 0.9413\n",
      "Epoch 71/80\n",
      "317/317 [==============================] - 0s 2ms/step - loss: 0.1371 - accuracy: 0.9414\n",
      "Epoch 72/80\n",
      "317/317 [==============================] - 0s 2ms/step - loss: 0.1369 - accuracy: 0.9414\n",
      "Epoch 73/80\n",
      "317/317 [==============================] - 0s 2ms/step - loss: 0.1371 - accuracy: 0.9405\n",
      "Epoch 74/80\n",
      "317/317 [==============================] - 0s 2ms/step - loss: 0.1361 - accuracy: 0.9412\n",
      "Epoch 75/80\n",
      "317/317 [==============================] - 0s 2ms/step - loss: 0.1359 - accuracy: 0.9424\n",
      "Epoch 76/80\n",
      "317/317 [==============================] - 0s 2ms/step - loss: 0.1362 - accuracy: 0.9423\n",
      "Epoch 77/80\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 0.1357 - accuracy: 0.9418\n",
      "Epoch 78/80\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 0.1356 - accuracy: 0.9419\n",
      "Epoch 79/80\n",
      "317/317 [==============================] - 0s 2ms/step - loss: 0.1349 - accuracy: 0.9415\n",
      "Epoch 80/80\n",
      "317/317 [==============================] - 0s 2ms/step - loss: 0.1341 - accuracy: 0.9426\n",
      "Standard NN trained!!!~~~~~~~\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Train Deep Ensembles Model\n",
    "print(\"Training Deep Ensembles Model~~~~~~~\")\n",
    "histories,trained_models = train(Xtrain, np.array(y_train).reshape(-1,1), epochs=80, batch=100)\n",
    "losses,accuracies = model_eval(Xtest,np.array(y_test).reshape(-1,1),trained_models)\n",
    "print(\"Deep Ensembles trained!!!~~~~~~~\")\n",
    "print(\"\\n\\n\\n\\n\\n\")\n",
    "## Train standard NN\n",
    "print(\"Training standard NN Model~~~~~~~\")\n",
    "DNN_model = Sequential([\n",
    "            Dense(50,activation='sigmoid'),\n",
    "            Dense(1,activation='sigmoid')])\n",
    "DNN_model.compile(tf.keras.optimizers.Adam(learning_rate=0.01), loss='binary_crossentropy',metrics=[\"accuracy\"])\n",
    "DNN_model.fit(Xtrain, np.array(y_train).reshape(-1,1), epochs=80, batch_size=100)\n",
    "print(\"Standard NN trained!!!~~~~~~~\")\n",
    "print(\"\\n\\n\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "424/424 [==============================] - 1s 1ms/step - loss: 0.2637 - accuracy: 0.9027\n",
      "Test results - Loss: 0.26366665959358215 - Accuracy: 0.9026835560798645%\n",
      "ECE with n_bins = 5:\n",
      "ECE_DeepEnsembles:  0.018\n",
      "ECE_StandardNN   :  0.0379\n",
      "UEI: \n",
      "UEI_DeepEnsembles:  0.019099897781779167\n",
      "UEI_StandardNN   :  0.023527484901852667\n",
      "US_0: \n",
      "1162 1373\n",
      "US0_DeepEnsembles:  0.8463219227967953\n",
      "1115 1373\n",
      "US0_StandardNN   :  0.8120903131828113\n",
      "US_1: \n",
      "205 214\n",
      "US1_DeepEnsembles:  0.9579439252336449\n",
      "204 214\n",
      "US1_StandardNN   :  0.9532710280373832\n"
     ]
    }
   ],
   "source": [
    "y_probs_combined = np.stack([model(Xtest) for model in trained_models])\n",
    "y_preds_combined = np.mean(y_probs_combined, axis=0)\n",
    "\n",
    "\n",
    "# Test the model after training\n",
    "test_results = DNN_model.evaluate(Xtest, np.array(y_test).reshape(-1,1), verbose=1)\n",
    "print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]}%')\n",
    "y_pred_1NN = DNN_model(Xtest)\n",
    "\n",
    "df = {}\n",
    "df['sa'] = Xtest[:,-1]\n",
    "df['actual'] = y_test\n",
    "df['Ensembles'] = y_preds_combined.ravel()\n",
    "df['DNN'] = np.array(y_pred_1NN).ravel()\n",
    "df = pd.DataFrame(df)\n",
    "\n",
    "print(\"ECE with n_bins = 5:\")\n",
    "print(\"ECE_DeepEnsembles: \",compute_calibration_error(np.array(y_test),y_preds_combined,n_bins=5))\n",
    "print(\"ECE_StandardNN   : \",compute_calibration_error(np.array(y_test),y_pred_1NN,n_bins=5))\n",
    "\n",
    "\n",
    "\n",
    "print(\"UEI: \")\n",
    "print(\"UEI_DeepEnsembles: \",UEI(df.sa.values, df.actual.values, np.round(df['Ensembles'].values)))\n",
    "print(\"UEI_StandardNN   : \",UEI(df.sa.values, df.actual.values, np.round(df['DNN'].values)))\n",
    "\n",
    "print(\"US_0: \")\n",
    "print(\"US0_DeepEnsembles: \",underestimation_score_1(df.actual.values, np.round(df['Ensembles'].values),df.sa.values))\n",
    "print(\"US0_StandardNN   : \",underestimation_score_1(df.actual.values, np.round(df['DNN'].values),df.sa.values))\n",
    "\n",
    "print(\"US_1: \")\n",
    "print(\"US1_DeepEnsembles: \",underestimation_score(df.actual.values, np.round(df['Ensembles'].values),df.sa.values))\n",
    "print(\"US1_StandardNN   : \",underestimation_score(df.actual.values, np.round(df['DNN'].values),df.sa.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECE with n_bins = 5:\n",
      "ECE_DeepEnsembles_Maj:  0.098\n",
      "ECE_DeepEnsembles_Min   :  0.0129\n",
      "ECE with n_bins = 5:\n",
      "ECE_DNN_Maj:  0.1927\n",
      "ECE_DNN_Min   :  0.0297\n"
     ]
    }
   ],
   "source": [
    "from sklearn.calibration import calibration_curve\n",
    "prob_true, prob_pred = calibration_curve(y_test, y_preds_combined, n_bins=5)\n",
    "prob_true_dnn, prob_pred_dnn = calibration_curve(y_test, y_pred_1NN, n_bins=5)\n",
    "minority = df[df['sa'] == 1]\n",
    "majority = df[df['sa'] == 0]\n",
    "prob_true_maj, prob_pred_maj = calibration_curve(np.array(majority.actual), majority['Ensembles'].values.reshape(-1,1), n_bins=5)\n",
    "prob_true_min, prob_pred_min = calibration_curve(np.array(minority.actual), minority['Ensembles'].values.reshape(-1,1), n_bins=5)\n",
    "prob_true_dnn_maj, prob_pre_dnnd_maj = calibration_curve(np.array(majority.actual), majority['DNN'].values.reshape(-1,1), n_bins=5)\n",
    "prob_true_dnn_min, prob_pred_dnn_min = calibration_curve(np.array(minority.actual), minority['DNN'].values.reshape(-1,1), n_bins=5)\n",
    "\n",
    "print(\"ECE with n_bins = 5:\")\n",
    "print(\"ECE_DeepEnsembles_Maj: \",compute_calibration_error(np.array(majority.actual), majority['Ensembles'].values.reshape(-1,1), n_bins=5))\n",
    "print(\"ECE_DeepEnsembles_Min   : \",compute_calibration_error(np.array(minority.actual), minority['Ensembles'].values.reshape(-1,1), n_bins=5))\n",
    "\n",
    "print(\"ECE with n_bins = 5:\")\n",
    "print(\"ECE_DNN_Maj: \",compute_calibration_error(np.array(majority.actual), majority['DNN'].values.reshape(-1,1), n_bins=5))\n",
    "print(\"ECE_DNN_Min   : \",compute_calibration_error(np.array(minority.actual), minority['DNN'].values.reshape(-1,1), n_bins=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best threshold for s=0 that minimizes P(Y|S) - P(Yhat|S) is:  0.5151515151515152\n",
      "best threshold for s=1 that minimizes P(Y|S) - P(Yhat|S) is:  0.43434343434343436\n",
      "Train:\n",
      "0.9581634910102064 0.11252283027666525 0.000786240760529791\n",
      "Test:\n",
      "0.9071070480684164 0.20122216465690432 0.004226597082048171\n",
      "US_S_0\n",
      "198 214\n",
      "0.9252336448598131\n",
      "US_S_1\n",
      "1381 1373\n",
      "1.0058266569555718\n"
     ]
    }
   ],
   "source": [
    "## Post-processing\n",
    "\n",
    "def find_thres(group,clf_prob,truth):\n",
    "    ls_0 = {}\n",
    "    ls_1 = {}\n",
    "    thresholds = np.linspace(0, 1, num=100)\n",
    "    for thres in thresholds:\n",
    "        df = {}\n",
    "        df['sa'] = group\n",
    "        df['prob'] = clf_prob\n",
    "        df['ground_truth'] = truth\n",
    "        df['prob_pred'] =[0]*len(truth)\n",
    "        df = pd.DataFrame(df)\n",
    "        df.loc[ (df['sa'] == 0) & (df['prob'] > thres),'prob_pred'] = 1\n",
    "        df.loc[ (df['sa'] == 1) & (df['prob'] > thres),'prob_pred'] = 1\n",
    "        US_pred_0 = df_count_feat_val_match(df, 'prob_pred', 1, 'sa',0)\n",
    "        US_true_0 = df_count_feat_val_match(df, 'ground_truth', 1, 'sa',0)\n",
    "        US_pred_1 = df_count_feat_val_match(df, 'prob_pred', 1, 'sa',1)\n",
    "        US_true_1 = df_count_feat_val_match(df, 'ground_truth', 1, 'sa',1)\n",
    "        ls_0[thres] = np.abs(US_pred_0-US_true_0)\n",
    "        ls_1[thres] = np.abs(US_pred_1-US_true_1)\n",
    "    best_0 = thresholds[np.argmin(list(ls_0.values()))]\n",
    "    best_1 = thresholds[np.argmin(list(ls_1.values()))]\n",
    "    print(\"best threshold for s=0 that minimizes P(Y|S) - P(Yhat|S) is: \",best_0)\n",
    "    print(\"best threshold for s=1 that minimizes P(Y|S) - P(Yhat|S) is: \",best_1)\n",
    "    return best_0,best_1\n",
    "\n",
    "def make_pred(group,clf_prob,thres_0,thres_1):\n",
    "    y_post = []\n",
    "    for sa,predictproba in zip(group,clf_prob):\n",
    "        if sa == 0 and predictproba > thres_0:\n",
    "            y_post.append(1)\n",
    "        elif sa == 0 and predictproba <= thres_0:\n",
    "            y_post.append(0)\n",
    "        elif sa == 1 and predictproba > thres_1:\n",
    "            y_post.append(1)\n",
    "        else:\n",
    "            y_post.append(0)\n",
    "    return y_post\n",
    "\n",
    "def evaluate(y_true,y_pred,sa):\n",
    "    ## convert the probability estimates to class labels (MC Dropout)\n",
    "\n",
    "    ba = accuracy_score(y_true,y_pred)\n",
    "    us_s = UEI(sa, y_true, np.round(y_pred))\n",
    "    return ba,us_s\n",
    "\n",
    "y_probs_combined = np.stack([model(Xtrain) for model in trained_models])\n",
    "y_preds_combined = np.mean(y_probs_combined, axis=0)\n",
    "best_thres_0,best_thres_1 = find_thres(Xtrain[:,-1],np.array(y_preds_combined.ravel()),y_train)\n",
    "y_pred_post = make_pred(Xtrain[:,-1],np.array(y_preds_combined.ravel()),best_thres_0,best_thres_1)\n",
    "best_ba,best_us = evaluate(y_train,np.array(y_pred_post),Xtrain[:,-1])\n",
    "print(\"Train:\")\n",
    "print(best_ba,nll1(y_train,np.array(y_preds_combined.ravel())).numpy()/Xtrain.shape[0],best_us)\n",
    "## test\n",
    "y_probs_combined = np.stack([model(Xtest) for model in trained_models])\n",
    "y_preds_combined = np.mean(y_probs_combined, axis=0)\n",
    "y_pred_post = make_pred(Xtest[:,-1],np.array(y_preds_combined.ravel()),best_thres_0,best_thres_1)\n",
    "best_ba,best_us = evaluate(y_test,np.array(y_pred_post),Xtest[:,-1])\n",
    "print(\"Test:\")\n",
    "print(best_ba,nll1(y_test,np.array(y_preds_combined.ravel())).numpy()/Xtest.shape[0],best_us)\n",
    "\n",
    "print(\"US_S_0\")\n",
    "print(underestimation_score(y_test,y_pred_post,Xtest[:,-1]))\n",
    "print(\"US_S_1\")\n",
    "print(underestimation_score_1(y_test,y_pred_post,Xtest[:,-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACS Mobility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from folktables import ACSDataSource, ACSMobility\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "data_source = ACSDataSource(survey_year='2018', horizon='1-Year', survey='person')\n",
    "acs_data = data_source.get_data(states=[\"CA\"], download=True)\n",
    "features, label, group = ACSMobility.df_to_numpy(acs_data)\n",
    "group = np.array([1 if x == 2 else 0 for x in group])\n",
    "Xtrain, Xtest, y_train, y_test, group_train, group_test = train_test_split(\n",
    "    features, label, group, test_size=0.2, random_state=0)\n",
    "std = StandardScaler()\n",
    "Xtrain = std.fit_transform(Xtrain)\n",
    "Xtest = std.transform(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Deep Ensembles Model~~~~~~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [10:20<00:00, 62.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  1/503 [..............................] - ETA: 1:23 - loss: 0.4393 - accuracy: 0.7188"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "503/503 [==============================] - 1s 1ms/step - loss: 0.4798 - accuracy: 0.7794\n",
      "Test results - Loss: 0.4797888398170471 - Accuracy: 0.7794099450111389%\n",
      "503/503 [==============================] - 1s 1ms/step - loss: 0.4825 - accuracy: 0.7792\n",
      "Test results - Loss: 0.4825078547000885 - Accuracy: 0.7791609764099121%\n",
      "503/503 [==============================] - 1s 1ms/step - loss: 0.4797 - accuracy: 0.7799\n",
      "Test results - Loss: 0.47974154353141785 - Accuracy: 0.7799078822135925%\n",
      "503/503 [==============================] - 1s 1ms/step - loss: 0.4823 - accuracy: 0.7790\n",
      "Test results - Loss: 0.4823417067527771 - Accuracy: 0.7790364623069763%\n",
      "503/503 [==============================] - 1s 1ms/step - loss: 0.4817 - accuracy: 0.7791\n",
      "Test results - Loss: 0.4817129969596863 - Accuracy: 0.7790986895561218%\n",
      "503/503 [==============================] - 1s 1ms/step - loss: 0.4855 - accuracy: 0.7784\n",
      "Test results - Loss: 0.4854848086833954 - Accuracy: 0.7783517837524414%\n",
      "503/503 [==============================] - 1s 1ms/step - loss: 0.4800 - accuracy: 0.7784\n",
      "Test results - Loss: 0.479990154504776 - Accuracy: 0.7783517837524414%\n",
      "503/503 [==============================] - 1s 1ms/step - loss: 0.4824 - accuracy: 0.7816\n",
      "Test results - Loss: 0.48242512345314026 - Accuracy: 0.7815884351730347%\n",
      "503/503 [==============================] - 1s 1ms/step - loss: 0.4860 - accuracy: 0.7715\n",
      "Test results - Loss: 0.4860091507434845 - Accuracy: 0.7715050578117371%\n",
      "503/503 [==============================] - 1s 1ms/step - loss: 0.4785 - accuracy: 0.7800\n",
      "Test results - Loss: 0.47852903604507446 - Accuracy: 0.7800323367118835%\n",
      "######################################################\n",
      " Loss    : 0.48185312151908877 - 0.002339148426786513\n",
      " Accuracy: 0.7786443352699279 - 0.0025405620697183558%\n",
      "Deep Ensembles trained!!!~~~~~~~\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training standard NN Model~~~~~~~\n",
      "Epoch 1/80\n",
      "643/643 [==============================] - 1s 2ms/step - loss: 0.5194 - accuracy: 0.7660\n",
      "Epoch 2/80\n",
      "643/643 [==============================] - 1s 2ms/step - loss: 0.5121 - accuracy: 0.7691\n",
      "Epoch 3/80\n",
      "643/643 [==============================] - 1s 2ms/step - loss: 0.5039 - accuracy: 0.7692\n",
      "Epoch 4/80\n",
      "643/643 [==============================] - 1s 2ms/step - loss: 0.4905 - accuracy: 0.7705\n",
      "Epoch 5/80\n",
      "643/643 [==============================] - 1s 2ms/step - loss: 0.4843 - accuracy: 0.7724\n",
      "Epoch 6/80\n",
      "643/643 [==============================] - 1s 2ms/step - loss: 0.4822 - accuracy: 0.7731\n",
      "Epoch 7/80\n",
      "643/643 [==============================] - 1s 2ms/step - loss: 0.4806 - accuracy: 0.7755\n",
      "Epoch 8/80\n",
      "643/643 [==============================] - 1s 2ms/step - loss: 0.4801 - accuracy: 0.7753\n",
      "Epoch 9/80\n",
      "643/643 [==============================] - 1s 2ms/step - loss: 0.4783 - accuracy: 0.7780\n",
      "Epoch 10/80\n",
      "643/643 [==============================] - 1s 2ms/step - loss: 0.4781 - accuracy: 0.7772\n",
      "Epoch 11/80\n",
      "643/643 [==============================] - 1s 2ms/step - loss: 0.4774 - accuracy: 0.7782\n",
      "Epoch 12/80\n",
      "643/643 [==============================] - 1s 2ms/step - loss: 0.4771 - accuracy: 0.7784\n",
      "Epoch 13/80\n",
      "643/643 [==============================] - 1s 2ms/step - loss: 0.4761 - accuracy: 0.7781\n",
      "Epoch 14/80\n",
      "643/643 [==============================] - 1s 2ms/step - loss: 0.4758 - accuracy: 0.7787\n",
      "Epoch 15/80\n",
      "643/643 [==============================] - 1s 2ms/step - loss: 0.4751 - accuracy: 0.7795\n",
      "Epoch 16/80\n",
      "643/643 [==============================] - 1s 2ms/step - loss: 0.4751 - accuracy: 0.7792\n",
      "Epoch 17/80\n",
      "643/643 [==============================] - 1s 2ms/step - loss: 0.4743 - accuracy: 0.7804\n",
      "Epoch 18/80\n",
      "643/643 [==============================] - 1s 2ms/step - loss: 0.4736 - accuracy: 0.7805\n",
      "Epoch 19/80\n",
      "643/643 [==============================] - 1s 2ms/step - loss: 0.4740 - accuracy: 0.7807\n",
      "Epoch 20/80\n",
      "643/643 [==============================] - 1s 2ms/step - loss: 0.4738 - accuracy: 0.7795\n",
      "Epoch 21/80\n",
      "643/643 [==============================] - 1s 2ms/step - loss: 0.4732 - accuracy: 0.7807\n",
      "Epoch 22/80\n",
      "643/643 [==============================] - 1s 2ms/step - loss: 0.4727 - accuracy: 0.7814\n",
      "Epoch 23/80\n",
      "643/643 [==============================] - 1s 2ms/step - loss: 0.4725 - accuracy: 0.7812\n",
      "Epoch 24/80\n",
      "643/643 [==============================] - 1s 2ms/step - loss: 0.4724 - accuracy: 0.7816\n",
      "Epoch 25/80\n",
      "643/643 [==============================] - 1s 2ms/step - loss: 0.4718 - accuracy: 0.7807\n",
      "Epoch 26/80\n",
      "643/643 [==============================] - 1s 2ms/step - loss: 0.4719 - accuracy: 0.7808\n",
      "Epoch 27/80\n",
      "643/643 [==============================] - 1s 2ms/step - loss: 0.4711 - accuracy: 0.7830\n",
      "Epoch 28/80\n",
      "643/643 [==============================] - 1s 2ms/step - loss: 0.4715 - accuracy: 0.7820\n",
      "Epoch 29/80\n",
      "643/643 [==============================] - 1s 2ms/step - loss: 0.4713 - accuracy: 0.7817\n",
      "Epoch 30/80\n",
      "643/643 [==============================] - 1s 2ms/step - loss: 0.4710 - accuracy: 0.7825\n",
      "Epoch 31/80\n",
      "643/643 [==============================] - 1s 2ms/step - loss: 0.4709 - accuracy: 0.7820\n",
      "Epoch 32/80\n",
      "643/643 [==============================] - 1s 2ms/step - loss: 0.4706 - accuracy: 0.7826\n",
      "Epoch 33/80\n",
      "643/643 [==============================] - 1s 2ms/step - loss: 0.4704 - accuracy: 0.7827\n",
      "Epoch 34/80\n",
      "643/643 [==============================] - 1s 2ms/step - loss: 0.4697 - accuracy: 0.7825\n",
      "Epoch 35/80\n",
      "643/643 [==============================] - 1s 2ms/step - loss: 0.4699 - accuracy: 0.7832\n",
      "Epoch 36/80\n",
      "643/643 [==============================] - 1s 2ms/step - loss: 0.4700 - accuracy: 0.7829\n",
      "Epoch 37/80\n",
      "643/643 [==============================] - 1s 2ms/step - loss: 0.4700 - accuracy: 0.7834\n",
      "Epoch 38/80\n",
      "643/643 [==============================] - 1s 2ms/step - loss: 0.4694 - accuracy: 0.7828\n",
      "Epoch 39/80\n",
      "643/643 [==============================] - 1s 2ms/step - loss: 0.4693 - accuracy: 0.7828\n",
      "Epoch 40/80\n",
      "643/643 [==============================] - 1s 2ms/step - loss: 0.4696 - accuracy: 0.7830\n",
      "Epoch 41/80\n",
      "643/643 [==============================] - 1s 2ms/step - loss: 0.4690 - accuracy: 0.7828\n",
      "Epoch 42/80\n",
      "643/643 [==============================] - 1s 2ms/step - loss: 0.4690 - accuracy: 0.7843\n",
      "Epoch 43/80\n",
      "643/643 [==============================] - 1s 2ms/step - loss: 0.4689 - accuracy: 0.7834\n",
      "Epoch 44/80\n",
      "643/643 [==============================] - 1s 2ms/step - loss: 0.4688 - accuracy: 0.7835\n",
      "Epoch 45/80\n",
      "643/643 [==============================] - 1s 2ms/step - loss: 0.4691 - accuracy: 0.7829\n",
      "Epoch 46/80\n",
      "643/643 [==============================] - 1s 2ms/step - loss: 0.4683 - accuracy: 0.7837\n",
      "Epoch 47/80\n",
      "643/643 [==============================] - 1s 2ms/step - loss: 0.4685 - accuracy: 0.7836\n",
      "Epoch 48/80\n",
      "643/643 [==============================] - 1s 2ms/step - loss: 0.4682 - accuracy: 0.7842\n",
      "Epoch 49/80\n",
      "643/643 [==============================] - 1s 2ms/step - loss: 0.4681 - accuracy: 0.7839\n",
      "Epoch 50/80\n",
      "643/643 [==============================] - 1s 2ms/step - loss: 0.4678 - accuracy: 0.7844\n",
      "Epoch 51/80\n",
      "643/643 [==============================] - 1s 2ms/step - loss: 0.4679 - accuracy: 0.7844\n",
      "Epoch 52/80\n",
      "643/643 [==============================] - 1s 2ms/step - loss: 0.4681 - accuracy: 0.7834\n",
      "Epoch 53/80\n",
      "643/643 [==============================] - 1s 2ms/step - loss: 0.4679 - accuracy: 0.7845\n",
      "Epoch 54/80\n",
      "643/643 [==============================] - 1s 2ms/step - loss: 0.4673 - accuracy: 0.7841\n",
      "Epoch 55/80\n",
      "643/643 [==============================] - 1s 2ms/step - loss: 0.4678 - accuracy: 0.7841\n",
      "Epoch 56/80\n",
      "643/643 [==============================] - 1s 2ms/step - loss: 0.4676 - accuracy: 0.7837\n",
      "Epoch 57/80\n",
      "643/643 [==============================] - 1s 2ms/step - loss: 0.4672 - accuracy: 0.7848\n",
      "Epoch 58/80\n",
      "643/643 [==============================] - 1s 2ms/step - loss: 0.4671 - accuracy: 0.7843\n",
      "Epoch 59/80\n",
      "643/643 [==============================] - 1s 2ms/step - loss: 0.4670 - accuracy: 0.7854\n",
      "Epoch 60/80\n",
      "643/643 [==============================] - 1s 2ms/step - loss: 0.4669 - accuracy: 0.7845\n",
      "Epoch 61/80\n",
      "643/643 [==============================] - 1s 2ms/step - loss: 0.4667 - accuracy: 0.7842\n",
      "Epoch 62/80\n",
      "643/643 [==============================] - 1s 2ms/step - loss: 0.4664 - accuracy: 0.7840\n",
      "Epoch 63/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "643/643 [==============================] - 1s 2ms/step - loss: 0.4670 - accuracy: 0.7856\n",
      "Epoch 64/80\n",
      "643/643 [==============================] - 1s 2ms/step - loss: 0.4664 - accuracy: 0.7863\n",
      "Epoch 65/80\n",
      "643/643 [==============================] - 1s 2ms/step - loss: 0.4667 - accuracy: 0.7842\n",
      "Epoch 66/80\n",
      "643/643 [==============================] - 1s 2ms/step - loss: 0.4663 - accuracy: 0.7842\n",
      "Epoch 67/80\n",
      "643/643 [==============================] - 1s 1ms/step - loss: 0.4663 - accuracy: 0.7853\n",
      "Epoch 68/80\n",
      "643/643 [==============================] - 1s 1ms/step - loss: 0.4662 - accuracy: 0.7858\n",
      "Epoch 69/80\n",
      "643/643 [==============================] - 1s 1ms/step - loss: 0.4662 - accuracy: 0.7855\n",
      "Epoch 70/80\n",
      "643/643 [==============================] - 1s 1ms/step - loss: 0.4667 - accuracy: 0.7848\n",
      "Epoch 71/80\n",
      "643/643 [==============================] - 1s 2ms/step - loss: 0.4662 - accuracy: 0.7864\n",
      "Epoch 72/80\n",
      "643/643 [==============================] - 1s 1ms/step - loss: 0.4661 - accuracy: 0.7859\n",
      "Epoch 73/80\n",
      "643/643 [==============================] - 1s 1ms/step - loss: 0.4660 - accuracy: 0.7856\n",
      "Epoch 74/80\n",
      "643/643 [==============================] - 1s 1ms/step - loss: 0.4660 - accuracy: 0.7854\n",
      "Epoch 75/80\n",
      "643/643 [==============================] - 1s 1ms/step - loss: 0.4658 - accuracy: 0.7851\n",
      "Epoch 76/80\n",
      "643/643 [==============================] - 1s 1ms/step - loss: 0.4660 - accuracy: 0.7856\n",
      "Epoch 77/80\n",
      "643/643 [==============================] - 1s 1ms/step - loss: 0.4657 - accuracy: 0.7851\n",
      "Epoch 78/80\n",
      "643/643 [==============================] - 1s 2ms/step - loss: 0.4656 - accuracy: 0.7862\n",
      "Epoch 79/80\n",
      "643/643 [==============================] - 1s 1ms/step - loss: 0.4654 - accuracy: 0.7864\n",
      "Epoch 80/80\n",
      "643/643 [==============================] - 1s 2ms/step - loss: 0.4656 - accuracy: 0.7859\n",
      "Standard NN trained!!!~~~~~~~\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Train Deep Ensembles Model\n",
    "print(\"Training Deep Ensembles Model~~~~~~~\")\n",
    "histories,trained_models = train(Xtrain, np.array(y_train).reshape(-1,1), epochs=80, batch=100)\n",
    "losses,accuracies = model_eval(Xtest,np.array(y_test).reshape(-1,1),trained_models)\n",
    "print(\"Deep Ensembles trained!!!~~~~~~~\")\n",
    "print(\"\\n\\n\\n\\n\\n\")\n",
    "## Train standard NN\n",
    "print(\"Training standard NN Model~~~~~~~\")\n",
    "DNN_model = Sequential([\n",
    "            Dense(50,activation='sigmoid'),\n",
    "            Dense(1,activation='sigmoid')])\n",
    "DNN_model.compile(tf.keras.optimizers.Adam(learning_rate=0.01), loss='binary_crossentropy',metrics=[\"accuracy\"])\n",
    "DNN_model.fit(Xtrain, np.array(y_train).reshape(-1,1), epochs=80, batch_size=100)\n",
    "print(\"Standard NN trained!!!~~~~~~~\")\n",
    "print(\"\\n\\n\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "503/503 [==============================] - 1s 1ms/step - loss: 0.4784 - accuracy: 0.7801\n",
      "Test results - Loss: 0.47835057973861694 - Accuracy: 0.7800946235656738%\n",
      "ECE with n_bins = 5:\n",
      "ECE_DeepEnsembles:  0.0083\n",
      "ECE_StandardNN   :  0.0116\n",
      "UEI: \n",
      "UEI_DeepEnsembles:  0.1489022262240894\n",
      "UEI_StandardNN   :  0.13902691848222662\n",
      "US_0: \n",
      "740 614\n",
      "US0_DeepEnsembles:  1.205211726384365\n",
      "746 614\n",
      "US0_StandardNN   :  1.214983713355049\n",
      "US_1: \n",
      "13959 11667\n",
      "US1_DeepEnsembles:  1.196451529956287\n",
      "13826 11667\n",
      "US1_StandardNN   :  1.1850518556612668\n"
     ]
    }
   ],
   "source": [
    "y_probs_combined = np.stack([model(Xtest) for model in trained_models])\n",
    "y_preds_combined = np.mean(y_probs_combined, axis=0)\n",
    "\n",
    "\n",
    "# Test the model after training\n",
    "test_results = DNN_model.evaluate(Xtest, np.array(y_test).reshape(-1,1), verbose=1)\n",
    "print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]}%')\n",
    "y_pred_1NN = DNN_model(Xtest)\n",
    "\n",
    "df = {}\n",
    "df['sa'] = group_test\n",
    "df['actual'] = y_test\n",
    "df['Ensembles'] = y_preds_combined.ravel()\n",
    "df['DNN'] = np.array(y_pred_1NN).ravel()\n",
    "df = pd.DataFrame(df)\n",
    "\n",
    "print(\"ECE with n_bins = 5:\")\n",
    "print(\"ECE_DeepEnsembles: \",compute_calibration_error(np.array(y_test),y_preds_combined,n_bins=5))\n",
    "print(\"ECE_StandardNN   : \",compute_calibration_error(np.array(y_test),y_pred_1NN,n_bins=5))\n",
    "\n",
    "\n",
    "\n",
    "print(\"UEI: \")\n",
    "print(\"UEI_DeepEnsembles: \",UEI(df.sa.values, df.actual.values, np.round(df['Ensembles'].values)))\n",
    "print(\"UEI_StandardNN   : \",UEI(df.sa.values, df.actual.values, np.round(df['DNN'].values)))\n",
    "\n",
    "print(\"US_0: \")\n",
    "print(\"US0_DeepEnsembles: \",underestimation_score_1(df.actual.values, np.round(df['Ensembles'].values),df.sa.values))\n",
    "print(\"US0_StandardNN   : \",underestimation_score_1(df.actual.values, np.round(df['DNN'].values),df.sa.values))\n",
    "\n",
    "print(\"US_1: \")\n",
    "print(\"US1_DeepEnsembles: \",underestimation_score(df.actual.values, np.round(df['Ensembles'].values),df.sa.values))\n",
    "print(\"US1_StandardNN   : \",underestimation_score(df.actual.values, np.round(df['DNN'].values),df.sa.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECE with n_bins = 5:\n",
      "ECE_DeepEnsembles_Maj:  0.0087\n",
      "ECE_DeepEnsembles_Min   :  0.0289\n",
      "ECE with n_bins = 5:\n",
      "ECE_DNN_Maj:  0.0109\n",
      "ECE_DNN_Min   :  0.0268\n"
     ]
    }
   ],
   "source": [
    "from sklearn.calibration import calibration_curve\n",
    "prob_true, prob_pred = calibration_curve(y_test, y_preds_combined, n_bins=5)\n",
    "prob_true_dnn, prob_pred_dnn = calibration_curve(y_test, y_pred_1NN, n_bins=5)\n",
    "minority = df[df['sa'] == 1]\n",
    "majority = df[df['sa'] == 0]\n",
    "prob_true_maj, prob_pred_maj = calibration_curve(np.array(majority.actual), majority['Ensembles'].values.reshape(-1,1), n_bins=5)\n",
    "prob_true_min, prob_pred_min = calibration_curve(np.array(minority.actual), minority['Ensembles'].values.reshape(-1,1), n_bins=5)\n",
    "prob_true_dnn_maj, prob_pre_dnnd_maj = calibration_curve(np.array(majority.actual), majority['DNN'].values.reshape(-1,1), n_bins=5)\n",
    "prob_true_dnn_min, prob_pred_dnn_min = calibration_curve(np.array(minority.actual), minority['DNN'].values.reshape(-1,1), n_bins=5)\n",
    "\n",
    "print(\"ECE with n_bins = 5:\")\n",
    "print(\"ECE_DeepEnsembles_Maj: \",compute_calibration_error(np.array(majority.actual), majority['Ensembles'].values.reshape(-1,1), n_bins=5))\n",
    "print(\"ECE_DeepEnsembles_Min   : \",compute_calibration_error(np.array(minority.actual), minority['Ensembles'].values.reshape(-1,1), n_bins=5))\n",
    "\n",
    "print(\"ECE with n_bins = 5:\")\n",
    "print(\"ECE_DNN_Maj: \",compute_calibration_error(np.array(majority.actual), majority['DNN'].values.reshape(-1,1), n_bins=5))\n",
    "print(\"ECE_DNN_Min   : \",compute_calibration_error(np.array(minority.actual), minority['DNN'].values.reshape(-1,1), n_bins=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best threshold for s=0 that minimizes P(Y|S) - P(Yhat|S) is:  0.6464646464646465\n",
      "best threshold for s=1 that minimizes P(Y|S) - P(Yhat|S) is:  0.6161616161616162\n",
      "Train:\n",
      "0.7734466178049577 0.4540603652179326 0.0019371098489292698\n",
      "Test:\n",
      "0.7598655545873273 0.4720355802821175 0.007842309425446474\n",
      "US_S_0\n",
      "11807 11667\n",
      "1.0119996571526528\n",
      "US_S_1\n",
      "624 614\n",
      "1.01628664495114\n"
     ]
    }
   ],
   "source": [
    "## Post-processing\n",
    "\n",
    "def find_thres(group,clf_prob,truth):\n",
    "    ls_0 = {}\n",
    "    ls_1 = {}\n",
    "    thresholds = np.linspace(0, 1, num=100)\n",
    "    for thres in thresholds:\n",
    "        df = {}\n",
    "        df['sa'] = group\n",
    "        df['prob'] = clf_prob\n",
    "        df['ground_truth'] = truth\n",
    "        df['prob_pred'] =[0]*len(truth)\n",
    "        df = pd.DataFrame(df)\n",
    "        df.loc[ (df['sa'] == 0) & (df['prob'] > thres),'prob_pred'] = 1\n",
    "        df.loc[ (df['sa'] == 1) & (df['prob'] > thres),'prob_pred'] = 1\n",
    "        US_pred_0 = df_count_feat_val_match(df, 'prob_pred', 1, 'sa',0)\n",
    "        US_true_0 = df_count_feat_val_match(df, 'ground_truth', 1, 'sa',0)\n",
    "        US_pred_1 = df_count_feat_val_match(df, 'prob_pred', 1, 'sa',1)\n",
    "        US_true_1 = df_count_feat_val_match(df, 'ground_truth', 1, 'sa',1)\n",
    "        ls_0[thres] = np.abs(US_pred_0-US_true_0)\n",
    "        ls_1[thres] = np.abs(US_pred_1-US_true_1)\n",
    "    best_0 = thresholds[np.argmin(list(ls_0.values()))]\n",
    "    best_1 = thresholds[np.argmin(list(ls_1.values()))]\n",
    "    print(\"best threshold for s=0 that minimizes P(Y|S) - P(Yhat|S) is: \",best_0)\n",
    "    print(\"best threshold for s=1 that minimizes P(Y|S) - P(Yhat|S) is: \",best_1)\n",
    "    return best_0,best_1\n",
    "\n",
    "def make_pred(group,clf_prob,thres_0,thres_1):\n",
    "    y_post = []\n",
    "    for sa,predictproba in zip(group,clf_prob):\n",
    "        if sa == 0 and predictproba > thres_0:\n",
    "            y_post.append(1)\n",
    "        elif sa == 0 and predictproba <= thres_0:\n",
    "            y_post.append(0)\n",
    "        elif sa == 1 and predictproba > thres_1:\n",
    "            y_post.append(1)\n",
    "        else:\n",
    "            y_post.append(0)\n",
    "    return y_post\n",
    "\n",
    "def evaluate(y_true,y_pred,sa):\n",
    "    ## convert the probability estimates to class labels (MC Dropout)\n",
    "\n",
    "    ba = accuracy_score(y_true,y_pred)\n",
    "    us_s = UEI(sa, y_true, np.round(y_pred))\n",
    "    return ba,us_s\n",
    "\n",
    "y_probs_combined = np.stack([model(Xtrain) for model in trained_models])\n",
    "y_preds_combined = np.mean(y_probs_combined, axis=0)\n",
    "best_thres_0,best_thres_1 = find_thres(group_train,np.array(y_preds_combined.ravel()),y_train)\n",
    "y_pred_post = make_pred(group_train,np.array(y_preds_combined.ravel()),best_thres_0,best_thres_1)\n",
    "best_ba,best_us = evaluate(y_train,np.array(y_pred_post),group_train)\n",
    "print(\"Train:\")\n",
    "print(best_ba,nll1(y_train,np.array(y_preds_combined.ravel())).numpy()/Xtrain.shape[0],best_us)\n",
    "## test\n",
    "y_probs_combined = np.stack([model(Xtest) for model in trained_models])\n",
    "y_preds_combined = np.mean(y_probs_combined, axis=0)\n",
    "y_pred_post = make_pred(group_test,np.array(y_preds_combined.ravel()),best_thres_0,best_thres_1)\n",
    "best_ba,best_us = evaluate(y_test,np.array(y_pred_post),group_test)\n",
    "print(\"Test:\")\n",
    "print(best_ba,nll1(y_test,np.array(y_preds_combined.ravel())).numpy()/Xtest.shape[0],best_us)\n",
    "\n",
    "print(\"US_S_0\")\n",
    "print(underestimation_score(y_test,y_pred_post,group_test))\n",
    "print(\"US_S_1\")\n",
    "print(underestimation_score_1(y_test,y_pred_post,group_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACS Travel time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from folktables import ACSDataSource, ACSTravelTime\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "data_source = ACSDataSource(survey_year='2018', horizon='1-Year', survey='person')\n",
    "acs_data = data_source.get_data(states=[\"CA\"], download=True)\n",
    "features, label, group = ACSTravelTime.df_to_numpy(acs_data)\n",
    "group = np.array([1 if x == 2 else 0 for x in group])\n",
    "Xtrain, Xtest, y_train, y_test, group_train, group_test = train_test_split(\n",
    "    features, label, group, test_size=0.2, random_state=0)\n",
    "std = StandardScaler()\n",
    "Xtrain = std.fit_transform(Xtrain)\n",
    "Xtest = std.transform(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Deep Ensembles Model~~~~~~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 10/10 [20:25<00:00, 122.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "   1/1079 [..............................] - ETA: 2:37 - loss: 0.5963 - accuracy: 0.7188"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1079/1079 [==============================] - 1s 1ms/step - loss: 0.5790 - accuracy: 0.6711\n",
      "Test results - Loss: 0.5789519548416138 - Accuracy: 0.6711205244064331%\n",
      "1079/1079 [==============================] - 1s 1ms/step - loss: 0.5807 - accuracy: 0.6678\n",
      "Test results - Loss: 0.5806553959846497 - Accuracy: 0.6677584052085876%\n",
      "1079/1079 [==============================] - 1s 1ms/step - loss: 0.5798 - accuracy: 0.6729\n",
      "Test results - Loss: 0.5797851085662842 - Accuracy: 0.6729465126991272%\n",
      "1079/1079 [==============================] - 1s 1ms/step - loss: 0.5816 - accuracy: 0.6705\n",
      "Test results - Loss: 0.5816010236740112 - Accuracy: 0.6705118417739868%\n",
      "1079/1079 [==============================] - 1s 1ms/step - loss: 0.5799 - accuracy: 0.6727\n",
      "Test results - Loss: 0.5799130201339722 - Accuracy: 0.6726566553115845%\n",
      "1079/1079 [==============================] - 1s 1ms/step - loss: 0.5781 - accuracy: 0.6718\n",
      "Test results - Loss: 0.5781004428863525 - Accuracy: 0.6717581748962402%\n",
      "1079/1079 [==============================] - 1s 1ms/step - loss: 0.5804 - accuracy: 0.6698\n",
      "Test results - Loss: 0.5803590416908264 - Accuracy: 0.669816255569458%\n",
      "1079/1079 [==============================] - 1s 1ms/step - loss: 0.5796 - accuracy: 0.6723\n",
      "Test results - Loss: 0.5795961618423462 - Accuracy: 0.6722508668899536%\n",
      "1079/1079 [==============================] - 1s 1ms/step - loss: 0.5784 - accuracy: 0.6738\n",
      "Test results - Loss: 0.5783756971359253 - Accuracy: 0.6738449931144714%\n",
      "1079/1079 [==============================] - 1s 1ms/step - loss: 0.5789 - accuracy: 0.6750\n",
      "Test results - Loss: 0.5789332985877991 - Accuracy: 0.6750333309173584%\n",
      "######################################################\n",
      " Loss    : 0.5796271145343781 - 0.0010213252466518175\n",
      " Accuracy: 0.6717697560787201 - 0.001981701991135412%\n",
      "Deep Ensembles trained!!!~~~~~~~\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training standard NN Model~~~~~~~\n",
      "Epoch 1/80\n",
      "1381/1381 [==============================] - 2s 1ms/step - loss: 0.6536 - accuracy: 0.5822\n",
      "Epoch 2/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.6227 - accuracy: 0.6223\n",
      "Epoch 3/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.6094 - accuracy: 0.6431\n",
      "Epoch 4/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.6011 - accuracy: 0.6499\n",
      "Epoch 5/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5984 - accuracy: 0.6537\n",
      "Epoch 6/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5965 - accuracy: 0.6569\n",
      "Epoch 7/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5955 - accuracy: 0.6584\n",
      "Epoch 8/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5942 - accuracy: 0.6586\n",
      "Epoch 9/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5933 - accuracy: 0.6597\n",
      "Epoch 10/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5924 - accuracy: 0.6629\n",
      "Epoch 11/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5916 - accuracy: 0.6637\n",
      "Epoch 12/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5908 - accuracy: 0.6644\n",
      "Epoch 13/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5899 - accuracy: 0.6652\n",
      "Epoch 14/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5895 - accuracy: 0.6668\n",
      "Epoch 15/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5887 - accuracy: 0.6673\n",
      "Epoch 16/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5879 - accuracy: 0.6682\n",
      "Epoch 17/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5872 - accuracy: 0.6692\n",
      "Epoch 18/80\n",
      "1381/1381 [==============================] - 3s 2ms/step - loss: 0.5866 - accuracy: 0.6699\n",
      "Epoch 19/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5858 - accuracy: 0.6707\n",
      "Epoch 20/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5849 - accuracy: 0.6713\n",
      "Epoch 21/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5841 - accuracy: 0.6718\n",
      "Epoch 22/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5836 - accuracy: 0.6723\n",
      "Epoch 23/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5828 - accuracy: 0.6719\n",
      "Epoch 24/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5823 - accuracy: 0.6726\n",
      "Epoch 25/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5817 - accuracy: 0.6741\n",
      "Epoch 26/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5813 - accuracy: 0.6738\n",
      "Epoch 27/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5807 - accuracy: 0.6738\n",
      "Epoch 28/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5803 - accuracy: 0.6746\n",
      "Epoch 29/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5799 - accuracy: 0.6756\n",
      "Epoch 30/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5797 - accuracy: 0.6741\n",
      "Epoch 31/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5788 - accuracy: 0.6751\n",
      "Epoch 32/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5783 - accuracy: 0.6746\n",
      "Epoch 33/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5782 - accuracy: 0.6753\n",
      "Epoch 34/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5778 - accuracy: 0.6756\n",
      "Epoch 35/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5776 - accuracy: 0.6762\n",
      "Epoch 36/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5776 - accuracy: 0.6756\n",
      "Epoch 37/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5769 - accuracy: 0.6752\n",
      "Epoch 38/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5768 - accuracy: 0.6762\n",
      "Epoch 39/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5766 - accuracy: 0.6761\n",
      "Epoch 40/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5764 - accuracy: 0.6760\n",
      "Epoch 41/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5762 - accuracy: 0.6763\n",
      "Epoch 42/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5761 - accuracy: 0.6765\n",
      "Epoch 43/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5758 - accuracy: 0.6757\n",
      "Epoch 44/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5761 - accuracy: 0.6756\n",
      "Epoch 45/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5758 - accuracy: 0.6761\n",
      "Epoch 46/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5753 - accuracy: 0.6764\n",
      "Epoch 47/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5755 - accuracy: 0.6759\n",
      "Epoch 48/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5757 - accuracy: 0.6751\n",
      "Epoch 49/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5751 - accuracy: 0.6763\n",
      "Epoch 50/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5749 - accuracy: 0.6766\n",
      "Epoch 51/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5745 - accuracy: 0.6761\n",
      "Epoch 52/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5747 - accuracy: 0.6768\n",
      "Epoch 53/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5745 - accuracy: 0.6768\n",
      "Epoch 54/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5747 - accuracy: 0.6766\n",
      "Epoch 55/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5743 - accuracy: 0.6768\n",
      "Epoch 56/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5743 - accuracy: 0.6769\n",
      "Epoch 57/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5743 - accuracy: 0.6766\n",
      "Epoch 58/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5740 - accuracy: 0.6777\n",
      "Epoch 59/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5740 - accuracy: 0.6775\n",
      "Epoch 60/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5741 - accuracy: 0.6766\n",
      "Epoch 61/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5740 - accuracy: 0.6776\n",
      "Epoch 62/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5736 - accuracy: 0.6776\n",
      "Epoch 63/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5736 - accuracy: 0.6766\n",
      "Epoch 64/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5734 - accuracy: 0.6780\n",
      "Epoch 65/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5734 - accuracy: 0.6773\n",
      "Epoch 66/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5733 - accuracy: 0.6770\n",
      "Epoch 67/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5730 - accuracy: 0.6773\n",
      "Epoch 68/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5731 - accuracy: 0.6770\n",
      "Epoch 69/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5728 - accuracy: 0.6777\n",
      "Epoch 70/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5731 - accuracy: 0.6768\n",
      "Epoch 71/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5730 - accuracy: 0.6775\n",
      "Epoch 72/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5729 - accuracy: 0.6764\n",
      "Epoch 73/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5730 - accuracy: 0.6769\n",
      "Epoch 74/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5729 - accuracy: 0.6771\n",
      "Epoch 75/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5728 - accuracy: 0.6774\n",
      "Epoch 76/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5727 - accuracy: 0.6767\n",
      "Epoch 77/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5724 - accuracy: 0.6773\n",
      "Epoch 78/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5725 - accuracy: 0.6766\n",
      "Epoch 79/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5726 - accuracy: 0.6776\n",
      "Epoch 80/80\n",
      "1381/1381 [==============================] - 2s 2ms/step - loss: 0.5725 - accuracy: 0.6769\n",
      "Standard NN trained!!!~~~~~~~\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Train Deep Ensembles Model\n",
    "print(\"Training Deep Ensembles Model~~~~~~~\")\n",
    "histories,trained_models = train(Xtrain, np.array(y_train).reshape(-1,1), epochs=80, batch=100)\n",
    "losses,accuracies = model_eval(Xtest,np.array(y_test).reshape(-1,1),trained_models)\n",
    "print(\"Deep Ensembles trained!!!~~~~~~~\")\n",
    "print(\"\\n\\n\\n\\n\\n\")\n",
    "## Train standard NN\n",
    "print(\"Training standard NN Model~~~~~~~\")\n",
    "DNN_model = Sequential([\n",
    "            Dense(50,activation='sigmoid'),\n",
    "            Dense(1,activation='sigmoid')])\n",
    "DNN_model.compile(tf.keras.optimizers.Adam(learning_rate=0.01), loss='binary_crossentropy',metrics=[\"accuracy\"])\n",
    "DNN_model.fit(Xtrain, np.array(y_train).reshape(-1,1), epochs=80, batch_size=100)\n",
    "print(\"Standard NN trained!!!~~~~~~~\")\n",
    "print(\"\\n\\n\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1079/1079 [==============================] - 2s 1ms/step - loss: 0.5805 - accuracy: 0.6714\n",
      "Test results - Loss: 0.5805374979972839 - Accuracy: 0.6713523864746094%\n",
      "ECE with n_bins = 5:\n",
      "ECE_DeepEnsembles:  0.0069\n",
      "ECE_StandardNN   :  0.0319\n",
      "UEI: \n",
      "UEI_DeepEnsembles:  0.03181804480231499\n",
      "UEI_StandardNN   :  0.014400473756297653\n",
      "US_0: \n",
      "754 796\n",
      "US0_DeepEnsembles:  0.9472361809045227\n",
      "850 796\n",
      "US0_StandardNN   :  1.0678391959798994\n",
      "US_1: \n",
      "14348 15848\n",
      "US1_DeepEnsembles:  0.9053508329126704\n",
      "16485 15848\n",
      "US1_StandardNN   :  1.0401943462897527\n"
     ]
    }
   ],
   "source": [
    "y_probs_combined = np.stack([model(Xtest) for model in trained_models])\n",
    "y_preds_combined = np.mean(y_probs_combined, axis=0)\n",
    "\n",
    "\n",
    "# Test the model after training\n",
    "test_results = DNN_model.evaluate(Xtest, np.array(y_test).reshape(-1,1), verbose=1)\n",
    "print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]}%')\n",
    "y_pred_1NN = DNN_model(Xtest)\n",
    "\n",
    "df = {}\n",
    "df['sa'] = group_test\n",
    "df['actual'] = y_test\n",
    "df['Ensembles'] = y_preds_combined.ravel()\n",
    "df['DNN'] = np.array(y_pred_1NN).ravel()\n",
    "df = pd.DataFrame(df)\n",
    "\n",
    "print(\"ECE with n_bins = 5:\")\n",
    "print(\"ECE_DeepEnsembles: \",compute_calibration_error(np.array(y_test),y_preds_combined,n_bins=5))\n",
    "print(\"ECE_StandardNN   : \",compute_calibration_error(np.array(y_test),y_pred_1NN,n_bins=5))\n",
    "\n",
    "\n",
    "\n",
    "print(\"UEI: \")\n",
    "print(\"UEI_DeepEnsembles: \",UEI(df.sa.values, df.actual.values, np.round(df['Ensembles'].values)))\n",
    "print(\"UEI_StandardNN   : \",UEI(df.sa.values, df.actual.values, np.round(df['DNN'].values)))\n",
    "\n",
    "print(\"US_0: \")\n",
    "print(\"US0_DeepEnsembles: \",underestimation_score_1(df.actual.values, np.round(df['Ensembles'].values),df.sa.values))\n",
    "print(\"US0_StandardNN   : \",underestimation_score_1(df.actual.values, np.round(df['DNN'].values),df.sa.values))\n",
    "\n",
    "print(\"US_1: \")\n",
    "print(\"US1_DeepEnsembles: \",underestimation_score(df.actual.values, np.round(df['Ensembles'].values),df.sa.values))\n",
    "print(\"US1_StandardNN   : \",underestimation_score(df.actual.values, np.round(df['DNN'].values),df.sa.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECE with n_bins = 5:\n",
      "ECE_DeepEnsembles_Maj:  0.0084\n",
      "ECE_DeepEnsembles_Min   :  0.0481\n",
      "ECE with n_bins = 5:\n",
      "ECE_DNN_Maj:  0.0338\n",
      "ECE_DNN_Min   :  0.0343\n"
     ]
    }
   ],
   "source": [
    "from sklearn.calibration import calibration_curve\n",
    "prob_true, prob_pred = calibration_curve(y_test, y_preds_combined, n_bins=5)\n",
    "prob_true_dnn, prob_pred_dnn = calibration_curve(y_test, y_pred_1NN, n_bins=5)\n",
    "minority = df[df['sa'] == 1]\n",
    "majority = df[df['sa'] == 0]\n",
    "prob_true_maj, prob_pred_maj = calibration_curve(np.array(majority.actual), majority['Ensembles'].values.reshape(-1,1), n_bins=5)\n",
    "prob_true_min, prob_pred_min = calibration_curve(np.array(minority.actual), minority['Ensembles'].values.reshape(-1,1), n_bins=5)\n",
    "prob_true_dnn_maj, prob_pre_dnnd_maj = calibration_curve(np.array(majority.actual), majority['DNN'].values.reshape(-1,1), n_bins=5)\n",
    "prob_true_dnn_min, prob_pred_dnn_min = calibration_curve(np.array(minority.actual), minority['DNN'].values.reshape(-1,1), n_bins=5)\n",
    "\n",
    "print(\"ECE with n_bins = 5:\")\n",
    "print(\"ECE_DeepEnsembles_Maj: \",compute_calibration_error(np.array(majority.actual), majority['Ensembles'].values.reshape(-1,1), n_bins=5))\n",
    "print(\"ECE_DeepEnsembles_Min   : \",compute_calibration_error(np.array(minority.actual), minority['Ensembles'].values.reshape(-1,1), n_bins=5))\n",
    "\n",
    "print(\"ECE with n_bins = 5:\")\n",
    "print(\"ECE_DNN_Maj: \",compute_calibration_error(np.array(majority.actual), majority['DNN'].values.reshape(-1,1), n_bins=5))\n",
    "print(\"ECE_DNN_Min   : \",compute_calibration_error(np.array(minority.actual), minority['DNN'].values.reshape(-1,1), n_bins=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best threshold for s=0 that minimizes P(Y|S) - P(Yhat|S) is:  0.4747474747474748\n",
      "best threshold for s=1 that minimizes P(Y|S) - P(Yhat|S) is:  0.48484848484848486\n",
      "Train:\n",
      "0.6837021578771938 0.5646913109756098 0.006049649048564927\n",
      "Test:\n",
      "0.674743493130833 0.5738773975059417 0.007668938071289827\n",
      "US_S_0\n",
      "16212 15848\n",
      "1.0229681978798586\n",
      "US_S_1\n",
      "804 796\n",
      "1.0100502512562815\n"
     ]
    }
   ],
   "source": [
    "## Post-processing\n",
    "\n",
    "def find_thres(group,clf_prob,truth):\n",
    "    ls_0 = {}\n",
    "    ls_1 = {}\n",
    "    thresholds = np.linspace(0, 1, num=100)\n",
    "    for thres in thresholds:\n",
    "        df = {}\n",
    "        df['sa'] = group\n",
    "        df['prob'] = clf_prob\n",
    "        df['ground_truth'] = truth\n",
    "        df['prob_pred'] =[0]*len(truth)\n",
    "        df = pd.DataFrame(df)\n",
    "        df.loc[ (df['sa'] == 0) & (df['prob'] > thres),'prob_pred'] = 1\n",
    "        df.loc[ (df['sa'] == 1) & (df['prob'] > thres),'prob_pred'] = 1\n",
    "        US_pred_0 = df_count_feat_val_match(df, 'prob_pred', 1, 'sa',0)\n",
    "        US_true_0 = df_count_feat_val_match(df, 'ground_truth', 1, 'sa',0)\n",
    "        US_pred_1 = df_count_feat_val_match(df, 'prob_pred', 1, 'sa',1)\n",
    "        US_true_1 = df_count_feat_val_match(df, 'ground_truth', 1, 'sa',1)\n",
    "        ls_0[thres] = np.abs(US_pred_0-US_true_0)\n",
    "        ls_1[thres] = np.abs(US_pred_1-US_true_1)\n",
    "    best_0 = thresholds[np.argmin(list(ls_0.values()))]\n",
    "    best_1 = thresholds[np.argmin(list(ls_1.values()))]\n",
    "    print(\"best threshold for s=0 that minimizes P(Y|S) - P(Yhat|S) is: \",best_0)\n",
    "    print(\"best threshold for s=1 that minimizes P(Y|S) - P(Yhat|S) is: \",best_1)\n",
    "    return best_0,best_1\n",
    "\n",
    "def make_pred(group,clf_prob,thres_0,thres_1):\n",
    "    y_post = []\n",
    "    for sa,predictproba in zip(group,clf_prob):\n",
    "        if sa == 0 and predictproba > thres_0:\n",
    "            y_post.append(1)\n",
    "        elif sa == 0 and predictproba <= thres_0:\n",
    "            y_post.append(0)\n",
    "        elif sa == 1 and predictproba > thres_1:\n",
    "            y_post.append(1)\n",
    "        else:\n",
    "            y_post.append(0)\n",
    "    return y_post\n",
    "\n",
    "def evaluate(y_true,y_pred,sa):\n",
    "    ## convert the probability estimates to class labels (MC Dropout)\n",
    "\n",
    "    ba = accuracy_score(y_true,y_pred)\n",
    "    us_s = UEI(sa, y_true, np.round(y_pred))\n",
    "    return ba,us_s\n",
    "\n",
    "y_probs_combined = np.stack([model(Xtrain) for model in trained_models])\n",
    "y_preds_combined = np.mean(y_probs_combined, axis=0)\n",
    "best_thres_0,best_thres_1 = find_thres(group_train,np.array(y_preds_combined.ravel()),y_train)\n",
    "y_pred_post = make_pred(group_train,np.array(y_preds_combined.ravel()),best_thres_0,best_thres_1)\n",
    "best_ba,best_us = evaluate(y_train,np.array(y_pred_post),group_train)\n",
    "print(\"Train:\")\n",
    "print(best_ba,nll1(y_train,np.array(y_preds_combined.ravel())).numpy()/Xtrain.shape[0],best_us)\n",
    "## test\n",
    "y_probs_combined = np.stack([model(Xtest) for model in trained_models])\n",
    "y_preds_combined = np.mean(y_probs_combined, axis=0)\n",
    "y_pred_post = make_pred(group_test,np.array(y_preds_combined.ravel()),best_thres_0,best_thres_1)\n",
    "best_ba,best_us = evaluate(y_test,np.array(y_pred_post),group_test)\n",
    "print(\"Test:\")\n",
    "print(best_ba,nll1(y_test,np.array(y_preds_combined.ravel())).numpy()/Xtest.shape[0],best_us)\n",
    "\n",
    "print(\"US_S_0\")\n",
    "print(underestimation_score(y_test,y_pred_post,group_test))\n",
    "print(\"US_S_1\")\n",
    "print(underestimation_score_1(y_test,y_pred_post,group_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACS Employment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from folktables import ACSDataSource, ACSEmployment\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "data_source = ACSDataSource(survey_year='2018', horizon='1-Year', survey='person')\n",
    "acs_data = data_source.get_data(states=[\"CA\"], download=True)\n",
    "features, label, group = ACSEmployment.df_to_numpy(acs_data)\n",
    "group = np.array([1 if x == 2 else 0 for x in group])\n",
    "Xtrain, Xtest, y_train, y_test, group_train, group_test = train_test_split(\n",
    "    features, label, group, test_size=0.2, random_state=0)\n",
    "Xtrain = std.fit_transform(Xtrain)\n",
    "Xtest = std.transform(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Deep Ensembles Model~~~~~~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 10/10 [51:18<00:00, 307.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "   1/2368 [..............................] - ETA: 6:20 - loss: 0.3457 - accuracy: 0.8125"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2368/2368 [==============================] - 3s 1ms/step - loss: 0.3878 - accuracy: 0.8191\n",
      "Test results - Loss: 0.38782840967178345 - Accuracy: 0.8190697431564331%\n",
      "2368/2368 [==============================] - 3s 1ms/step - loss: 0.3861 - accuracy: 0.8199\n",
      "Test results - Loss: 0.3860671818256378 - Accuracy: 0.8199276924133301%\n",
      "2368/2368 [==============================] - 3s 1ms/step - loss: 0.3858 - accuracy: 0.8201\n",
      "Test results - Loss: 0.385774165391922 - Accuracy: 0.8200992345809937%\n",
      "2368/2368 [==============================] - 3s 1ms/step - loss: 0.3865 - accuracy: 0.8199\n",
      "Test results - Loss: 0.38654863834381104 - Accuracy: 0.8198880553245544%\n",
      "2368/2368 [==============================] - 3s 1ms/step - loss: 0.3863 - accuracy: 0.8186\n",
      "Test results - Loss: 0.38634762167930603 - Accuracy: 0.8186078071594238%\n",
      "2368/2368 [==============================] - 3s 1ms/step - loss: 0.3867 - accuracy: 0.8195\n",
      "Test results - Loss: 0.3866567015647888 - Accuracy: 0.8195053339004517%\n",
      "2368/2368 [==============================] - 3s 1ms/step - loss: 0.3855 - accuracy: 0.8206\n",
      "Test results - Loss: 0.38548049330711365 - Accuracy: 0.8205744028091431%\n",
      "2368/2368 [==============================] - 3s 1ms/step - loss: 0.3885 - accuracy: 0.8188\n",
      "Test results - Loss: 0.388516366481781 - Accuracy: 0.8188453912734985%\n",
      "2368/2368 [==============================] - 3s 1ms/step - loss: 0.3861 - accuracy: 0.8204\n",
      "Test results - Loss: 0.38613161444664 - Accuracy: 0.8203500509262085%\n",
      "2368/2368 [==============================] - 3s 1ms/step - loss: 0.3880 - accuracy: 0.8185\n",
      "Test results - Loss: 0.38795870542526245 - Accuracy: 0.8184757828712463%\n",
      "######################################################\n",
      " Loss    : 0.3867309898138046 - 0.0009676814613514458\n",
      " Accuracy: 0.8195343494415284 - 0.0007082661737548235%\n",
      "Deep Ensembles trained!!!~~~~~~~\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training standard NN Model~~~~~~~\n",
      "Epoch 1/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.4222 - accuracy: 0.7980\n",
      "Epoch 2/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.4014 - accuracy: 0.8098\n",
      "Epoch 3/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3977 - accuracy: 0.8126\n",
      "Epoch 4/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3953 - accuracy: 0.8141\n",
      "Epoch 5/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3936 - accuracy: 0.8151\n",
      "Epoch 6/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3928 - accuracy: 0.8160\n",
      "Epoch 7/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3919 - accuracy: 0.8161\n",
      "Epoch 8/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3913 - accuracy: 0.8165\n",
      "Epoch 9/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3909 - accuracy: 0.8172\n",
      "Epoch 10/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3906 - accuracy: 0.8168\n",
      "Epoch 11/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3902 - accuracy: 0.8172\n",
      "Epoch 12/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3899 - accuracy: 0.8176\n",
      "Epoch 13/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3896 - accuracy: 0.8179\n",
      "Epoch 14/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3894 - accuracy: 0.8177\n",
      "Epoch 15/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3892 - accuracy: 0.8183\n",
      "Epoch 16/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3891 - accuracy: 0.8180\n",
      "Epoch 17/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3891 - accuracy: 0.8178\n",
      "Epoch 18/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3888 - accuracy: 0.8187\n",
      "Epoch 19/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3886 - accuracy: 0.8175\n",
      "Epoch 20/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3885 - accuracy: 0.8184\n",
      "Epoch 21/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3885 - accuracy: 0.8183\n",
      "Epoch 22/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3881 - accuracy: 0.8185\n",
      "Epoch 23/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3880 - accuracy: 0.8190\n",
      "Epoch 24/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3881 - accuracy: 0.8181\n",
      "Epoch 25/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3880 - accuracy: 0.8185\n",
      "Epoch 26/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3878 - accuracy: 0.8186\n",
      "Epoch 27/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3878 - accuracy: 0.8185\n",
      "Epoch 28/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3875 - accuracy: 0.8185\n",
      "Epoch 29/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3875 - accuracy: 0.8186\n",
      "Epoch 30/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3875 - accuracy: 0.8191\n",
      "Epoch 31/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3872 - accuracy: 0.8193\n",
      "Epoch 32/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3873 - accuracy: 0.8190\n",
      "Epoch 33/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3870 - accuracy: 0.8194\n",
      "Epoch 34/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3871 - accuracy: 0.8191\n",
      "Epoch 35/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3871 - accuracy: 0.8188\n",
      "Epoch 36/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3872 - accuracy: 0.8191\n",
      "Epoch 37/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3869 - accuracy: 0.8194\n",
      "Epoch 38/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3869 - accuracy: 0.8192\n",
      "Epoch 39/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3869 - accuracy: 0.8191\n",
      "Epoch 40/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3866 - accuracy: 0.8196\n",
      "Epoch 41/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3867 - accuracy: 0.8192\n",
      "Epoch 42/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3867 - accuracy: 0.8192\n",
      "Epoch 43/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3868 - accuracy: 0.8191\n",
      "Epoch 44/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3866 - accuracy: 0.8194\n",
      "Epoch 45/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3866 - accuracy: 0.8194\n",
      "Epoch 46/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3865 - accuracy: 0.8196\n",
      "Epoch 47/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3863 - accuracy: 0.8190\n",
      "Epoch 48/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3862 - accuracy: 0.8197\n",
      "Epoch 49/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3863 - accuracy: 0.8195\n",
      "Epoch 50/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3863 - accuracy: 0.8194\n",
      "Epoch 51/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3861 - accuracy: 0.8196\n",
      "Epoch 52/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3861 - accuracy: 0.8195\n",
      "Epoch 53/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3861 - accuracy: 0.8197\n",
      "Epoch 54/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3858 - accuracy: 0.8200\n",
      "Epoch 55/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3859 - accuracy: 0.8197\n",
      "Epoch 56/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3858 - accuracy: 0.8195\n",
      "Epoch 57/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3859 - accuracy: 0.8198\n",
      "Epoch 58/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3855 - accuracy: 0.8198\n",
      "Epoch 59/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3856 - accuracy: 0.8195\n",
      "Epoch 60/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3856 - accuracy: 0.8199\n",
      "Epoch 61/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3855 - accuracy: 0.8198\n",
      "Epoch 62/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3854 - accuracy: 0.8199\n",
      "Epoch 63/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3851 - accuracy: 0.8199\n",
      "Epoch 64/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3853 - accuracy: 0.8200\n",
      "Epoch 65/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3851 - accuracy: 0.8202\n",
      "Epoch 66/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3850 - accuracy: 0.8201\n",
      "Epoch 67/80\n",
      "3031/3031 [==============================] - 6s 2ms/step - loss: 0.3850 - accuracy: 0.8198\n",
      "Epoch 68/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3848 - accuracy: 0.8199\n",
      "Epoch 69/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3848 - accuracy: 0.8199\n",
      "Epoch 70/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3848 - accuracy: 0.8204\n",
      "Epoch 71/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3848 - accuracy: 0.8201\n",
      "Epoch 72/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3846 - accuracy: 0.8201\n",
      "Epoch 73/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3847 - accuracy: 0.8197\n",
      "Epoch 74/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3845 - accuracy: 0.8202\n",
      "Epoch 75/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3845 - accuracy: 0.8203\n",
      "Epoch 76/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3846 - accuracy: 0.8208\n",
      "Epoch 77/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3845 - accuracy: 0.8200\n",
      "Epoch 78/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3844 - accuracy: 0.8200\n",
      "Epoch 79/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3843 - accuracy: 0.8204\n",
      "Epoch 80/80\n",
      "3031/3031 [==============================] - 5s 2ms/step - loss: 0.3845 - accuracy: 0.8200\n",
      "Standard NN trained!!!~~~~~~~\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Train Deep Ensembles Model\n",
    "print(\"Training Deep Ensembles Model~~~~~~~\")\n",
    "histories,trained_models = train(Xtrain, np.array(y_train).reshape(-1,1), epochs=80, batch=100)\n",
    "losses,accuracies = model_eval(Xtest,np.array(y_test).reshape(-1,1),trained_models)\n",
    "print(\"Deep Ensembles trained!!!~~~~~~~\")\n",
    "print(\"\\n\\n\\n\\n\\n\")\n",
    "## Train standard NN\n",
    "print(\"Training standard NN Model~~~~~~~\")\n",
    "DNN_model = Sequential([\n",
    "            Dense(50,activation='sigmoid'),\n",
    "            Dense(1,activation='sigmoid')])\n",
    "DNN_model.compile(tf.keras.optimizers.Adam(learning_rate=0.01), loss='binary_crossentropy',metrics=[\"accuracy\"])\n",
    "DNN_model.fit(Xtrain, np.array(y_train).reshape(-1,1), epochs=80, batch_size=100)\n",
    "print(\"Standard NN trained!!!~~~~~~~\")\n",
    "print(\"\\n\\n\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2368/2368 [==============================] - 3s 1ms/step - loss: 0.3847 - accuracy: 0.8195\n",
      "Test results - Loss: 0.3846989870071411 - Accuracy: 0.819518506526947%\n",
      "ECE with n_bins = 5:\n",
      "ECE_DeepEnsembles:  0.0053\n",
      "ECE_StandardNN   :  0.0101\n",
      "UEI: \n",
      "UEI_DeepEnsembles:  0.03644318957341736\n",
      "UEI_StandardNN   :  0.044668098715933184\n",
      "US_0: \n",
      "1680 1466\n",
      "US0_DeepEnsembles:  1.145975443383356\n",
      "1703 1466\n",
      "US0_StandardNN   :  1.1616643929058663\n",
      "US_1: \n",
      "36645 32962\n",
      "US1_DeepEnsembles:  1.111734724834658\n",
      "37505 32962\n",
      "US1_StandardNN   :  1.137825374673867\n"
     ]
    }
   ],
   "source": [
    "y_probs_combined = np.stack([model(Xtest) for model in trained_models])\n",
    "y_preds_combined = np.mean(y_probs_combined, axis=0)\n",
    "\n",
    "\n",
    "# Test the model after training\n",
    "test_results = DNN_model.evaluate(Xtest, np.array(y_test).reshape(-1,1), verbose=1)\n",
    "print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]}%')\n",
    "y_pred_1NN = DNN_model(Xtest)\n",
    "\n",
    "df = {}\n",
    "df['sa'] = group_test\n",
    "df['actual'] = y_test\n",
    "df['Ensembles'] = y_preds_combined.ravel()\n",
    "df['DNN'] = np.array(y_pred_1NN).ravel()\n",
    "df = pd.DataFrame(df)\n",
    "\n",
    "print(\"ECE with n_bins = 5:\")\n",
    "print(\"ECE_DeepEnsembles: \",compute_calibration_error(np.array(y_test),y_preds_combined,n_bins=5))\n",
    "print(\"ECE_StandardNN   : \",compute_calibration_error(np.array(y_test),y_pred_1NN,n_bins=5))\n",
    "\n",
    "\n",
    "\n",
    "print(\"UEI: \")\n",
    "print(\"UEI_DeepEnsembles: \",UEI(df.sa.values, df.actual.values, np.round(df['Ensembles'].values)))\n",
    "print(\"UEI_StandardNN   : \",UEI(df.sa.values, df.actual.values, np.round(df['DNN'].values)))\n",
    "\n",
    "print(\"US_0: \")\n",
    "print(\"US0_DeepEnsembles: \",underestimation_score_1(df.actual.values, np.round(df['Ensembles'].values),df.sa.values))\n",
    "print(\"US0_StandardNN   : \",underestimation_score_1(df.actual.values, np.round(df['DNN'].values),df.sa.values))\n",
    "\n",
    "print(\"US_1: \")\n",
    "print(\"US1_DeepEnsembles: \",underestimation_score(df.actual.values, np.round(df['Ensembles'].values),df.sa.values))\n",
    "print(\"US1_StandardNN   : \",underestimation_score(df.actual.values, np.round(df['DNN'].values),df.sa.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECE with n_bins = 5:\n",
      "ECE_DeepEnsembles_Maj:  0.0052\n",
      "ECE_DeepEnsembles_Min   :  0.0261\n",
      "ECE with n_bins = 5:\n",
      "ECE_DNN_Maj:  0.0094\n",
      "ECE_DNN_Min   :  0.0288\n"
     ]
    }
   ],
   "source": [
    "from sklearn.calibration import calibration_curve\n",
    "prob_true, prob_pred = calibration_curve(y_test, y_preds_combined, n_bins=5)\n",
    "prob_true_dnn, prob_pred_dnn = calibration_curve(y_test, y_pred_1NN, n_bins=5)\n",
    "minority = df[df['sa'] == 1]\n",
    "majority = df[df['sa'] == 0]\n",
    "prob_true_maj, prob_pred_maj = calibration_curve(np.array(majority.actual), majority['Ensembles'].values.reshape(-1,1), n_bins=5)\n",
    "prob_true_min, prob_pred_min = calibration_curve(np.array(minority.actual), minority['Ensembles'].values.reshape(-1,1), n_bins=5)\n",
    "prob_true_dnn_maj, prob_pre_dnnd_maj = calibration_curve(np.array(majority.actual), majority['DNN'].values.reshape(-1,1), n_bins=5)\n",
    "prob_true_dnn_min, prob_pred_dnn_min = calibration_curve(np.array(minority.actual), minority['DNN'].values.reshape(-1,1), n_bins=5)\n",
    "\n",
    "print(\"ECE with n_bins = 5:\")\n",
    "print(\"ECE_DeepEnsembles_Maj: \",compute_calibration_error(np.array(majority.actual), majority['Ensembles'].values.reshape(-1,1), n_bins=5))\n",
    "print(\"ECE_DeepEnsembles_Min   : \",compute_calibration_error(np.array(minority.actual), minority['Ensembles'].values.reshape(-1,1), n_bins=5))\n",
    "\n",
    "print(\"ECE with n_bins = 5:\")\n",
    "print(\"ECE_DNN_Maj: \",compute_calibration_error(np.array(majority.actual), majority['DNN'].values.reshape(-1,1), n_bins=5))\n",
    "print(\"ECE_DNN_Min   : \",compute_calibration_error(np.array(minority.actual), minority['DNN'].values.reshape(-1,1), n_bins=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best threshold for s=0 that minimizes P(Y|S) - P(Yhat|S) is:  0.5858585858585859\n",
      "best threshold for s=1 that minimizes P(Y|S) - P(Yhat|S) is:  0.6060606060606061\n",
      "Train:\n",
      "0.817833844245066 0.37916640199899027 0.001567349615543771\n",
      "Test:\n",
      "0.8164695633810253 0.38179200997505414 0.0015099175172066763\n",
      "US_S_0\n",
      "32820 32962\n",
      "0.9956920089800376\n",
      "US_S_1\n",
      "1481 1466\n",
      "1.010231923601637\n"
     ]
    }
   ],
   "source": [
    "## Post-processing\n",
    "\n",
    "def find_thres(group,clf_prob,truth):\n",
    "    ls_0 = {}\n",
    "    ls_1 = {}\n",
    "    thresholds = np.linspace(0, 1, num=100)\n",
    "    for thres in thresholds:\n",
    "        df = {}\n",
    "        df['sa'] = group\n",
    "        df['prob'] = clf_prob\n",
    "        df['ground_truth'] = truth\n",
    "        df['prob_pred'] =[0]*len(truth)\n",
    "        df = pd.DataFrame(df)\n",
    "        df.loc[ (df['sa'] == 0) & (df['prob'] > thres),'prob_pred'] = 1\n",
    "        df.loc[ (df['sa'] == 1) & (df['prob'] > thres),'prob_pred'] = 1\n",
    "        US_pred_0 = df_count_feat_val_match(df, 'prob_pred', 1, 'sa',0)\n",
    "        US_true_0 = df_count_feat_val_match(df, 'ground_truth', 1, 'sa',0)\n",
    "        US_pred_1 = df_count_feat_val_match(df, 'prob_pred', 1, 'sa',1)\n",
    "        US_true_1 = df_count_feat_val_match(df, 'ground_truth', 1, 'sa',1)\n",
    "        ls_0[thres] = np.abs(US_pred_0-US_true_0)\n",
    "        ls_1[thres] = np.abs(US_pred_1-US_true_1)\n",
    "    best_0 = thresholds[np.argmin(list(ls_0.values()))]\n",
    "    best_1 = thresholds[np.argmin(list(ls_1.values()))]\n",
    "    print(\"best threshold for s=0 that minimizes P(Y|S) - P(Yhat|S) is: \",best_0)\n",
    "    print(\"best threshold for s=1 that minimizes P(Y|S) - P(Yhat|S) is: \",best_1)\n",
    "    return best_0,best_1\n",
    "\n",
    "def make_pred(group,clf_prob,thres_0,thres_1):\n",
    "    y_post = []\n",
    "    for sa,predictproba in zip(group,clf_prob):\n",
    "        if sa == 0 and predictproba > thres_0:\n",
    "            y_post.append(1)\n",
    "        elif sa == 0 and predictproba <= thres_0:\n",
    "            y_post.append(0)\n",
    "        elif sa == 1 and predictproba > thres_1:\n",
    "            y_post.append(1)\n",
    "        else:\n",
    "            y_post.append(0)\n",
    "    return y_post\n",
    "\n",
    "def evaluate(y_true,y_pred,sa):\n",
    "    ## convert the probability estimates to class labels (MC Dropout)\n",
    "\n",
    "    ba = accuracy_score(y_true,y_pred)\n",
    "    us_s = UEI(sa, y_true, np.round(y_pred))\n",
    "    return ba,us_s\n",
    "\n",
    "y_probs_combined = np.stack([model(Xtrain) for model in trained_models])\n",
    "y_preds_combined = np.mean(y_probs_combined, axis=0)\n",
    "best_thres_0,best_thres_1 = find_thres(group_train,np.array(y_preds_combined.ravel()),y_train)\n",
    "y_pred_post = make_pred(group_train,np.array(y_preds_combined.ravel()),best_thres_0,best_thres_1)\n",
    "best_ba,best_us = evaluate(y_train,np.array(y_pred_post),group_train)\n",
    "print(\"Train:\")\n",
    "print(best_ba,nll1(y_train,np.array(y_preds_combined.ravel())).numpy()/Xtrain.shape[0],best_us)\n",
    "## test\n",
    "y_probs_combined = np.stack([model(Xtest) for model in trained_models])\n",
    "y_preds_combined = np.mean(y_probs_combined, axis=0)\n",
    "y_pred_post = make_pred(group_test,np.array(y_preds_combined.ravel()),best_thres_0,best_thres_1)\n",
    "best_ba,best_us = evaluate(y_test,np.array(y_pred_post),group_test)\n",
    "print(\"Test:\")\n",
    "print(best_ba,nll1(y_test,np.array(y_preds_combined.ravel())).numpy()/Xtest.shape[0],best_us)\n",
    "\n",
    "print(\"US_S_0\")\n",
    "print(underestimation_score(y_test,y_pred_post,group_test))\n",
    "print(\"US_S_1\")\n",
    "print(underestimation_score_1(y_test,y_pred_post,group_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACS Public Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from folktables import ACSDataSource, ACSPublicCoverage\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "data_source = ACSDataSource(survey_year='2018', horizon='1-Year', survey='person')\n",
    "acs_data = data_source.get_data(states=[\"CA\"], download=True)\n",
    "features, label, group = ACSPublicCoverage.df_to_numpy(acs_data)\n",
    "group = np.array([1 if x == 1 else 0 for x in group])\n",
    "Xtrain, Xtest, y_train, y_test, group_train, group_test = train_test_split(\n",
    "    features, label, group, test_size=0.2, random_state=0)\n",
    "Xtrain = std.fit_transform(Xtrain)\n",
    "Xtest = std.transform(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Deep Ensembles Model~~~~~~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 10/10 [21:43<00:00, 130.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  1/866 [..............................] - ETA: 2:17 - loss: 0.6425 - accuracy: 0.6250"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "866/866 [==============================] - 1s 1ms/step - loss: 0.5492 - accuracy: 0.7194\n",
      "Test results - Loss: 0.5491540431976318 - Accuracy: 0.7193533182144165%\n",
      "866/866 [==============================] - 1s 1ms/step - loss: 0.5482 - accuracy: 0.7214\n",
      "Test results - Loss: 0.548162043094635 - Accuracy: 0.7214102745056152%\n",
      "866/866 [==============================] - 1s 1ms/step - loss: 0.5496 - accuracy: 0.7202\n",
      "Test results - Loss: 0.5496159791946411 - Accuracy: 0.7201833128929138%\n",
      "866/866 [==============================] - 1s 1ms/step - loss: 0.5492 - accuracy: 0.7225\n",
      "Test results - Loss: 0.5491656064987183 - Accuracy: 0.7225289344787598%\n",
      "866/866 [==============================] - 1s 1ms/step - loss: 0.5475 - accuracy: 0.7241\n",
      "Test results - Loss: 0.5474693775177002 - Accuracy: 0.7240806818008423%\n",
      "866/866 [==============================] - 1s 1ms/step - loss: 0.5472 - accuracy: 0.7244\n",
      "Test results - Loss: 0.5471554398536682 - Accuracy: 0.7243694067001343%\n",
      "866/866 [==============================] - 1s 1ms/step - loss: 0.5479 - accuracy: 0.7220\n",
      "Test results - Loss: 0.547920823097229 - Accuracy: 0.7219515442848206%\n",
      "866/866 [==============================] - 1s 1ms/step - loss: 0.5487 - accuracy: 0.7206\n",
      "Test results - Loss: 0.5486971139907837 - Accuracy: 0.7205802798271179%\n",
      "866/866 [==============================] - 1s 1ms/step - loss: 0.5503 - accuracy: 0.7199\n",
      "Test results - Loss: 0.5502936840057373 - Accuracy: 0.7198946475982666%\n",
      "866/866 [==============================] - 1s 1ms/step - loss: 0.5474 - accuracy: 0.7210\n",
      "Test results - Loss: 0.5473898649215698 - Accuracy: 0.7210133075714111%\n",
      "######################################################\n",
      " Loss    : 0.5485023975372314 - 0.0009962127367888372\n",
      " Accuracy: 0.7215365707874298 - 0.0016171736730124292%\n",
      "Deep Ensembles trained!!!~~~~~~~\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training standard NN Model~~~~~~~\n",
      "Epoch 1/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5997 - accuracy: 0.6877\n",
      "Epoch 2/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5729 - accuracy: 0.7034\n",
      "Epoch 3/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5644 - accuracy: 0.7095\n",
      "Epoch 4/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5607 - accuracy: 0.7125\n",
      "Epoch 5/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5589 - accuracy: 0.7127\n",
      "Epoch 6/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5577 - accuracy: 0.7140\n",
      "Epoch 7/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5562 - accuracy: 0.7139\n",
      "Epoch 8/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5559 - accuracy: 0.7149\n",
      "Epoch 9/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5547 - accuracy: 0.7156\n",
      "Epoch 10/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5545 - accuracy: 0.7152\n",
      "Epoch 11/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5536 - accuracy: 0.7161\n",
      "Epoch 12/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5535 - accuracy: 0.7159\n",
      "Epoch 13/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5528 - accuracy: 0.7168\n",
      "Epoch 14/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5522 - accuracy: 0.7169\n",
      "Epoch 15/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5522 - accuracy: 0.7163\n",
      "Epoch 16/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5516 - accuracy: 0.7180\n",
      "Epoch 17/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5517 - accuracy: 0.7187\n",
      "Epoch 18/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5513 - accuracy: 0.7178\n",
      "Epoch 19/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5511 - accuracy: 0.7187\n",
      "Epoch 20/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5510 - accuracy: 0.7182\n",
      "Epoch 21/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5507 - accuracy: 0.7177\n",
      "Epoch 22/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5504 - accuracy: 0.7188\n",
      "Epoch 23/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5503 - accuracy: 0.7184\n",
      "Epoch 24/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5499 - accuracy: 0.7192\n",
      "Epoch 25/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5502 - accuracy: 0.7181\n",
      "Epoch 26/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5495 - accuracy: 0.7188\n",
      "Epoch 27/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5496 - accuracy: 0.7195\n",
      "Epoch 28/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5497 - accuracy: 0.7186\n",
      "Epoch 29/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5490 - accuracy: 0.7198\n",
      "Epoch 30/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5489 - accuracy: 0.7193\n",
      "Epoch 31/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5489 - accuracy: 0.7196\n",
      "Epoch 32/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5490 - accuracy: 0.7189\n",
      "Epoch 33/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5491 - accuracy: 0.7200\n",
      "Epoch 34/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5487 - accuracy: 0.7198\n",
      "Epoch 35/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5487 - accuracy: 0.7201\n",
      "Epoch 36/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5487 - accuracy: 0.7198\n",
      "Epoch 37/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5484 - accuracy: 0.7198\n",
      "Epoch 38/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5488 - accuracy: 0.7187\n",
      "Epoch 39/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5484 - accuracy: 0.7206\n",
      "Epoch 40/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5484 - accuracy: 0.7197\n",
      "Epoch 41/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5483 - accuracy: 0.7198\n",
      "Epoch 42/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5482 - accuracy: 0.7202\n",
      "Epoch 43/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5483 - accuracy: 0.7199\n",
      "Epoch 44/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5480 - accuracy: 0.7198\n",
      "Epoch 45/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5480 - accuracy: 0.7213\n",
      "Epoch 46/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5481 - accuracy: 0.7203\n",
      "Epoch 47/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5481 - accuracy: 0.7199\n",
      "Epoch 48/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5483 - accuracy: 0.7198\n",
      "Epoch 49/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5482 - accuracy: 0.7197\n",
      "Epoch 50/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5476 - accuracy: 0.7202\n",
      "Epoch 51/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5478 - accuracy: 0.7205\n",
      "Epoch 52/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5477 - accuracy: 0.7212\n",
      "Epoch 53/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5479 - accuracy: 0.7201\n",
      "Epoch 54/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5476 - accuracy: 0.7198\n",
      "Epoch 55/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5474 - accuracy: 0.7209\n",
      "Epoch 56/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5477 - accuracy: 0.7206\n",
      "Epoch 57/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5474 - accuracy: 0.7208\n",
      "Epoch 58/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5476 - accuracy: 0.7208\n",
      "Epoch 59/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5472 - accuracy: 0.7207\n",
      "Epoch 60/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5472 - accuracy: 0.7215\n",
      "Epoch 61/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5473 - accuracy: 0.7205\n",
      "Epoch 62/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5470 - accuracy: 0.7214\n",
      "Epoch 63/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5473 - accuracy: 0.7209\n",
      "Epoch 64/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5474 - accuracy: 0.7219\n",
      "Epoch 65/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5473 - accuracy: 0.7205\n",
      "Epoch 66/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5469 - accuracy: 0.7212\n",
      "Epoch 67/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5473 - accuracy: 0.7204\n",
      "Epoch 68/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5471 - accuracy: 0.7217\n",
      "Epoch 69/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5470 - accuracy: 0.7216\n",
      "Epoch 70/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5471 - accuracy: 0.7205\n",
      "Epoch 71/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5473 - accuracy: 0.7209\n",
      "Epoch 72/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5469 - accuracy: 0.7212\n",
      "Epoch 73/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5468 - accuracy: 0.7220\n",
      "Epoch 74/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5464 - accuracy: 0.7213\n",
      "Epoch 75/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5465 - accuracy: 0.7215\n",
      "Epoch 76/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5466 - accuracy: 0.7211\n",
      "Epoch 77/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5466 - accuracy: 0.7211\n",
      "Epoch 78/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5464 - accuracy: 0.7216\n",
      "Epoch 79/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5461 - accuracy: 0.7222\n",
      "Epoch 80/80\n",
      "1109/1109 [==============================] - 2s 2ms/step - loss: 0.5460 - accuracy: 0.7222\n",
      "Standard NN trained!!!~~~~~~~\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Train Deep Ensembles Model\n",
    "print(\"Training Deep Ensembles Model~~~~~~~\")\n",
    "histories,trained_models = train(Xtrain, np.array(y_train).reshape(-1,1), epochs=80, batch=100)\n",
    "losses,accuracies = model_eval(Xtest,np.array(y_test).reshape(-1,1),trained_models)\n",
    "print(\"Deep Ensembles trained!!!~~~~~~~\")\n",
    "print(\"\\n\\n\\n\\n\\n\")\n",
    "## Train standard NN\n",
    "print(\"Training standard NN Model~~~~~~~\")\n",
    "DNN_model = Sequential([\n",
    "            Dense(50,activation='sigmoid'),\n",
    "            Dense(1,activation='sigmoid')])\n",
    "DNN_model.compile(tf.keras.optimizers.Adam(learning_rate=0.01), loss='binary_crossentropy',metrics=[\"accuracy\"])\n",
    "DNN_model.fit(Xtrain, np.array(y_train).reshape(-1,1), epochs=80, batch_size=100)\n",
    "print(\"Standard NN trained!!!~~~~~~~\")\n",
    "print(\"\\n\\n\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "866/866 [==============================] - 1s 1ms/step - loss: 0.5484 - accuracy: 0.7225\n",
      "Test results - Loss: 0.5484405755996704 - Accuracy: 0.7224568128585815%\n",
      "ECE with n_bins = 5:\n",
      "ECE_DeepEnsembles:  0.011\n",
      "ECE_StandardNN   :  0.0078\n",
      "UEI: \n",
      "UEI_DeepEnsembles:  0.10870027930995231\n",
      "UEI_StandardNN   :  0.09517638986200762\n",
      "US_0: \n",
      "3481 5627\n",
      "US0_DeepEnsembles:  0.6186244890705527\n",
      "3813 5627\n",
      "US0_StandardNN   :  0.6776257330726853\n",
      "US_1: \n",
      "2845 4575\n",
      "US1_DeepEnsembles:  0.6218579234972678\n",
      "2970 4575\n",
      "US1_StandardNN   :  0.6491803278688525\n"
     ]
    }
   ],
   "source": [
    "y_probs_combined = np.stack([model(Xtest) for model in trained_models])\n",
    "y_preds_combined = np.mean(y_probs_combined, axis=0)\n",
    "\n",
    "\n",
    "# Test the model after training\n",
    "test_results = DNN_model.evaluate(Xtest, np.array(y_test).reshape(-1,1), verbose=1)\n",
    "print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]}%')\n",
    "y_pred_1NN = DNN_model(Xtest)\n",
    "\n",
    "df = {}\n",
    "df['sa'] = group_test\n",
    "df['actual'] = y_test\n",
    "df['Ensembles'] = y_preds_combined.ravel()\n",
    "df['DNN'] = np.array(y_pred_1NN).ravel()\n",
    "df = pd.DataFrame(df)\n",
    "\n",
    "print(\"ECE with n_bins = 5:\")\n",
    "print(\"ECE_DeepEnsembles: \",compute_calibration_error(np.array(y_test),y_preds_combined,n_bins=5))\n",
    "print(\"ECE_StandardNN   : \",compute_calibration_error(np.array(y_test),y_pred_1NN,n_bins=5))\n",
    "\n",
    "\n",
    "\n",
    "print(\"UEI: \")\n",
    "print(\"UEI_DeepEnsembles: \",UEI(df.sa.values, df.actual.values, np.round(df['Ensembles'].values)))\n",
    "print(\"UEI_StandardNN   : \",UEI(df.sa.values, df.actual.values, np.round(df['DNN'].values)))\n",
    "\n",
    "print(\"US_0: \")\n",
    "print(\"US0_DeepEnsembles: \",underestimation_score_1(df.actual.values, np.round(df['Ensembles'].values),df.sa.values))\n",
    "print(\"US0_StandardNN   : \",underestimation_score_1(df.actual.values, np.round(df['DNN'].values),df.sa.values))\n",
    "\n",
    "print(\"US_1: \")\n",
    "print(\"US1_DeepEnsembles: \",underestimation_score(df.actual.values, np.round(df['Ensembles'].values),df.sa.values))\n",
    "print(\"US1_StandardNN   : \",underestimation_score(df.actual.values, np.round(df['DNN'].values),df.sa.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECE with n_bins = 5:\n",
      "ECE_DeepEnsembles_Maj:  0.0149\n",
      "ECE_DeepEnsembles_Min   :  0.0121\n",
      "ECE with n_bins = 5:\n",
      "ECE_DNN_Maj:  0.0175\n",
      "ECE_DNN_Min   :  0.0063\n"
     ]
    }
   ],
   "source": [
    "from sklearn.calibration import calibration_curve\n",
    "prob_true, prob_pred = calibration_curve(y_test, y_preds_combined, n_bins=5)\n",
    "prob_true_dnn, prob_pred_dnn = calibration_curve(y_test, y_pred_1NN, n_bins=5)\n",
    "minority = df[df['sa'] == 1]\n",
    "majority = df[df['sa'] == 0]\n",
    "prob_true_maj, prob_pred_maj = calibration_curve(np.array(majority.actual), majority['Ensembles'].values.reshape(-1,1), n_bins=5)\n",
    "prob_true_min, prob_pred_min = calibration_curve(np.array(minority.actual), minority['Ensembles'].values.reshape(-1,1), n_bins=5)\n",
    "prob_true_dnn_maj, prob_pre_dnnd_maj = calibration_curve(np.array(majority.actual), majority['DNN'].values.reshape(-1,1), n_bins=5)\n",
    "prob_true_dnn_min, prob_pred_dnn_min = calibration_curve(np.array(minority.actual), minority['DNN'].values.reshape(-1,1), n_bins=5)\n",
    "\n",
    "print(\"ECE with n_bins = 5:\")\n",
    "print(\"ECE_DeepEnsembles_Maj: \",compute_calibration_error(np.array(majority.actual), majority['Ensembles'].values.reshape(-1,1), n_bins=5))\n",
    "print(\"ECE_DeepEnsembles_Min   : \",compute_calibration_error(np.array(minority.actual), minority['Ensembles'].values.reshape(-1,1), n_bins=5))\n",
    "\n",
    "print(\"ECE with n_bins = 5:\")\n",
    "print(\"ECE_DNN_Maj: \",compute_calibration_error(np.array(majority.actual), majority['DNN'].values.reshape(-1,1), n_bins=5))\n",
    "print(\"ECE_DNN_Min   : \",compute_calibration_error(np.array(minority.actual), minority['DNN'].values.reshape(-1,1), n_bins=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best threshold for s=0 that minimizes P(Y|S) - P(Yhat|S) is:  0.393939393939394\n",
      "best threshold for s=1 that minimizes P(Y|S) - P(Yhat|S) is:  0.393939393939394\n",
      "Train:\n",
      "0.7188997049881364 0.5343305818815802 0.0019868781176223664\n",
      "Test:\n",
      "0.7114142398325575 0.5403747327324889 0.00021580810819730122\n",
      "US_S_0\n",
      "4574 4575\n",
      "0.9997814207650273\n",
      "US_S_1\n",
      "5621 5627\n",
      "0.9989337124577928\n"
     ]
    }
   ],
   "source": [
    "## Post-processing\n",
    "\n",
    "def find_thres(group,clf_prob,truth):\n",
    "    ls_0 = {}\n",
    "    ls_1 = {}\n",
    "    thresholds = np.linspace(0, 1, num=100)\n",
    "    for thres in thresholds:\n",
    "        df = {}\n",
    "        df['sa'] = group\n",
    "        df['prob'] = clf_prob\n",
    "        df['ground_truth'] = truth\n",
    "        df['prob_pred'] =[0]*len(truth)\n",
    "        df = pd.DataFrame(df)\n",
    "        df.loc[ (df['sa'] == 0) & (df['prob'] > thres),'prob_pred'] = 1\n",
    "        df.loc[ (df['sa'] == 1) & (df['prob'] > thres),'prob_pred'] = 1\n",
    "        US_pred_0 = df_count_feat_val_match(df, 'prob_pred', 1, 'sa',0)\n",
    "        US_true_0 = df_count_feat_val_match(df, 'ground_truth', 1, 'sa',0)\n",
    "        US_pred_1 = df_count_feat_val_match(df, 'prob_pred', 1, 'sa',1)\n",
    "        US_true_1 = df_count_feat_val_match(df, 'ground_truth', 1, 'sa',1)\n",
    "        ls_0[thres] = np.abs(US_pred_0-US_true_0)\n",
    "        ls_1[thres] = np.abs(US_pred_1-US_true_1)\n",
    "    best_0 = thresholds[np.argmin(list(ls_0.values()))]\n",
    "    best_1 = thresholds[np.argmin(list(ls_1.values()))]\n",
    "    print(\"best threshold for s=0 that minimizes P(Y|S) - P(Yhat|S) is: \",best_0)\n",
    "    print(\"best threshold for s=1 that minimizes P(Y|S) - P(Yhat|S) is: \",best_1)\n",
    "    return best_0,best_1\n",
    "\n",
    "def make_pred(group,clf_prob,thres_0,thres_1):\n",
    "    y_post = []\n",
    "    for sa,predictproba in zip(group,clf_prob):\n",
    "        if sa == 0 and predictproba > thres_0:\n",
    "            y_post.append(1)\n",
    "        elif sa == 0 and predictproba <= thres_0:\n",
    "            y_post.append(0)\n",
    "        elif sa == 1 and predictproba > thres_1:\n",
    "            y_post.append(1)\n",
    "        else:\n",
    "            y_post.append(0)\n",
    "    return y_post\n",
    "\n",
    "def evaluate(y_true,y_pred,sa):\n",
    "    ## convert the probability estimates to class labels (MC Dropout)\n",
    "\n",
    "    ba = accuracy_score(y_true,y_pred)\n",
    "    us_s = UEI(sa, y_true, np.round(y_pred))\n",
    "    return ba,us_s\n",
    "\n",
    "y_probs_combined = np.stack([model(Xtrain) for model in trained_models])\n",
    "y_preds_combined = np.mean(y_probs_combined, axis=0)\n",
    "best_thres_0,best_thres_1 = find_thres(group_train,np.array(y_preds_combined.ravel()),y_train)\n",
    "y_pred_post = make_pred(group_train,np.array(y_preds_combined.ravel()),best_thres_0,best_thres_1)\n",
    "best_ba,best_us = evaluate(y_train,np.array(y_pred_post),group_train)\n",
    "print(\"Train:\")\n",
    "print(best_ba,nll1(y_train,np.array(y_preds_combined.ravel())).numpy()/Xtrain.shape[0],best_us)\n",
    "## test\n",
    "y_probs_combined = np.stack([model(Xtest) for model in trained_models])\n",
    "y_preds_combined = np.mean(y_probs_combined, axis=0)\n",
    "y_pred_post = make_pred(group_test,np.array(y_preds_combined.ravel()),best_thres_0,best_thres_1)\n",
    "best_ba,best_us = evaluate(y_test,np.array(y_pred_post),group_test)\n",
    "print(\"Test:\")\n",
    "print(best_ba,nll1(y_test,np.array(y_preds_combined.ravel())).numpy()/Xtest.shape[0],best_us)\n",
    "\n",
    "print(\"US_S_0\")\n",
    "print(underestimation_score(y_test,y_pred_post,group_test))\n",
    "print(\"US_S_1\")\n",
    "print(underestimation_score_1(y_test,y_pred_post,group_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
